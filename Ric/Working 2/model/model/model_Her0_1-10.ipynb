{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 02:11:15.835768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 02:11:16.637307: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 02:11:17.816228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 02:11:17.816339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 02:11:17.816349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Her0 helpers\n",
    "import BBVAHer0.preprocessing as Pp\n",
    "import BBVAHer0.metrics as Mtr\n",
    "\n",
    "# Core libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "importlib.reload(Pp)\n",
    "importlib.reload(Mtr)\n",
    "\n",
    "# Graphic libs\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "# sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error as LMAPE\n",
    "\n",
    "# IA + blockchain = profit\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Dropout, BatchNormalization, Activation, Dense, LeakyReLU, Add\n",
    "from keras.layers.merging import Add, Concatenate\n",
    "from keras.utils import plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_master = pd.read_excel('../data/xlsx/ord80p.xlsx', header = [0]).applymap(lambda x : (x - pd.Timestamp(\"1900-01-01 00:00:00\")).days + 2 if isinstance(x,pd.Timestamp) else x)\n",
    "raw_test_master = pd.read_excel('../data/xlsx/ord20p.xlsx', header = [0]).applymap(lambda x : (x - pd.Timestamp(\"1900-01-01 00:00:00\")).days + 2 if isinstance(x,pd.Timestamp) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Pp)\n",
    "importlib.reload(Mtr)\n",
    "\n",
    "trainer_data, train_gt = Pp.sanitize(raw_data_master, True)\n",
    "tester_data, test_gt = Pp.sanitize(raw_data_master, True)\n",
    "log_data = trainer_data.drop(['Valorcomercial'], axis=1)\n",
    "log_test = tester_data.drop(['Valorcomercial'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/plotly/express/_core.py:137: FutureWarning:\n",
      "\n",
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = px.scatter_matrix(trainer_data,\n",
    "    #dimensions=['PC '+ str(i+1) + ' ' + '({:.2f}%)'.format(pca.explained_variance_ratio_[i]*100) for i in range(1,13)],\n",
    "    #color=\"Valor comercial (USD)\",\n",
    "    title=\"Scatter matrix of data set\",\n",
    "    labels=trainer_data.columns) # remove underscore\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.update_traces(marker_size=1)\n",
    "\n",
    "fig.update_layout(font=dict(size=10))\n",
    "\n",
    "fig.update_layout({\"xaxis\"+str(i+1): dict(showticklabels = False, title=trainer_data.columns[i][:3].upper()) for i in range(8)})\n",
    "fig.update_layout({\"yaxis\"+str(i+1): dict(showticklabels = False, title=trainer_data.columns[i][:3].upper()) for i in range(8)})\n",
    "\n",
    "\n",
    "fig.update_layout(margin={\"r\":150,\"t\":20,\"l\":150,\"b\":20})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Categoriadelbien</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Areaterreno</th>\n",
       "      <th>Areaconstruccion</th>\n",
       "      <th>Valorcomercial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28774.000000</td>\n",
       "      <td>28774.000000</td>\n",
       "      <td>28774.000000</td>\n",
       "      <td>28774.000000</td>\n",
       "      <td>28774.000000</td>\n",
       "      <td>28774.000000</td>\n",
       "      <td>28774.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.263190</td>\n",
       "      <td>-4.193688</td>\n",
       "      <td>1.335604</td>\n",
       "      <td>1.865950</td>\n",
       "      <td>4.431212</td>\n",
       "      <td>5.076233</td>\n",
       "      <td>62.278120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.269159</td>\n",
       "      <td>0.505336</td>\n",
       "      <td>0.380319</td>\n",
       "      <td>1.243425</td>\n",
       "      <td>5.435525</td>\n",
       "      <td>2.421045</td>\n",
       "      <td>24.360705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.255516</td>\n",
       "      <td>-9.129394</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>2.758924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.296839</td>\n",
       "      <td>-4.255290</td>\n",
       "      <td>1.259921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.286882</td>\n",
       "      <td>4.173702</td>\n",
       "      <td>48.039103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.295076</td>\n",
       "      <td>-4.254701</td>\n",
       "      <td>1.259921</td>\n",
       "      <td>1.912931</td>\n",
       "      <td>3.133592</td>\n",
       "      <td>4.754843</td>\n",
       "      <td>56.898455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.293360</td>\n",
       "      <td>-4.253983</td>\n",
       "      <td>1.442250</td>\n",
       "      <td>2.802039</td>\n",
       "      <td>5.428835</td>\n",
       "      <td>5.874717</td>\n",
       "      <td>69.770336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>2.351335</td>\n",
       "      <td>12.609701</td>\n",
       "      <td>468.755196</td>\n",
       "      <td>35.523294</td>\n",
       "      <td>329.403330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Lat          Long  Categoriadelbien          Edad  \\\n",
       "count  28774.000000  28774.000000      28774.000000  28774.000000   \n",
       "mean      -2.263190     -4.193688          1.335604      1.865950   \n",
       "std        0.269159      0.505336          0.380319      1.243425   \n",
       "min       -4.255516     -9.129394          0.004642      0.004642   \n",
       "25%       -2.296839     -4.255290          1.259921      1.000000   \n",
       "50%       -2.295076     -4.254701          1.259921      1.912931   \n",
       "75%       -2.293360     -4.253983          1.442250      2.802039   \n",
       "max        0.004642      0.004642          2.351335     12.609701   \n",
       "\n",
       "        Areaterreno  Areaconstruccion  Valorcomercial  \n",
       "count  28774.000000      28774.000000    28774.000000  \n",
       "mean       4.431212          5.076233       62.278120  \n",
       "std        5.435525          2.421045       24.360705  \n",
       "min        0.004642          0.004642        2.758924  \n",
       "25%        2.286882          4.173702       48.039103  \n",
       "50%        3.133592          4.754843       56.898455  \n",
       "75%        5.428835          5.874717       69.770336  \n",
       "max      468.755196         35.523294      329.403330  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PC1 (98.004)%', 'PC2 (1.165)%', 'PC3 (0.497)%', 'PC4 (0.198)%', 'PC5 (0.066)%', 'PC6 (0.048)%', 'PC7 (0.021)%']\n",
      "[ 98.00415797  99.16879764  99.66598786  99.86405682  99.9304733\n",
      "  99.97876263  99.99928796 100.        ]\n"
     ]
    }
   ],
   "source": [
    "data_pca = PCA()\n",
    "data_pca.fit(trainer_data)\n",
    "\n",
    "print(['PC'+str(i+1)+' ({:.3f})%'.format(data_pca.explained_variance_ratio_[i]*100) for i in range(7)])\n",
    "print(np.cumsum(data_pca.explained_variance_ratio_)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27426, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = trainer_data.to_numpy().T\n",
    "components = (data_pca.components_[:5,:]@X).T\n",
    "\n",
    "components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/plotly/express/_core.py:137: FutureWarning:\n",
      "\n",
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "components_df = pd.DataFrame(components, columns=['PC'+str(i+1)+' ({:.1f})%'.format(data_pca.explained_variance_ratio_[i]*100) for i in range(8)])\n",
    "components_df.insert(0, 'Valorcomercial', trainer_data['Valorcomercial'].to_numpy())\n",
    "\n",
    "fig = px.scatter_matrix(components_df,\n",
    "    dimensions=['PC'+str(i+1)+' ({:.1f})%'.format(data_pca.explained_variance_ratio_[i]*100) for i in range(8)],\n",
    "    color=\"Valorcomercial\",\n",
    "    title=\"PCA Pairs plot\",\n",
    "    labels=components_df.columns) # remove underscore\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.update_traces(marker_size=1)\n",
    "\n",
    "fig.update_layout(font=dict(size=10))\n",
    "\n",
    "fig.update_layout({\"xaxis\"+str(i+1): dict(showticklabels = False) for i in range(8)})\n",
    "fig.update_layout({\"yaxis\"+str(i+1): dict(showticklabels = False, title='PC'+str(i+1)) for i in range(8)})\n",
    "\n",
    "\n",
    "fig.update_layout(margin={\"r\":150,\"t\":20,\"l\":150,\"b\":20})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8qUlEQVR4nO3deVhUdf//8dewKiooIShI7mtuhemtZWqipLm1KFmGmtlipUmrlppWkuX6S0sz0Kzb3Epb9IuaRplS3m5l5ZKlkguot8ugFMvM+f3hxdxOgwoDMnh8Pq5rrov5nM858/4MM8OLcz7njMUwDEMAAAAm4eXpAgAAAEoS4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QaAR6SkpMhisSglJcXRNmjQINWqVctjNQEwB8INcA2ZP3++LBaLtmzZ4ulSrkoWi8Vx8/LyUnh4uLp27eoU0PLZbDbNmzdPHTt2VHBwsPz9/VWrVi0NHjz4ss//n3/+qfHjx6t169aqUqWKQkJC1LFjR3311VdXaGSAufh4ugAAyDd37lzZ7XZPl3FJXbp0UVxcnAzD0P79+/XOO+/o9ttv18qVK9WtWzdJ0l9//aW7775bycnJuu222zR69GgFBwfrwIEDWrJkiT744AOlpaWpRo0aBT7GZ599pkmTJqlPnz4aOHCg8vLytGDBAnXp0kVJSUkaPHhwaQ4ZuOoQbgCUGb6+vp4u4bIaNGigAQMGOO7fddddat68uaZPn+4IN88995ySk5M1bdo0Pf30007rjxs3TtOmTbvkY3Tq1ElpaWkKCQlxtD322GNq2bKlxo4dS7gBLoPDUgBcbN++Xd26dVNgYKAqVqyozp076/vvv3fqc/LkST377LNq1qyZKlasqMDAQHXr1k0//vijy/YOHTqkPn36qEKFCgoNDdXIkSOVnZ3t0u+fc24OHDggi8WiyZMn67333lPdunXl7++vm2++Wf/5z39c1l+6dKmaNGmicuXKqWnTplq+fHmB83gWLVqkqKgoVapUSYGBgWrWrJlmzJjh1nPVrFkzhYSEaP/+/Y6xzpkzR126dHEJNpLk7e2tZ5999qJ7bSTphhtucAo2kuTv76/u3bvr0KFDyszMdKtW4FrBnhsATn755Re1b99egYGBev755+Xr66s5c+aoY8eO+uabb9SmTRtJ0h9//KEVK1aob9++ql27tjIyMjRnzhx16NBBv/76q8LDwyWdP0TTuXNnpaWlafjw4QoPD9eHH36o9evXF7qmhQsXKjMzU48++qgsFovefPNN3X333frjjz8ce3tWrlyp2NhYNWvWTAkJCTp16pSGDBmiiIgIp22tXbtW/fv3V+fOnTVp0iRJ0q5du7Rx40aNGDGiyM/XqVOndOrUKdWrV0+S9H//93/Ky8vTgw8+WORtXU56eroCAgIUEBBQ4tsGzIRwA8DJyy+/rNzcXH333XeqU6eOJCkuLk4NGzbU888/r2+++UbS+T0We/fulZfX/3YAP/jgg2rUqJESExM1ZswYSdJ7772nvXv3asmSJerbt68kaejQoWrRokWha0pLS9Nvv/2mKlWqSJIaNmyo3r17a/Xq1erRo4ckadSoUYqIiNDGjRtVsWJFSVLnzp3VsWNH1axZ07GtlStXKjAwUKtXr5a3t3eRn5+///5bJ06ccMy5GT16tGw2m2Nsu3btcjw/JWnfvn369NNP1bdvX7fqBq4lHJYC4GCz2bRmzRr16dPHEWwkqXr16rr//vv13XffyWq1Sjp/mCQ/2NhsNv33v/9VxYoV1bBhQ23bts2x7qpVq1S9enXde++9jraAgAA98sgjha4rNjbWEWwkqX379pLO7z2SpCNHjmjnzp2Ki4tzBBtJ6tChg0vIqFy5ss6dO6e1a9cW+vEvlJiYqKpVqyo0NFRt2rTRxo0bFR8f7zgElf/8VKpUya3tFyQrK0t9+/ZV+fLl9cYbb5TYdgGzItwAcDh+/LiysrLUsGFDl2WNGzeW3W7Xn3/+KUmy2+2aNm2a6tevL39/f4WEhKhq1ar66aefdObMGcd6Bw8eVL169WSxWJy2V9BjXMz111/vdD8/6Jw6dcrxGJIch4Yu9M+2YcOGqUGDBurWrZtq1Kihhx56SMnJyYWupXfv3lq7dq2++uor/fDDDzpx4oSmTJniCHqBgYGSVGLzYmw2m+677z79+uuvWrZsmeNwH4CLI9wAcMvEiRMVHx+v2267TR999JFWr16ttWvX6oYbbijx07kvdhjGMIwibys0NFQ7duzQ559/rl69eunrr79Wt27dNHDgwEKtX6NGDUVHR6tz585q3bq1KlSo4LS8UaNGkqSdO3cWubaCDB06VF9++aXmz5+v22+/vUS2CZgdc24AOFStWlUBAQHas2ePy7Ldu3fLy8tLkZGRkqRly5apU6dOSkxMdOp3+vRppzN9atasqZ9//lmGYTjtvSnoMdyVP6dm3759LssKavPz81PPnj3Vs2dP2e12DRs2THPmzNGYMWMK3PtTFN26dZO3t7c++uijYk8qfu655zRv3jxNnz5d/fv3L9a2gGsJe24AOHh7e6tr16767LPPdODAAUd7RkaGFi5cqFtvvdVx2MXb29tlz8nSpUt1+PBhp7bu3bvryJEjWrZsmaMtKytL7733XonVHR4erqZNm2rBggU6e/aso/2bb75x2YPy3//+1+m+l5eXmjdvLkkFnp5eVJGRkRo6dKjWrFmjt99+22W53W7XlClTdOjQoUtu56233tLkyZM1evRot87iAq5l7LkBrkFJSUkFzjMZMWKEXnvtNa1du1a33nqrhg0bJh8fH82ZM0fZ2dl68803HX179OihCRMmaPDgwWrXrp127typf//7304TkaXzh1VmzpypuLg4bd26VdWrV9eHH35Y4qczT5w4Ub1799Ytt9yiwYMH69SpU5o5c6aaNm3qFHgefvhhnTx5Urfffrtq1KihgwcP6u2331bLli3VuHHjEqllypQp+v333zV8+HB9+umn6tGjh6pUqaK0tDQtXbpUu3fv1n333XfR9ZcvX67nn39e9evXV+PGjfXRRx85Le/SpYvCwsJKpFbAlAwA14x58+YZki56+/PPPw3DMIxt27YZMTExRsWKFY2AgACjU6dOxqZNm5y29ffffxvPPPOMUb16daN8+fLGLbfcYqSmphodOnQwOnTo4NT34MGDRq9evYyAgAAjJCTEGDFihJGcnGxIMr7++mtHv4EDBxo1a9Z03N+/f78hyXjrrbdcxiLJGDdunFPbokWLjEaNGhn+/v5G06ZNjc8//9y45557jEaNGjn6LFu2zOjatasRGhpq+Pn5Gddff73x6KOPGkePHr3s8yfJeOKJJy7bzzAMIy8vz3j//feN9u3bG0FBQYavr69Rs2ZNY/Dgwcb27dsvue64ceMu+Xu68DkD4MpiGG7MyAOAq0TLli1VtWpVt0/9BnD1Yc4NAFPIzc1VXl6eU1tKSop+/PFHdezY0TNFAfAI9twAMIUDBw4oOjpaAwYMUHh4uHbv3q3Zs2crKChIP//8s6677jpPlwiglDChGIApVKlSRVFRUXr//fd1/PhxVahQQXfeeafeeOMNgg1wjWHPDQAAMBXm3AAAAFMh3AAAAFO55ubc2O12HTlyRJUqVXL5Ij8AAFA2GYahzMxMhYeHO76o9mKuuXBz5MgRx3fjAACAq8uff/6pGjVqXLLPNRduKlWqJOn8k5P/HTkAAKBss1qtioyMdPwdv5RrLtzkH4oKDAwk3AAAcJUpzJQSJhQDAABTIdwAAABTIdwAAABTuebm3BSWzWZTbm7uRZf7+fld9lQ0AABQ+gg3/2AYhtLT03X69OlL9vPy8lLt2rXl5+dXOoUBAIBCIdz8Q36wCQ0NVUBAQIGzsvMvBHj06FFdf/31XAwQAIAyxKPHVb799lv17NlT4eHhslgsWrFixWXXSUlJ0U033SR/f3/Vq1dP8+fPL7F6bDabI9hcd911Kl++vMqVK+dyCwgIUNWqVZWVlaW8vLwSe3wAAFB8Hg03586dU4sWLTRr1qxC9d+/f7/uvPNOderUSTt27NDTTz+thx9+WKtXry6RevLn2AQEBFy2b/7hKJvNViKPDQAASoZHD0t169ZN3bp1K3T/2bNnq3bt2poyZYokqXHjxvruu+80bdo0xcTElFhdhTnMxKEoAADKpqvqdJ/U1FRFR0c7tcXExCg1NdVDFQEAgLLmqppQnJ6errCwMKe2sLAwWa1W/fXXXypfvrzLOtnZ2crOznbct1qtks4fgvrnqd65ubkyDEN2u112u/2StdjtdhmGodzcXHl7e7s7JAAAUAiXujzLP11V4cYdCQkJGj9+vEv7mjVrXObW+Pj4qFq1ajp79qxycnIuud2cnBz99ddf+vbbb5lUDADAFZaVlVXovldVuKlWrZoyMjKc2jIyMhQYGFjgXhtJGjVqlOLj4x33879VtGvXri5fnJmdna20tDRVqFDhotvLl7+nqEOHDvL393dzRAAAoDDyj7wUxlUVbtq2batVq1Y5ta1du1Zt27a96Dr+/v4Fhg9fX1/5+vo6tXl5eclisejvv/9WhQoVLllLXl6eLBaL/P39XbYDAABKVlH+1no03Jw9e1b79u1z3N+/f7927Nih4OBgXX/99Ro1apQOHz6sBQsWSJIee+wxzZw5U88//7weeughrV+/XkuWLNHKlStLpB5vb29VrlxZx44dk6RLXsTv+PHjCggIkI/PVZUPAZjc0HdOeroEt8wdFuzpEmAiHv3LvGXLFnXq1MlxP//w0cCBAzV//nwdPXpUaWlpjuW1a9fWypUrNXLkSM2YMUM1atTQ+++/X6KngVerVk2SHAHnYry8vLg6MQAAZZDFMAzD00WUJqvVqqCgIJ05c8Zlzs2F+OJMAFcj9tzArAr791u6yubclCZvb29O8QYA4CrErgcAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqHg83s2bNUq1atVSuXDm1adNGmzdvvmT/6dOnq2HDhipfvrwiIyM1cuRI/f3336VULQAAKOs8Gm4WL16s+Ph4jRs3Ttu2bVOLFi0UExOjY8eOFdh/4cKFevHFFzVu3Djt2rVLiYmJWrx4sUaPHl3KlQMAgLLKo+Fm6tSpGjp0qAYPHqwmTZpo9uzZCggIUFJSUoH9N23apFtuuUX333+/atWqpa5du6p///6X3dsDAACuHT6eeuCcnBxt3bpVo0aNcrR5eXkpOjpaqampBa7Trl07ffTRR9q8ebNat26tP/74Q6tWrdKDDz540cfJzs5Wdna2477VapUk5ebmKjc3t4RGAwAoDj6PcTlFeY14LNycOHFCNptNYWFhTu1hYWHavXt3gevcf//9OnHihG699VYZhqG8vDw99thjlzwslZCQoPHjx7u0r1mzRgEBAcUbBACUOe09XYBbVq1a5ekSUMZlZWUVuq/Hwo07UlJSNHHiRL3zzjtq06aN9u3bpxEjRujVV1/VmDFjClxn1KhRio+Pd9y3Wq2KjIxU165dFRgYWFqlA0Cp+HJupqdLcEv37t09XQLKuPwjL4XhsXATEhIib29vZWRkOLVnZGSoWrVqBa4zZswYPfjgg3r44YclSc2aNdO5c+f0yCOP6KWXXpKXl+sUIn9/f/n7+7u0+/r6ytfXtwRGAgAoLj6PcTlFeY14bEKxn5+foqKitG7dOkeb3W7XunXr1LZt2wLXycrKcgkw3t7ekiTDMK5csQAA4Krh0cNS8fHxGjhwoFq1aqXWrVtr+vTpOnfunAYPHixJiouLU0REhBISEiRJPXv21NSpU3XjjTc6DkuNGTNGPXv2dIQcAABwbfNouImNjdXx48c1duxYpaenq2XLlkpOTnZMMk5LS3PaU/Pyyy/LYrHo5Zdf1uHDh1W1alX17NlTr7/+uqeGAAAAyhiLcY0dz7FarQoKCtKZM2eYUAzAdIa+c9LTJbhl7rBgT5eAMq4of789/vULAAAAJYlwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMXj4WbWrFmqVauWypUrpzZt2mjz5s2X7H/69Gk98cQTql69uvz9/dWgQQOtWrWqlKoFAABlnY8nH3zx4sWKj4/X7Nmz1aZNG02fPl0xMTHas2ePQkNDXfrn5OSoS5cuCg0N1bJlyxQREaGDBw+qcuXKpV88AAAokzwabqZOnaqhQ4dq8ODBkqTZs2dr5cqVSkpK0osvvujSPykpSSdPntSmTZvk6+srSapVq1ZplgwAAMo4j4WbnJwcbd26VaNGjXK0eXl5KTo6WqmpqQWu8/nnn6tt27Z64okn9Nlnn6lq1aq6//779cILL8jb27vAdbKzs5Wdne24b7VaJUm5ubnKzc0twREBANzF5zEupyivEY+FmxMnTshmsyksLMypPSwsTLt37y5wnT/++EPr16/XAw88oFWrVmnfvn0aNmyYcnNzNW7cuALXSUhI0Pjx413a16xZo4CAgOIPBADKlPaeLsAtzJ3E5WRlZRW6r0cPSxWV3W5XaGio3nvvPXl7eysqKkqHDx/WW2+9ddFwM2rUKMXHxzvuW61WRUZGqmvXrgoMDCyt0gGgVHw5N9PTJbile/funi4BZVz+kZfC8Fi4CQkJkbe3tzIyMpzaMzIyVK1atQLXqV69unx9fZ0OQTVu3Fjp6enKycmRn5+fyzr+/v7y9/d3aff19XXM2wEAeBafx7icorxGPHYquJ+fn6KiorRu3TpHm91u17p169S2bdsC17nlllu0b98+2e12R9vevXtVvXr1AoMNAAC49nj0Ojfx8fGaO3euPvjgA+3atUuPP/64zp075zh7Ki4uzmnC8eOPP66TJ09qxIgR2rt3r1auXKmJEyfqiSee8NQQAABAGePROTexsbE6fvy4xo4dq/T0dLVs2VLJycmOScZpaWny8vpf/oqMjNTq1as1cuRINW/eXBERERoxYoReeOEFTw0BAACUMRbDMAxPF1GarFargoKCdObMGSYUAzCdoe+c9HQJbpk7LNjTJaCMK8rfb49//QIAAEBJItwAAABTIdwAAABTKdaE4l9//VVpaWnKyclxau/Vq1exigIAAHCXW+Hmjz/+0F133aWdO3fKYrEof06yxWKRJNlstpKrEAAAoAjcOiw1YsQI1a5dW8eOHVNAQIB++eUXffvtt2rVqpVSUlJKuEQAAIDCc2vPTWpqqtavX6+QkBB5eXnJy8tLt956qxISEjR8+HBt3769pOsEAAAoFLf23NhsNlWqVEnS+e+IOnLkiCSpZs2a2rNnT8lVBwAAUERu7blp2rSpfvzxR9WuXVtt2rTRm2++KT8/P7333nuqU6dOSdcIAABQaG6Fm5dfflnnzp2TJE2YMEE9evRQ+/btdd1112nx4sUlWiAAAEBRuBVuYmJiHD/Xq1dPu3fv1smTJ1WlShXHGVMAAACeUGJfnBkczPeCAAAAzyt0uLn77rs1f/58BQYG6u67775k308//bTYhQEAALij0OEmKCjIccgpKCjoihUEAABQHIUON/PmzSvwZwAAgLLErevc7N+/X7/99ptL+2+//aYDBw4UtyYAAAC3uRVuBg0apE2bNrm0//DDDxo0aFBxawIAAHCbW+Fm+/btuuWWW1za//Wvf2nHjh3FrQkAAMBtboUbi8WizMxMl/YzZ87wjeAAAMCj3Ao3t912mxISEpyCjM1mU0JCgm699dYSKw4AAKCo3LqI36RJk3TbbbepYcOGat++vSRpw4YNslqtWr9+fYkWCAAAUBRu7blp0qSJfvrpJ/Xr10/Hjh1TZmam4uLitHv3bjVt2rSkawQAACg0t79+ITw8XBMnTizJWgAAAIrN7XBz+vRpbd68WceOHZPdbndaFhcXV+zCAAAA3OFWuPniiy/0wAMP6OzZswoMDHT6JnCLxUK4AQAAHuPWnJtnnnlGDz30kM6ePavTp0/r1KlTjtvJkydLukYAAIBCcyvcHD58WMOHD1dAQEBJ1wMAAFAsboWbmJgYbdmypaRrAQAAKDa35tzceeedeu655/Trr7+qWbNm8vX1dVreq1evEikOAACgqNwKN0OHDpUkTZgwwWWZxWLhKxgAAIDHuBVu/nnqNwAAQFnh1pwbAACAssrti/idO3dO33zzjdLS0pSTk+O0bPjw4cUuDAAAwB1uhZvt27ere/fuysrK0rlz5xQcHKwTJ04oICBAoaGhhBsAAOAxbh2WGjlypHr27KlTp06pfPny+v7773Xw4EFFRUVp8uTJJV0jAABAobkVbnbs2KFnnnlGXl5e8vb2VnZ2tiIjI/Xmm29q9OjRJV0jAABAobkVbnx9feXldX7V0NBQpaWlSZKCgoL0559/llx1AAAAReTWnJsbb7xR//nPf1S/fn116NBBY8eO1YkTJ/Thhx+qadOmJV0jAABAobm152bixImqXr26JOn1119XlSpV9Pjjj+v48eOaM2dOiRYIAABQFG7tuWnVqpXj59DQUCUnJ5dYQQAAAMXh1p6b22+/XadPn3Zpt1qtuv3224tbEwAAgNvcCjcpKSkuF+6TpL///lsbNmwodlEAAADuKtJhqZ9++snx86+//qr09HTHfZvNpuTkZEVERJRcdQAAAEVUpHDTsmVLWSwWWSyWAg8/lS9fXm+//XaJFQcAAFBURQo3+/fvl2EYqlOnjjZv3qyqVas6lvn5+Sk0NFTe3t4lXiQAAEBhFSnc1KxZU7m5uRo4cKCuu+461axZ80rVBQAA4JYiTyj29fXV8uXLr0QtAAAAxebW2VK9e/fWihUrSrgUAACA4nPrIn7169fXhAkTtHHjRkVFRalChQpOy4cPH14ixQEAABSVW+EmMTFRlStX1tatW7V161anZRaLhXADAAA8xq3DUvv377/o7Y8//ijy9mbNmqVatWqpXLlyatOmjTZv3lyo9RYtWiSLxaI+ffoU+TEBAIA5uRVuLmQYhgzDcHv9xYsXKz4+XuPGjdO2bdvUokULxcTE6NixY5dc78CBA3r22WfVvn17tx8bAACYj9vhZsGCBWrWrJnKly+v8uXLq3nz5vrwww+LvJ2pU6dq6NChGjx4sJo0aaLZs2crICBASUlJF13HZrPpgQce0Pjx41WnTh13hwAAAEzIrXAzdepUPf744+revbuWLFmiJUuW6I477tBjjz2madOmFXo7OTk52rp1q6Kjo/9XkJeXoqOjlZqaetH1JkyYoNDQUA0ZMsSd8gEAgIm5NaH47bff1rvvvqu4uDhHW69evXTDDTfolVde0ciRIwu1nRMnTshmsyksLMypPSwsTLt37y5wne+++06JiYnasWNHoR4jOztb2dnZjvtWq1WSlJubq9zc3EJtAwBwZfF5jMspymvErXBz9OhRtWvXzqW9Xbt2Onr0qDubLJTMzEw9+OCDmjt3rkJCQgq1TkJCgsaPH+/SvmbNGgUEBJR0iQDgYVfnPMRVq1Z5ugSUcVlZWYXu61a4qVevnpYsWaLRo0c7tS9evFj169cv9HZCQkLk7e2tjIwMp/aMjAxVq1bNpf/vv/+uAwcOqGfPno42u90uSfLx8dGePXtUt25dp3VGjRql+Ph4x32r1arIyEh17dpVgYGBha4VAK4GX87N9HQJbunevbunS0AZl3/kpTDcCjfjx49XbGysvv32W91yyy2SpI0bN2rdunVasmRJobfj5+enqKgorVu3znE6t91u17p16/Tkk0+69G/UqJF27tzp1Pbyyy8rMzNTM2bMUGRkpMs6/v7+8vf3d2n39fWVr69voWsFAFw5fB7jcoryGnEr3Nxzzz364YcfNG3aNMfXMDRu3FibN2/WjTfeWKRtxcfHa+DAgWrVqpVat26t6dOn69y5cxo8eLAkKS4uThEREUpISFC5cuXUtGlTp/UrV64sSS7tAADg2uRWuJGkqKgoffTRR8UuIDY2VsePH9fYsWOVnp6uli1bKjk52THJOC0tTV5exb4cDwAAuEZYDDevwGez2bR8+XLt2rVLktSkSRP17t1bPj5u56VSYbVaFRQUpDNnzjDnBoDpDH3npKdLcMvcYcGeLgFlXFH+fruVRH755Rf16tVL6enpatiwoSRp0qRJqlq1qr744gsOEQEAAI9x63jPww8/rBtuuEGHDh3Stm3btG3bNv35559q3ry5HnnkkZKuEQAAoNDc2nOzY8cObdmyRVWqVHG0ValSRa+//rpuvvnmEisOAACgqNzac9OgQQOXa9NI0rFjx1SvXr1iFwUAAOAut8JNQkKChg8frmXLlunQoUM6dOiQli1bpqefflqTJk2S1Wp13AAAAEqTW4elevToIUnq16+fLBaLJCn/pKv8qwcbhiGLxSKbzVYSdQIAABSKW+Hm66+/Luk6AAAASoRb4aZDhw4lXQcAAECJcPuKe3///bd++uknHTt2zPHllfl69epV7MIAAADc4Va4SU5OVlxcnE6cOOGyjHk2AADAk9w6W+qpp55S3759dfToUdntdqcbwQYAAHiSW+EmIyND8fHxji+3BAAAKCvcCjf33nuvUlJSSrgUAACA4nNrzs3MmTPVt29fbdiwQc2aNZOvr6/T8uHDh5dIcQAAAEXlVrj5+OOPtWbNGpUrV04pKSmOC/lJ5ycUE24AAICnuBVuXnrpJY0fP14vvviivLzcOrIFAABwRbiVTHJychQbG0uwAQAAZY5b6WTgwIFavHhxSdcCAABQbG4dlrLZbHrzzTe1evVqNW/e3GVC8dSpU0ukOAAAgKJyK9zs3LlTN954oyTp559/LtGCAAAAioNvBQcAAKZSpHBz9913X7aPxWLRJ5984nZBAAAAxVGkcBMUFHSl6gAAACgRRQo38+bNu1J1AAAAlAguVAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEylTISbWbNmqVatWipXrpzatGmjzZs3X7Tv3Llz1b59e1WpUkVVqlRRdHT0JfsDAIBri8fDzeLFixUfH69x48Zp27ZtatGihWJiYnTs2LEC+6ekpKh///76+uuvlZqaqsjISHXt2lWHDx8u5coBAEBZZDEMw/BkAW3atNHNN9+smTNnSpLsdrsiIyP11FNP6cUXX7zs+jabTVWqVNHMmTMVFxd32f5Wq1VBQUE6c+aMAgMDi10/AJQlQ9856ekS3DJ3WLCnS0AZV5S/3z6lVFOBcnJytHXrVo0aNcrR5uXlpejoaKWmphZqG1lZWcrNzVVwcMFvjOzsbGVnZzvuW61WSVJubq5yc3OLUT0AoKTweYzLKcprxKPh5sSJE7LZbAoLC3NqDwsL0+7duwu1jRdeeEHh4eGKjo4ucHlCQoLGjx/v0r5mzRoFBAQUvWgAKNPae7oAt6xatcrTJaCMy8rKKnRfj4ab4nrjjTe0aNEipaSkqFy5cgX2GTVqlOLj4x33rVarY54Oh6UAmM2XczM9XYJbunfv7ukSUMblH3kpDI+Gm5CQEHl7eysjI8OpPSMjQ9WqVbvkupMnT9Ybb7yhr776Ss2bN79oP39/f/n7+7u0+/r6ytfX173CAQAlis9jXE5RXiMePVvKz89PUVFRWrdunaPNbrdr3bp1atu27UXXe/PNN/Xqq68qOTlZrVq1Ko1SAQDAVcLjh6Xi4+M1cOBAtWrVSq1bt9b06dN17tw5DR48WJIUFxeniIgIJSQkSJImTZqksWPHauHChapVq5bS09MlSRUrVlTFihU9Ng4AAFA2eDzcxMbG6vjx4xo7dqzS09PVsmVLJScnOyYZp6WlycvrfzuY3n33XeXk5Ojee+912s64ceP0yiuvlGbpAACgDPL4dW5KG9e5AWBmXOcGZlWUv98ev0IxAABASSLcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAU/HxdAEAUBqGvnPS0yW4Ze6wYE+XAFx12HMDAABMhXADAABMhXADAABMhXADAABMhXADAABMhbOlgGscZxEBMBv23AAAAFMh3AAAAFMpE+Fm1qxZqlWrlsqVK6c2bdpo8+bNl+y/dOlSNWrUSOXKlVOzZs20atWqUqoUAACUdR4PN4sXL1Z8fLzGjRunbdu2qUWLFoqJidGxY8cK7L9p0yb1799fQ4YM0fbt29WnTx/16dNHP//8cylXDgAAyiKPh5upU6dq6NChGjx4sJo0aaLZs2crICBASUlJBfafMWOG7rjjDj333HNq3LixXn31Vd10002aOXNmKVcOAADKIo+eLZWTk6OtW7dq1KhRjjYvLy9FR0crNTW1wHVSU1MVHx/v1BYTE6MVK1YU2D87O1vZ2dmO+1arVZKUm5ur3NzcYo4AgKdcK+9fxgmcV5TXiEfDzYkTJ2Sz2RQWFubUHhYWpt27dxe4Tnp6eoH909PTC+yfkJCg8ePHu7SvWbNGAQEBblZ+cV8ebl/i2ywNPSI2FKn/tTDOq3WMUtHG2SPiChZyBRV1qh3jLNuKOs6r9f3JZ5D7srKyCt3X9Ne5GTVqlNOeHqvVqsjISHXt2lWBgYEl/nhfzs0s8W2Whu7duxet/xWq48orfOVX6+9SKvrvE7jaXK3vz6K8N6/WMUpX5jMo/8hLYXg03ISEhMjb21sZGRlO7RkZGapWrVqB61SrVq1I/f39/eXv7+/S7uvrK19fXzcrNx+eC1dcJA5ASbtWPmuvxDiLsk2PTij28/NTVFSU1q1b52iz2+1at26d2rZtW+A6bdu2deovSWvXrr1ofwAAcG3x+GGp+Ph4DRw4UK1atVLr1q01ffp0nTt3ToMHD5YkxcXFKSIiQgkJCZKkESNGqEOHDpoyZYruvPNOLVq0SFu2bNF7773nyWEAAIAywuPhJjY2VsePH9fYsWOVnp6uli1bKjk52TFpOC0tTV5e/9vB1K5dOy1cuFAvv/yyRo8erfr162vFihVq2rSpp4YAAADKEI+HG0l68skn9eSTTxa4LCUlxaWtb9++6tu37xWuCgAAXI08fhE/AACAklQm9tyYCWfYAADgWey5AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApuLj6QIAACiqucOCPV0CyjD23AAAAFMh3AAAAFPhsBQAAGUQh97cx54bAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKj6eLqC0GYYhSbJarR6uBAAAFFb+3+38v+OXcs2Fm8zMTElSZGSkhysBAABFlZmZqaCgoEv2sRiFiUAmYrfbdeTIEVWqVEkWi8XT5RSa1WpVZGSk/vzzTwUGBnq6nCuGcZrHtTBGiXGaDeMsuwzDUGZmpsLDw+XldelZNdfcnhsvLy/VqFHD02W4LTAw8Kp5IRYH4zSPa2GMEuM0G8ZZNl1uj00+JhQDAABTIdwAAABTIdxcJfz9/TVu3Dj5+/t7upQrinGax7UwRolxmg3jNIdrbkIxAAAwN/bcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHclAGDBg2SxWKRxWKRr6+vwsLC1KVLFyUlJclutzv61apVS9OnT3fc//HHH9WrVy+FhoaqXLlyqlWrlmJjY3Xs2DEPjOLSBg0apD59+lyyz6FDh+Tn56emTZs62l555RXHc3OxW1lwqfH99ddfGjdunBo0aCB/f3+FhISob9+++uWXX5z65Y/1sccec2rfsWOHLBaLDhw4cIWqL7r09HQ99dRTqlOnjvz9/RUZGamePXtq3bp1Tv0SEhLk7e2tt956y9FWq1atS/4+Bw0aVMqjcXbh+/HC2x133OFSf/ny5VWrVi3169dP69evL3B7f/31l4KDgxUSEqLs7OzSHEqhpKamytvbW3feeadT+4EDB5zGHxwcrA4dOmjDhg1O/S72Hm3UqFFpDuOyzD7Onj17Ol6j/7RhwwZZLBb99NNPkqRHH31U3t7eWrp0qUvfV155RS1btrySpZYKwk0Zcccdd+jo0aM6cOCA/u///k+dOnXSiBEj1KNHD+Xl5bn0P378uDp37qzg4GCtXr1au3bt0rx58xQeHq5z5855YATFN3/+fPXr109Wq1U//PCDJOnZZ5/V0aNHHbcaNWpowoQJTm1lWXZ2tqKjo5WUlKTXXntNe/fu1apVq5SXl6c2bdro+++/d+pfrlw5JSYm6rfffvNQxZd34MABRUVFaf369Xrrrbe0c+dOJScnq1OnTnriiSec+iYlJen5559XUlKSo+0///mP43f3ySefSJL27NnjaJsxY0apjqcg+e/HC28ff/yxY3n+a3DPnj1asGCBKleurOjoaL3++usu2/rkk090ww03qFGjRlqxYkUpjqJwEhMT9dRTT+nbb7/VkSNHXJZ/9dVXOnr0qL799luFh4erR48eysjIcOpzww03uDxf3333XWkNoVDMPs4hQ4Zo7dq1OnTokMuyefPmqVWrVmrevLmysrK0aNEil/el6RjwuIEDBxq9e/d2aV+3bp0hyZg7d65hGIZRs2ZNY9q0aYZhGMby5csNHx8fIzc3txQrdd/FxpjPbrcbderUMZKTk40XXnjBGDp0aIH9LnwOypKLje+NN94wLBaLsWPHDqd2m81mtGrVymjSpIlht9sNwzCMcePGGS1atDC6dOli9O3b19F3+/bthiRj//79V3IIhdatWzcjIiLCOHv2rMuyU6dOOX5OSUkxIiIijJycHCM8PNzYuHGjS/+vv/7akOS0nqdd7rV6sdfg2LFjDS8vL2P37t1O7R07djRmz55tvPvuu0aXLl1KuNriyczMNCpWrGjs3r3biI2NNV5//XXHsv379xuSjO3btzvafvrpJ0OS8dlnnzna8l+3Zdm1MM7c3FwjLCzMePXVV53a88f+7rvvGoZhGPPnzzf+9a9/GadPnzYCAgKMtLQ0p/5lfZyFxZ6bMuz2229XixYt9Omnn7osq1atmvLy8rR8+fJCff17Wff1118rKytL0dHRGjBggBYtWnTV7oG60MKFC9WlSxe1aNHCqd3Ly0sjR47Ur7/+qh9//NFp2RtvvKFPPvlEW7ZsKc1SC+XkyZNKTk7WE088oQoVKrgsr1y5suPnxMRE9e/fX76+vurfv78SExNLsdLSN2LECBmGoc8++8zR9vvvvys1NVX9+vVTv379tGHDBh08eNCDVTpbsmSJGjVqpIYNG2rAgAFKSkq66OfJX3/9pQULFkiS/Pz8SrPMYrsWxunj46O4uDjNnz/faWxLly6VzWZT//79JZ1/Xw4YMEBBQUHq1q2b5s+f76GKryzCTRnXqFGjAuda/Otf/9Lo0aN1//33KyQkRN26ddNbb73lshv1apGYmKj77rtP3t7eatq0qerUqVPg8eCrzd69e9W4ceMCl+W3792716n9pptuUr9+/fTCCy9c8fqKat++fTIM47LzDKxWq5YtW6YBAwZIkgYMGKAlS5bo7NmzpVFmsX355ZeqWLGi023ixImXXCc4OFihoaFO79ekpCR169ZNVapUUXBwsGJiYjRv3rwrXH3h5f+hk84fijtz5oy++eYbpz7t2rVTxYoVVaFCBU2ePFlRUVHq3LmzU5+dO3e6PF//nDvmSdfKOB966CH9/vvvTmObN2+e7rnnHgUFBem3337T999/r9jYWEnn35fz5s0zxT/I/0S4KeMMw7jopNnXX39d6enpmj17tm644QbNnj1bjRo10s6dO0u5yuI5ffq0Pv30U8eHj3T+TWeW//Td+eB47bXXtGHDBq1Zs+YKVOS+wo7l448/Vt26dR17rFq2bKmaNWtq8eLFV7K8EtOpUyft2LHD6VaYP2IXvl9tNps++OADl9f1/PnznU4U8JQ9e/Zo8+bNjv/ofXx8FBsb6/K+W7x4sbZv365PPvlE9erV0/z58+Xr6+vUp2HDhi7P14QJE0ptLJdyrYxTOv/PcLt27Rxzafbt26cNGzZoyJAhks6H7ZiYGIWEhEiSunfvrjNnzlx0MvzVzMfTBeDSdu3apdq1a190+XXXXae+ffuqb9++mjhxom688UZNnjxZH3zwQSlWWTwLFy7U33//rTZt2jjaDMOQ3W7X3r171aBBAw9WVzwNGjTQrl27ClyW317Q+OrWrauhQ4fqxRdfLFMhr379+rJYLNq9e/cl+yUmJuqXX36Rj8//PmLsdruSkpIcH7RlWYUKFVSvXr0irfPf//5Xx48fd7xfV69ercOHDzv+S85ns9m0bt06denSpcTqdUdiYqLy8vIUHh7uaDMMQ/7+/po5c6ajLTIyUvXr11f9+vWVl5enu+66Sz///LPTdxL5+fkV+fkqLdfKOPMNGTJETz31lGbNmqV58+apbt266tChgyNsp6enO70vbTabkpKSXPZSXe3Yc1OGrV+/Xjt37tQ999xTqP5+fn6qW7fuVTdXJTExUc8884zTf0M//vij2rdvf9XP5r/vvvv01VdfucyrsdvtmjZtmpo0aeIyHyff2LFjtXfvXi1atKg0Si2U/EMrs2bNKvB1dvr0ae3cuVNbtmxRSkqK0+80JSVFqamplw1GV6sZM2bIy8vLcUmA/EOt//xP/7777vN4YM3Ly9OCBQs0ZcoUl/ddeHi405lhF7r33nvl4+Ojd955p5Qrds+1Ms4L9evXT15eXlq4cKEWLFighx56SBaLRatWrVJmZqa2b9/u9Fx8/PHH+vTTT3X69GlPl16i2HNTRmRnZys9PV02m00ZGRlKTk5WQkKCevToobi4OJf+X375pRYtWqT77rtPDRo0kGEY+uKLL7Rq1aoydUz/QmfOnNGOHTuc2jIzM7Vt2zb9+9//dpnH0b9/f02YMEGvvfaa038aZVVB4xswYIA+++wz9ezZU1OmTFGbNm2UkZGhiRMnateuXfrqq68uetgxLCxM8fHxTteIKQtmzZqlW265Ra1bt9aECRPUvHlz5eXlae3atXr33XcVExOj1q1b67bbbnNZ9+abb1ZiYmKZG9M/5b8fL+Tj4+PYnZ+Zman09HTl5uZq//79+uijj/T+++8rISFB9erV0/Hjx/XFF1/o888/d7pukyTFxcXprrvu0smTJxUcHFxqY7rQl19+qVOnTmnIkCEKCgpyWnbPPfcoMTGxwGumWCwWDR8+XK+88ooeffRRBQQESDofIv75fFksFoWFhV25QRTCtTLOC1WsWFGxsbEaNWqUrFar47pRiYmJuvPOO13+mWrSpIlGjhypf//7345LOfz1118un2WVKlVS3bp1S2MIJcMDZ2jhHwYOHGhIMiQZPj4+RtWqVY3o6GgjKSnJsNlsjn4XnoL6+++/G0OHDjUaNGhglC9f3qhcubJx8803G/PmzfPMIC7jwjFeeBs0aJDRpEmTAtc5evSo4eXl5XQ6Zlk+Fbyg8Q0ZMsQ4d+6c8dJLLxn16tUzfH19jeDgYOOee+4xdu7c6bSNgk7BPHPmjBESElKmTgU3DMM4cuSI8cQTTxg1a9Y0/Pz8jIiICKNXr17G6tWrjeuuu8548803C1xv0qRJRmhoqJGTk2MYRtk9Fbyg32XDhg0Nwzj/Gsxv8/PzM66//nqjX79+xvr16x3bmDx5slG5cmXHOC+UnZ1tVK5c2ZgxY0apjemfevToYXTv3r3AZT/88IMhyfjxxx9dTpE2DMM4d+6cUaVKFWPSpEmGYZx/3Rb0fPn7+1/pYVzWtTLOf9q0aZMhyTH29PR0w8fHx1iyZEmB/R9//HHjxhtvNAzj4uPs3LlzqdVfEiyGYcJp0gAA4JrFnBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAVy2LxaIVK1YUuv8rr7yili1bXrLPoEGDHF+hAODqRLgBcEX17NmzwEvcS9KGDRtksVj0008/ubXto0ePqlu3bsUpD4AJEW4AXFFDhgzR2rVrdejQIZdl8+bNU6tWrdS8efMibTMnJ0eSVK1aNadvbQYAiXAD4Arr0aOHqlatqvnz5zu1nz17VkuXLlWfPn3Uv39/RUREKCAgQM2aNXP5tuaOHTvqySef1NNPP62QkBDFxMRIcj0s9cILL6hBgwYKCAhQnTp1NGbMGOXm5rrUNGfOHEVGRiogIED9+vXTmTNnLlq/3W5XQkKCateurfLly6tFixZatmyZ+08IgCuOcAPgivLx8VFcXJzmz5+vC7/KbunSpbLZbBowYICioqK0cuVK/fzzz3rkkUf04IMPavPmzU7b+eCDD+Tn56eNGzdq9uzZBT5WpUqVNH/+fP3666+aMWOG5s6dq2nTpjn12bdvn5YsWaIvvvhCycnJ2r59u4YNG3bR+hMSErRgwQLNnj1bv/zyi0aOHKkBAwbom2++KcazAuBK4oszAVxxu3fvVuPGjfX111+rY8eOkqTbbrtNNWvW1IcffujSv0ePHmrUqJEmT54s6fyeG6vVqm3btjn1s1gsWr58+UUnAE+ePFmLFi3Sli1bJJ2fUPzaa6/p4MGDioiIkCQlJyfrzjvv1OHDh1WtWjUNGjRIp0+f1ooVK5Sdna3g4GB99dVXatu2rWO7Dz/8sLKysrRw4cLiPjUArgAfTxcAwPwaNWqkdu3aKSkpSR07dtS+ffu0YcMGTZgwQTabTRMnTtSSJUt0+PBh5eTkKDs7WwEBAU7biIqKuuzjLF68WP/v//0//f777zp79qzy8vIUGBjo1Of66693BBtJatu2rex2u/bs2aNq1ao59d23b5+ysrLUpUsXp/acnBzdeOONRX0aAJQSwg2AUjFkyBA99dRTmjVrlubNm6e6deuqQ4cOmjRpkmbMmKHp06erWbNmqlChgp5++mnHpOF8FSpUuOT2U1NT9cADD2j8+PGKiYlRUFCQFi1apClTprhd89mzZyVJK1eudApEkpjIDJRhhBsApaJfv34aMWKEFi5cqAULFujxxx+XxWLRxo0b1bt3bw0YMEDS+Qm8e/fuVZMmTYq0/U2bNqlmzZp66aWXHG0HDx506ZeWlqYjR44oPDxckvT999/Ly8tLDRs2dOnbpEkT+fv7Ky0tTR06dChSPQA8h3ADoFRUrFhRsbGxGjVqlKxWqwYNGiRJql+/vpYtW6ZNmzapSpUqmjp1qjIyMoocburXr6+0tDQtWrRIN998s1auXKnly5e79CtXrpwGDhyoyZMny2q1avjw4erXr5/LISnp/ATlZ599ViNHjpTdbtett96qM2fOaOPGjQoMDNTAgQPdei4AXFmcLQWg1AwZMkSnTp1STEyMY8/Jyy+/rJtuukkxMTHq2LGjqlWr5tYVgnv16qWRI0fqySefVMuWLbVp0yaNGTPGpV+9evV09913q3v37uratauaN2+ud95556LbffXVVzVmzBglJCSocePGuuOOO7Ry5UrVrl27yDUCKB2cLQUAAEyFPTcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBU/j957AIeEgkOnAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('Loadings PC 2')\n",
    "ax.bar(range(1,9),data_pca.components_[1], color='cornflowerblue')\n",
    "ax.set_ylabel('Importancia')\n",
    "ax.set_xlabel('Variable')\n",
    "ax.set_xticks(range(1,9),[trainer_data.columns[i][:3].upper() for i in range(8)])\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "#add horizontal gridlines behind bars in the plot\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(axis='y')\n",
    "\n",
    "#display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(axis='y')\n",
    "plt.title('Loadings PC 1')\n",
    "plt.bar(range(1,9),data_pca.components_[0] )\n",
    "plt.ylabel('Importancia')\n",
    "plt.xlabel('Variable')\n",
    "plt.xticks(range(1,9),[trainer_data.columns[i][:3].upper() for i in range(8)])\n",
    "plt.legend(loc='upper left')\n",
    "#plt.axisbelow(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=list(range(1,9)), y=data_pca.components_[0])\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = list(range(1,9)),\n",
    "        ticktext = [trainer_data.columns[i][:3].upper() for i in range(8)]\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xin = Input(shape=(8,),name='In')\n",
    "#X = Dense(7,activation='relu')(Xin)\n",
    "#X = Dense(7,activation='relu')(X)\n",
    "#X = Dense(7,activation='relu')(X)\n",
    "#X = Dense(7,activation='relu')(X)\n",
    "X = Dense(10)(Xin)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(10)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(10)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(10)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(10)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(10)(X)\n",
    "#X = Dense(7,activation=tf.keras.activations.softsign)(X)\n",
    "#X = Dense(7,activation=tf.keras.activations.softsign)(X)\n",
    "X = Dense(8)(X)\n",
    "completion = LeakyReLU()(X)\n",
    "\n",
    "S4D_jengi = Model(inputs = Xin, outputs = [completion], name = \"S4D_Jengi\")\n",
    "\n",
    "#full_pca_inference = Concatenate(axis=1, name = 'completion')([Xin,completion])\n",
    "full_pca_inference = Add(name = 'completion')([Xin,completion])\n",
    "Yout = Lambda(lambda x : tf.transpose(data_pca.components_[:5,:]@tf.transpose(x)))(full_pca_inference)\n",
    "\n",
    "Jengi_train = Model(inputs = Xin, outputs = [Yout], name = 'PCA_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S4D_jengi.save_weights(\"S4D_Her0/S4D_jengi.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "22/22 [==============================] - 1s 12ms/step - loss: 26.8751 - accuracy: 0.9999 - val_loss: 34.0407 - val_accuracy: 0.9998\n",
      "Epoch 2/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.3411 - accuracy: 0.9999 - val_loss: 33.8428 - val_accuracy: 0.9998\n",
      "Epoch 3/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.3540 - accuracy: 0.9999 - val_loss: 33.0763 - val_accuracy: 0.9998\n",
      "Epoch 4/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.2978 - accuracy: 0.9999 - val_loss: 33.4816 - val_accuracy: 0.9998\n",
      "Epoch 5/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.2419 - accuracy: 0.9999 - val_loss: 33.3524 - val_accuracy: 0.9998\n",
      "Epoch 6/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.2963 - accuracy: 0.9999 - val_loss: 33.4380 - val_accuracy: 0.9998\n",
      "Epoch 7/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.4976 - accuracy: 0.9999 - val_loss: 34.2315 - val_accuracy: 0.9998\n",
      "Epoch 8/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.2887 - accuracy: 0.9999 - val_loss: 33.3423 - val_accuracy: 0.9998\n",
      "Epoch 9/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.3261 - accuracy: 0.9999 - val_loss: 33.0111 - val_accuracy: 0.9998\n",
      "Epoch 10/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.2816 - accuracy: 0.9999 - val_loss: 33.7182 - val_accuracy: 0.9998\n",
      "Epoch 11/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.3023 - accuracy: 0.9999 - val_loss: 33.1423 - val_accuracy: 0.9998\n",
      "Epoch 12/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.4662 - accuracy: 0.9999 - val_loss: 33.9497 - val_accuracy: 0.9998\n",
      "Epoch 13/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.7045 - accuracy: 0.9999 - val_loss: 33.5388 - val_accuracy: 0.9998\n",
      "Epoch 14/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 26.3580 - accuracy: 0.9999 - val_loss: 33.1895 - val_accuracy: 0.9998\n",
      "Epoch 15/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1879 - accuracy: 0.9999 - val_loss: 33.1169 - val_accuracy: 0.9998\n",
      "Epoch 16/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.2007 - accuracy: 0.9999 - val_loss: 33.4656 - val_accuracy: 0.9998\n",
      "Epoch 17/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1625 - accuracy: 0.9999 - val_loss: 33.0800 - val_accuracy: 0.9998\n",
      "Epoch 18/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1659 - accuracy: 0.9999 - val_loss: 32.8390 - val_accuracy: 0.9998\n",
      "Epoch 19/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1691 - accuracy: 0.9999 - val_loss: 33.1492 - val_accuracy: 0.9998\n",
      "Epoch 20/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.1152 - accuracy: 0.9999 - val_loss: 32.5824 - val_accuracy: 0.9998\n",
      "Epoch 21/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 26.2304 - accuracy: 0.9999 - val_loss: 33.0827 - val_accuracy: 0.9998\n",
      "Epoch 22/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1502 - accuracy: 0.9999 - val_loss: 33.1495 - val_accuracy: 0.9998\n",
      "Epoch 23/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.4537 - accuracy: 0.9999 - val_loss: 32.6535 - val_accuracy: 0.9998\n",
      "Epoch 24/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.2036 - accuracy: 0.9999 - val_loss: 33.1361 - val_accuracy: 0.9998\n",
      "Epoch 25/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1072 - accuracy: 0.9999 - val_loss: 33.1311 - val_accuracy: 0.9998\n",
      "Epoch 26/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.3714 - accuracy: 0.9999 - val_loss: 32.5917 - val_accuracy: 0.9998\n",
      "Epoch 27/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.2673 - accuracy: 0.9999 - val_loss: 33.1684 - val_accuracy: 0.9998\n",
      "Epoch 28/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 26.1340 - accuracy: 0.9999 - val_loss: 33.1669 - val_accuracy: 0.9998\n",
      "Epoch 29/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1147 - accuracy: 0.9999 - val_loss: 33.0145 - val_accuracy: 0.9998\n",
      "Epoch 30/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.1403 - accuracy: 0.9999 - val_loss: 33.1475 - val_accuracy: 0.9998\n",
      "Epoch 31/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.3447 - accuracy: 0.9999 - val_loss: 32.5776 - val_accuracy: 0.9998\n",
      "Epoch 32/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.0769 - accuracy: 0.9999 - val_loss: 32.9390 - val_accuracy: 0.9998\n",
      "Epoch 33/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 26.0182 - accuracy: 0.9999 - val_loss: 32.7933 - val_accuracy: 0.9998\n",
      "Epoch 34/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 26.3067 - accuracy: 0.9999 - val_loss: 32.6774 - val_accuracy: 0.9998\n",
      "Epoch 35/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.1117 - accuracy: 0.9999 - val_loss: 32.5213 - val_accuracy: 0.9998\n",
      "Epoch 36/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.1478 - accuracy: 0.9999 - val_loss: 32.3471 - val_accuracy: 0.9998\n",
      "Epoch 37/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.2070 - accuracy: 0.9999 - val_loss: 32.2509 - val_accuracy: 0.9998\n",
      "Epoch 38/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.0766 - accuracy: 0.9999 - val_loss: 32.5019 - val_accuracy: 0.9998\n",
      "Epoch 39/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.9964 - accuracy: 0.9999 - val_loss: 32.6788 - val_accuracy: 0.9998\n",
      "Epoch 40/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.0864 - accuracy: 0.9999 - val_loss: 32.7545 - val_accuracy: 0.9998\n",
      "Epoch 41/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.9664 - accuracy: 0.9999 - val_loss: 32.3463 - val_accuracy: 0.9998\n",
      "Epoch 42/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.9884 - accuracy: 0.9999 - val_loss: 32.4965 - val_accuracy: 0.9998\n",
      "Epoch 43/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.0416 - accuracy: 0.9999 - val_loss: 32.5256 - val_accuracy: 0.9998\n",
      "Epoch 44/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.9876 - accuracy: 0.9999 - val_loss: 32.4350 - val_accuracy: 0.9998\n",
      "Epoch 45/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.9998 - accuracy: 0.9999 - val_loss: 32.2663 - val_accuracy: 0.9998\n",
      "Epoch 46/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.9969 - accuracy: 0.9999 - val_loss: 32.4493 - val_accuracy: 0.9998\n",
      "Epoch 47/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.9807 - accuracy: 0.9999 - val_loss: 32.4302 - val_accuracy: 0.9998\n",
      "Epoch 48/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.9800 - accuracy: 0.9999 - val_loss: 32.1693 - val_accuracy: 0.9998\n",
      "Epoch 49/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.9223 - accuracy: 0.9999 - val_loss: 32.1261 - val_accuracy: 0.9998\n",
      "Epoch 50/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.8982 - accuracy: 0.9999 - val_loss: 32.3294 - val_accuracy: 0.9998\n",
      "Epoch 51/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.9421 - accuracy: 0.9999 - val_loss: 32.4224 - val_accuracy: 0.9998\n",
      "Epoch 52/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.0882 - accuracy: 0.9999 - val_loss: 32.2882 - val_accuracy: 0.9998\n",
      "Epoch 53/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.9140 - accuracy: 0.9999 - val_loss: 32.0626 - val_accuracy: 0.9998\n",
      "Epoch 54/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.9753 - accuracy: 0.9999 - val_loss: 33.3972 - val_accuracy: 0.9998\n",
      "Epoch 55/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.0558 - accuracy: 0.9999 - val_loss: 32.8700 - val_accuracy: 0.9998\n",
      "Epoch 56/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.0104 - accuracy: 0.9999 - val_loss: 32.5228 - val_accuracy: 0.9998\n",
      "Epoch 57/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.9085 - accuracy: 0.9999 - val_loss: 32.2728 - val_accuracy: 0.9998\n",
      "Epoch 58/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.9224 - accuracy: 0.9999 - val_loss: 32.4771 - val_accuracy: 0.9998\n",
      "Epoch 59/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.9044 - accuracy: 0.9999 - val_loss: 31.9312 - val_accuracy: 0.9998\n",
      "Epoch 60/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.9796 - accuracy: 0.9999 - val_loss: 32.0554 - val_accuracy: 0.9998\n",
      "Epoch 61/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.8582 - accuracy: 0.9999 - val_loss: 32.4924 - val_accuracy: 0.9998\n",
      "Epoch 62/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.8598 - accuracy: 0.9999 - val_loss: 32.5258 - val_accuracy: 0.9998\n",
      "Epoch 63/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.8421 - accuracy: 0.9999 - val_loss: 32.3207 - val_accuracy: 0.9998\n",
      "Epoch 64/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.8217 - accuracy: 0.9999 - val_loss: 32.0488 - val_accuracy: 0.9998\n",
      "Epoch 65/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.9512 - accuracy: 0.9999 - val_loss: 32.0008 - val_accuracy: 0.9998\n",
      "Epoch 66/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.0387 - accuracy: 0.9999 - val_loss: 31.6077 - val_accuracy: 0.9998\n",
      "Epoch 67/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.9223 - accuracy: 0.9999 - val_loss: 31.9571 - val_accuracy: 0.9998\n",
      "Epoch 68/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.0564 - accuracy: 0.9999 - val_loss: 33.3857 - val_accuracy: 0.9998\n",
      "Epoch 69/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 26.1045 - accuracy: 0.9999 - val_loss: 31.6220 - val_accuracy: 0.9998\n",
      "Epoch 70/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.7943 - accuracy: 0.9999 - val_loss: 31.8695 - val_accuracy: 0.9998\n",
      "Epoch 71/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.8223 - accuracy: 0.9999 - val_loss: 31.7956 - val_accuracy: 0.9998\n",
      "Epoch 72/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.9307 - accuracy: 0.9999 - val_loss: 32.2393 - val_accuracy: 0.9998\n",
      "Epoch 73/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.9113 - accuracy: 0.9999 - val_loss: 31.6538 - val_accuracy: 0.9998\n",
      "Epoch 74/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.7690 - accuracy: 0.9999 - val_loss: 31.9298 - val_accuracy: 0.9998\n",
      "Epoch 75/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.7973 - accuracy: 0.9999 - val_loss: 31.7448 - val_accuracy: 0.9998\n",
      "Epoch 76/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7722 - accuracy: 0.9999 - val_loss: 31.7906 - val_accuracy: 0.9998\n",
      "Epoch 77/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.7595 - accuracy: 0.9999 - val_loss: 31.7671 - val_accuracy: 0.9998\n",
      "Epoch 78/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7140 - accuracy: 0.9999 - val_loss: 31.8368 - val_accuracy: 0.9998\n",
      "Epoch 79/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7679 - accuracy: 0.9999 - val_loss: 31.3179 - val_accuracy: 0.9998\n",
      "Epoch 80/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.8194 - accuracy: 0.9999 - val_loss: 31.6274 - val_accuracy: 0.9998\n",
      "Epoch 81/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 26.0109 - accuracy: 0.9999 - val_loss: 32.1722 - val_accuracy: 0.9998\n",
      "Epoch 82/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7977 - accuracy: 0.9999 - val_loss: 31.6998 - val_accuracy: 0.9998\n",
      "Epoch 83/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.7841 - accuracy: 0.9999 - val_loss: 31.7309 - val_accuracy: 0.9998\n",
      "Epoch 84/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.8167 - accuracy: 0.9999 - val_loss: 31.6170 - val_accuracy: 0.9998\n",
      "Epoch 85/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.8945 - accuracy: 0.9999 - val_loss: 31.9770 - val_accuracy: 0.9998\n",
      "Epoch 86/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.8237 - accuracy: 0.9999 - val_loss: 31.3955 - val_accuracy: 0.9998\n",
      "Epoch 87/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.6654 - accuracy: 0.9999 - val_loss: 31.5503 - val_accuracy: 0.9998\n",
      "Epoch 88/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.8201 - accuracy: 0.9999 - val_loss: 31.4618 - val_accuracy: 0.9998\n",
      "Epoch 89/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.7988 - accuracy: 0.9999 - val_loss: 31.7184 - val_accuracy: 0.9998\n",
      "Epoch 90/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7141 - accuracy: 0.9999 - val_loss: 31.5436 - val_accuracy: 0.9998\n",
      "Epoch 91/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.6979 - accuracy: 0.9999 - val_loss: 31.6015 - val_accuracy: 0.9998\n",
      "Epoch 92/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.8263 - accuracy: 0.9999 - val_loss: 31.7203 - val_accuracy: 0.9998\n",
      "Epoch 93/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.6706 - accuracy: 0.9999 - val_loss: 31.6037 - val_accuracy: 0.9998\n",
      "Epoch 94/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7363 - accuracy: 0.9999 - val_loss: 31.6709 - val_accuracy: 0.9998\n",
      "Epoch 95/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.8029 - accuracy: 0.9999 - val_loss: 32.2585 - val_accuracy: 0.9998\n",
      "Epoch 96/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.6824 - accuracy: 0.9999 - val_loss: 31.7892 - val_accuracy: 0.9998\n",
      "Epoch 97/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.7221 - accuracy: 0.9999 - val_loss: 31.4284 - val_accuracy: 0.9998\n",
      "Epoch 98/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.6383 - accuracy: 0.9999 - val_loss: 31.2243 - val_accuracy: 0.9998\n",
      "Epoch 99/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.6073 - accuracy: 0.9999 - val_loss: 31.7422 - val_accuracy: 0.9998\n",
      "Epoch 100/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.6607 - accuracy: 0.9999 - val_loss: 31.7362 - val_accuracy: 0.9998\n",
      "Epoch 101/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7074 - accuracy: 0.9999 - val_loss: 31.6281 - val_accuracy: 0.9998\n",
      "Epoch 102/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5602 - accuracy: 0.9999 - val_loss: 31.3451 - val_accuracy: 0.9998\n",
      "Epoch 103/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.5970 - accuracy: 0.9999 - val_loss: 31.5437 - val_accuracy: 0.9998\n",
      "Epoch 104/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.5760 - accuracy: 0.9999 - val_loss: 31.2672 - val_accuracy: 0.9998\n",
      "Epoch 105/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.6592 - accuracy: 0.9999 - val_loss: 31.1695 - val_accuracy: 0.9998\n",
      "Epoch 106/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5996 - accuracy: 0.9999 - val_loss: 31.5628 - val_accuracy: 0.9998\n",
      "Epoch 107/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7693 - accuracy: 0.9999 - val_loss: 31.2914 - val_accuracy: 0.9998\n",
      "Epoch 108/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 26.1121 - accuracy: 0.9999 - val_loss: 32.2264 - val_accuracy: 0.9998\n",
      "Epoch 109/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.8959 - accuracy: 0.9999 - val_loss: 30.8322 - val_accuracy: 0.9998\n",
      "Epoch 110/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5462 - accuracy: 0.9999 - val_loss: 30.9007 - val_accuracy: 0.9998\n",
      "Epoch 111/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.5779 - accuracy: 0.9999 - val_loss: 30.9042 - val_accuracy: 0.9998\n",
      "Epoch 112/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5278 - accuracy: 0.9999 - val_loss: 30.6509 - val_accuracy: 0.9998\n",
      "Epoch 113/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5218 - accuracy: 0.9999 - val_loss: 30.4820 - val_accuracy: 0.9998\n",
      "Epoch 114/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.4734 - accuracy: 0.9999 - val_loss: 30.4519 - val_accuracy: 0.9998\n",
      "Epoch 115/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7398 - accuracy: 0.9999 - val_loss: 31.1359 - val_accuracy: 0.9998\n",
      "Epoch 116/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5429 - accuracy: 0.9999 - val_loss: 30.5135 - val_accuracy: 0.9998\n",
      "Epoch 117/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.4820 - accuracy: 0.9999 - val_loss: 30.2706 - val_accuracy: 0.9998\n",
      "Epoch 118/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4152 - accuracy: 0.9999 - val_loss: 30.3935 - val_accuracy: 0.9998\n",
      "Epoch 119/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4709 - accuracy: 0.9999 - val_loss: 30.2084 - val_accuracy: 0.9998\n",
      "Epoch 120/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3559 - accuracy: 0.9999 - val_loss: 30.2706 - val_accuracy: 0.9998\n",
      "Epoch 121/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.4984 - accuracy: 0.9999 - val_loss: 30.4388 - val_accuracy: 0.9998\n",
      "Epoch 122/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4292 - accuracy: 0.9999 - val_loss: 30.3886 - val_accuracy: 0.9998\n",
      "Epoch 123/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4975 - accuracy: 0.9999 - val_loss: 30.0822 - val_accuracy: 0.9998\n",
      "Epoch 124/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.5431 - accuracy: 0.9999 - val_loss: 30.2785 - val_accuracy: 0.9998\n",
      "Epoch 125/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4101 - accuracy: 0.9999 - val_loss: 30.4980 - val_accuracy: 0.9998\n",
      "Epoch 126/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.4858 - accuracy: 0.9999 - val_loss: 30.3351 - val_accuracy: 0.9998\n",
      "Epoch 127/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.7839 - accuracy: 0.9999 - val_loss: 30.6320 - val_accuracy: 0.9998\n",
      "Epoch 128/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4373 - accuracy: 0.9999 - val_loss: 30.8981 - val_accuracy: 0.9998\n",
      "Epoch 129/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5413 - accuracy: 0.9999 - val_loss: 30.3185 - val_accuracy: 0.9998\n",
      "Epoch 130/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4935 - accuracy: 0.9999 - val_loss: 30.0365 - val_accuracy: 0.9998\n",
      "Epoch 131/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.4766 - accuracy: 0.9999 - val_loss: 30.0872 - val_accuracy: 0.9998\n",
      "Epoch 132/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3279 - accuracy: 0.9999 - val_loss: 30.2310 - val_accuracy: 0.9998\n",
      "Epoch 133/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5024 - accuracy: 0.9999 - val_loss: 29.8029 - val_accuracy: 0.9998\n",
      "Epoch 134/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.4107 - accuracy: 0.9999 - val_loss: 30.4796 - val_accuracy: 0.9998\n",
      "Epoch 135/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3840 - accuracy: 0.9999 - val_loss: 30.1632 - val_accuracy: 0.9998\n",
      "Epoch 136/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3557 - accuracy: 0.9999 - val_loss: 30.0949 - val_accuracy: 0.9998\n",
      "Epoch 137/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.3272 - accuracy: 0.9999 - val_loss: 29.7433 - val_accuracy: 0.9998\n",
      "Epoch 138/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3787 - accuracy: 0.9999 - val_loss: 30.1688 - val_accuracy: 0.9998\n",
      "Epoch 139/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3087 - accuracy: 0.9999 - val_loss: 29.9773 - val_accuracy: 0.9998\n",
      "Epoch 140/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3295 - accuracy: 0.9999 - val_loss: 29.9480 - val_accuracy: 0.9998\n",
      "Epoch 141/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3606 - accuracy: 0.9999 - val_loss: 29.8630 - val_accuracy: 0.9998\n",
      "Epoch 142/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.3359 - accuracy: 0.9999 - val_loss: 30.3837 - val_accuracy: 0.9998\n",
      "Epoch 143/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.4863 - accuracy: 0.9999 - val_loss: 29.8145 - val_accuracy: 0.9998\n",
      "Epoch 144/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4224 - accuracy: 0.9999 - val_loss: 30.1098 - val_accuracy: 0.9998\n",
      "Epoch 145/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4549 - accuracy: 0.9999 - val_loss: 30.0817 - val_accuracy: 0.9998\n",
      "Epoch 146/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.4919 - accuracy: 0.9999 - val_loss: 30.0798 - val_accuracy: 0.9998\n",
      "Epoch 147/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3595 - accuracy: 0.9999 - val_loss: 30.0399 - val_accuracy: 0.9998\n",
      "Epoch 148/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2902 - accuracy: 0.9999 - val_loss: 30.5774 - val_accuracy: 0.9998\n",
      "Epoch 149/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4099 - accuracy: 0.9999 - val_loss: 29.8339 - val_accuracy: 0.9998\n",
      "Epoch 150/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.3489 - accuracy: 0.9999 - val_loss: 30.0230 - val_accuracy: 0.9998\n",
      "Epoch 151/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.3321 - accuracy: 0.9999 - val_loss: 30.0813 - val_accuracy: 0.9998\n",
      "Epoch 152/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3594 - accuracy: 0.9999 - val_loss: 29.6226 - val_accuracy: 0.9998\n",
      "Epoch 153/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3012 - accuracy: 0.9999 - val_loss: 29.8314 - val_accuracy: 0.9998\n",
      "Epoch 154/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2314 - accuracy: 0.9999 - val_loss: 29.6644 - val_accuracy: 0.9998\n",
      "Epoch 155/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3077 - accuracy: 0.9999 - val_loss: 30.0797 - val_accuracy: 0.9998\n",
      "Epoch 156/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3509 - accuracy: 0.9999 - val_loss: 29.5975 - val_accuracy: 0.9998\n",
      "Epoch 157/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.5424 - accuracy: 0.9999 - val_loss: 29.6142 - val_accuracy: 0.9998\n",
      "Epoch 158/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3780 - accuracy: 0.9999 - val_loss: 29.8791 - val_accuracy: 0.9998\n",
      "Epoch 159/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2157 - accuracy: 0.9999 - val_loss: 29.6501 - val_accuracy: 0.9998\n",
      "Epoch 160/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2963 - accuracy: 0.9999 - val_loss: 29.5947 - val_accuracy: 0.9998\n",
      "Epoch 161/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2390 - accuracy: 0.9999 - val_loss: 29.7986 - val_accuracy: 0.9998\n",
      "Epoch 162/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.4908 - accuracy: 0.9999 - val_loss: 29.8334 - val_accuracy: 0.9998\n",
      "Epoch 163/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.5282 - accuracy: 0.9999 - val_loss: 29.5616 - val_accuracy: 0.9998\n",
      "Epoch 164/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2293 - accuracy: 0.9999 - val_loss: 29.9420 - val_accuracy: 0.9998\n",
      "Epoch 165/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3049 - accuracy: 0.9999 - val_loss: 29.7625 - val_accuracy: 0.9998\n",
      "Epoch 166/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.3529 - accuracy: 0.9999 - val_loss: 29.9504 - val_accuracy: 0.9998\n",
      "Epoch 167/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2473 - accuracy: 0.9999 - val_loss: 29.5827 - val_accuracy: 0.9998\n",
      "Epoch 168/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2508 - accuracy: 0.9999 - val_loss: 29.7595 - val_accuracy: 0.9998\n",
      "Epoch 169/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3044 - accuracy: 0.9999 - val_loss: 29.9317 - val_accuracy: 0.9998\n",
      "Epoch 170/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2628 - accuracy: 0.9999 - val_loss: 29.9031 - val_accuracy: 0.9998\n",
      "Epoch 171/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.4139 - accuracy: 0.9999 - val_loss: 29.1857 - val_accuracy: 0.9998\n",
      "Epoch 172/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.3958 - accuracy: 0.9999 - val_loss: 29.7969 - val_accuracy: 0.9998\n",
      "Epoch 173/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3935 - accuracy: 0.9999 - val_loss: 29.3114 - val_accuracy: 0.9998\n",
      "Epoch 174/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3697 - accuracy: 0.9999 - val_loss: 30.2716 - val_accuracy: 0.9998\n",
      "Epoch 175/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.2563 - accuracy: 0.9999 - val_loss: 29.6361 - val_accuracy: 0.9998\n",
      "Epoch 176/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2622 - accuracy: 0.9999 - val_loss: 29.9145 - val_accuracy: 0.9998\n",
      "Epoch 177/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3389 - accuracy: 0.9999 - val_loss: 29.3910 - val_accuracy: 0.9998\n",
      "Epoch 178/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2209 - accuracy: 0.9999 - val_loss: 29.6808 - val_accuracy: 0.9998\n",
      "Epoch 179/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2435 - accuracy: 0.9999 - val_loss: 29.1788 - val_accuracy: 0.9998\n",
      "Epoch 180/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2163 - accuracy: 0.9999 - val_loss: 29.6661 - val_accuracy: 0.9998\n",
      "Epoch 181/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1999 - accuracy: 0.9999 - val_loss: 29.2094 - val_accuracy: 0.9998\n",
      "Epoch 182/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2239 - accuracy: 0.9999 - val_loss: 29.3992 - val_accuracy: 0.9998\n",
      "Epoch 183/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2086 - accuracy: 0.9999 - val_loss: 29.3612 - val_accuracy: 0.9998\n",
      "Epoch 184/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1554 - accuracy: 0.9999 - val_loss: 29.2296 - val_accuracy: 0.9998\n",
      "Epoch 185/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2338 - accuracy: 0.9999 - val_loss: 29.5791 - val_accuracy: 0.9998\n",
      "Epoch 186/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2259 - accuracy: 0.9999 - val_loss: 29.1045 - val_accuracy: 0.9998\n",
      "Epoch 187/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.4150 - accuracy: 0.9999 - val_loss: 30.0796 - val_accuracy: 0.9998\n",
      "Epoch 188/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3257 - accuracy: 0.9999 - val_loss: 29.5724 - val_accuracy: 0.9998\n",
      "Epoch 189/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2353 - accuracy: 0.9999 - val_loss: 29.4791 - val_accuracy: 0.9998\n",
      "Epoch 190/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1647 - accuracy: 0.9999 - val_loss: 29.2756 - val_accuracy: 0.9998\n",
      "Epoch 191/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.2051 - accuracy: 0.9999 - val_loss: 29.2436 - val_accuracy: 0.9998\n",
      "Epoch 192/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2828 - accuracy: 0.9999 - val_loss: 29.6244 - val_accuracy: 0.9998\n",
      "Epoch 193/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1115 - accuracy: 0.9999 - val_loss: 29.1170 - val_accuracy: 0.9998\n",
      "Epoch 194/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1338 - accuracy: 0.9999 - val_loss: 29.3782 - val_accuracy: 0.9998\n",
      "Epoch 195/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.1698 - accuracy: 0.9999 - val_loss: 29.7057 - val_accuracy: 0.9998\n",
      "Epoch 196/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.6111 - accuracy: 0.9999 - val_loss: 29.2390 - val_accuracy: 0.9998\n",
      "Epoch 197/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1718 - accuracy: 0.9999 - val_loss: 29.2453 - val_accuracy: 0.9998\n",
      "Epoch 198/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1722 - accuracy: 0.9999 - val_loss: 29.3739 - val_accuracy: 0.9998\n",
      "Epoch 199/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2738 - accuracy: 0.9999 - val_loss: 29.2810 - val_accuracy: 0.9998\n",
      "Epoch 200/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2193 - accuracy: 0.9999 - val_loss: 29.3114 - val_accuracy: 0.9998\n",
      "Epoch 201/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1192 - accuracy: 0.9999 - val_loss: 29.2896 - val_accuracy: 0.9998\n",
      "Epoch 202/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2069 - accuracy: 0.9999 - val_loss: 29.4438 - val_accuracy: 0.9998\n",
      "Epoch 203/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1338 - accuracy: 0.9999 - val_loss: 29.1108 - val_accuracy: 0.9998\n",
      "Epoch 204/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.1070 - accuracy: 0.9999 - val_loss: 29.1679 - val_accuracy: 0.9998\n",
      "Epoch 205/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1203 - accuracy: 0.9999 - val_loss: 29.0782 - val_accuracy: 0.9998\n",
      "Epoch 206/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1296 - accuracy: 0.9999 - val_loss: 29.3239 - val_accuracy: 0.9998\n",
      "Epoch 207/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1467 - accuracy: 0.9999 - val_loss: 29.1962 - val_accuracy: 0.9998\n",
      "Epoch 208/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.1768 - accuracy: 0.9999 - val_loss: 29.5061 - val_accuracy: 0.9998\n",
      "Epoch 209/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1292 - accuracy: 0.9999 - val_loss: 29.3871 - val_accuracy: 0.9998\n",
      "Epoch 210/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0862 - accuracy: 0.9999 - val_loss: 29.2942 - val_accuracy: 0.9998\n",
      "Epoch 211/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.1447 - accuracy: 0.9999 - val_loss: 29.4223 - val_accuracy: 0.9998\n",
      "Epoch 212/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.4843 - accuracy: 0.9999 - val_loss: 29.7828 - val_accuracy: 0.9998\n",
      "Epoch 213/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.2115 - accuracy: 0.9999 - val_loss: 29.6630 - val_accuracy: 0.9998\n",
      "Epoch 214/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0547 - accuracy: 0.9999 - val_loss: 28.9994 - val_accuracy: 0.9998\n",
      "Epoch 215/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0907 - accuracy: 0.9999 - val_loss: 29.0227 - val_accuracy: 0.9998\n",
      "Epoch 216/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1149 - accuracy: 0.9999 - val_loss: 28.9327 - val_accuracy: 0.9998\n",
      "Epoch 217/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0577 - accuracy: 0.9999 - val_loss: 29.0090 - val_accuracy: 0.9998\n",
      "Epoch 218/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1119 - accuracy: 0.9999 - val_loss: 29.0280 - val_accuracy: 0.9998\n",
      "Epoch 219/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1597 - accuracy: 0.9999 - val_loss: 29.2883 - val_accuracy: 0.9998\n",
      "Epoch 220/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1340 - accuracy: 0.9999 - val_loss: 28.7861 - val_accuracy: 0.9998\n",
      "Epoch 221/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0585 - accuracy: 0.9999 - val_loss: 28.8539 - val_accuracy: 0.9998\n",
      "Epoch 222/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.0764 - accuracy: 0.9999 - val_loss: 28.8315 - val_accuracy: 0.9998\n",
      "Epoch 223/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1085 - accuracy: 0.9999 - val_loss: 28.8573 - val_accuracy: 0.9998\n",
      "Epoch 224/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0688 - accuracy: 0.9999 - val_loss: 28.8378 - val_accuracy: 0.9998\n",
      "Epoch 225/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0409 - accuracy: 0.9999 - val_loss: 28.7584 - val_accuracy: 0.9998\n",
      "Epoch 226/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0238 - accuracy: 0.9999 - val_loss: 28.9489 - val_accuracy: 0.9998\n",
      "Epoch 227/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0497 - accuracy: 0.9999 - val_loss: 28.9426 - val_accuracy: 0.9998\n",
      "Epoch 228/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.0324 - accuracy: 0.9999 - val_loss: 29.0352 - val_accuracy: 0.9998\n",
      "Epoch 229/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.1352 - accuracy: 0.9999 - val_loss: 29.1876 - val_accuracy: 0.9998\n",
      "Epoch 230/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0604 - accuracy: 0.9999 - val_loss: 29.4250 - val_accuracy: 0.9998\n",
      "Epoch 231/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.2657 - accuracy: 0.9999 - val_loss: 29.0158 - val_accuracy: 0.9998\n",
      "Epoch 232/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0758 - accuracy: 0.9999 - val_loss: 29.1049 - val_accuracy: 0.9998\n",
      "Epoch 233/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.0117 - accuracy: 0.9999 - val_loss: 28.6654 - val_accuracy: 0.9998\n",
      "Epoch 234/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.3068 - accuracy: 0.9999 - val_loss: 29.5131 - val_accuracy: 0.9998\n",
      "Epoch 235/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9892 - accuracy: 0.9999 - val_loss: 28.7458 - val_accuracy: 0.9998\n",
      "Epoch 236/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1361 - accuracy: 0.9999 - val_loss: 29.7246 - val_accuracy: 0.9998\n",
      "Epoch 237/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1230 - accuracy: 0.9999 - val_loss: 29.0584 - val_accuracy: 0.9998\n",
      "Epoch 238/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1111 - accuracy: 0.9999 - val_loss: 28.6748 - val_accuracy: 0.9998\n",
      "Epoch 239/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0349 - accuracy: 0.9999 - val_loss: 28.8669 - val_accuracy: 0.9998\n",
      "Epoch 240/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9646 - accuracy: 0.9999 - val_loss: 28.5963 - val_accuracy: 0.9998\n",
      "Epoch 241/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9955 - accuracy: 0.9999 - val_loss: 29.0394 - val_accuracy: 0.9998\n",
      "Epoch 242/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1441 - accuracy: 0.9999 - val_loss: 28.4588 - val_accuracy: 0.9998\n",
      "Epoch 243/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.9615 - accuracy: 0.9999 - val_loss: 29.3801 - val_accuracy: 0.9998\n",
      "Epoch 244/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.1691 - accuracy: 0.9999 - val_loss: 29.3432 - val_accuracy: 0.9998\n",
      "Epoch 245/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1229 - accuracy: 0.9999 - val_loss: 28.6138 - val_accuracy: 0.9998\n",
      "Epoch 246/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0466 - accuracy: 0.9999 - val_loss: 28.7296 - val_accuracy: 0.9998\n",
      "Epoch 247/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9656 - accuracy: 0.9999 - val_loss: 28.8173 - val_accuracy: 0.9998\n",
      "Epoch 248/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.9997 - accuracy: 0.9999 - val_loss: 28.6492 - val_accuracy: 0.9998\n",
      "Epoch 249/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9944 - accuracy: 0.9999 - val_loss: 28.5526 - val_accuracy: 0.9998\n",
      "Epoch 250/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0273 - accuracy: 0.9999 - val_loss: 28.9217 - val_accuracy: 0.9998\n",
      "Epoch 251/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0554 - accuracy: 0.9999 - val_loss: 28.6222 - val_accuracy: 0.9998\n",
      "Epoch 252/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9357 - accuracy: 0.9999 - val_loss: 28.6263 - val_accuracy: 0.9998\n",
      "Epoch 253/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0614 - accuracy: 0.9999 - val_loss: 28.7259 - val_accuracy: 0.9998\n",
      "Epoch 254/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0336 - accuracy: 0.9999 - val_loss: 28.4365 - val_accuracy: 0.9998\n",
      "Epoch 255/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0192 - accuracy: 0.9999 - val_loss: 28.6014 - val_accuracy: 0.9998\n",
      "Epoch 256/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1181 - accuracy: 0.9999 - val_loss: 28.5962 - val_accuracy: 0.9998\n",
      "Epoch 257/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0729 - accuracy: 0.9999 - val_loss: 28.7720 - val_accuracy: 0.9998\n",
      "Epoch 258/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.0644 - accuracy: 0.9999 - val_loss: 28.6264 - val_accuracy: 0.9998\n",
      "Epoch 259/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.1684 - accuracy: 0.9999 - val_loss: 28.5062 - val_accuracy: 0.9998\n",
      "Epoch 260/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9930 - accuracy: 0.9999 - val_loss: 28.4329 - val_accuracy: 0.9998\n",
      "Epoch 261/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9433 - accuracy: 0.9999 - val_loss: 28.7177 - val_accuracy: 0.9998\n",
      "Epoch 262/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0651 - accuracy: 0.9999 - val_loss: 28.6824 - val_accuracy: 0.9998\n",
      "Epoch 263/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 25.1685 - accuracy: 0.9999 - val_loss: 28.6901 - val_accuracy: 0.9998\n",
      "Epoch 264/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.9510 - accuracy: 0.9999 - val_loss: 28.6581 - val_accuracy: 0.9998\n",
      "Epoch 265/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1073 - accuracy: 0.9999 - val_loss: 28.6055 - val_accuracy: 0.9998\n",
      "Epoch 266/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1155 - accuracy: 0.9999 - val_loss: 28.6060 - val_accuracy: 0.9998\n",
      "Epoch 267/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.1566 - accuracy: 0.9999 - val_loss: 28.7004 - val_accuracy: 0.9998\n",
      "Epoch 268/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9336 - accuracy: 0.9999 - val_loss: 28.3070 - val_accuracy: 0.9998\n",
      "Epoch 269/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8930 - accuracy: 0.9999 - val_loss: 28.8784 - val_accuracy: 0.9998\n",
      "Epoch 270/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9163 - accuracy: 0.9999 - val_loss: 28.6703 - val_accuracy: 0.9998\n",
      "Epoch 271/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9589 - accuracy: 0.9999 - val_loss: 28.8663 - val_accuracy: 0.9998\n",
      "Epoch 272/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 25.0841 - accuracy: 0.9999 - val_loss: 28.8938 - val_accuracy: 0.9998\n",
      "Epoch 273/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9792 - accuracy: 0.9999 - val_loss: 28.7702 - val_accuracy: 0.9998\n",
      "Epoch 274/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0380 - accuracy: 0.9999 - val_loss: 28.7394 - val_accuracy: 0.9998\n",
      "Epoch 275/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9066 - accuracy: 0.9999 - val_loss: 28.4089 - val_accuracy: 0.9998\n",
      "Epoch 276/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9060 - accuracy: 0.9999 - val_loss: 28.3322 - val_accuracy: 0.9998\n",
      "Epoch 277/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9265 - accuracy: 0.9999 - val_loss: 28.6672 - val_accuracy: 0.9998\n",
      "Epoch 278/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8720 - accuracy: 0.9999 - val_loss: 28.4918 - val_accuracy: 0.9998\n",
      "Epoch 279/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9696 - accuracy: 0.9999 - val_loss: 28.3173 - val_accuracy: 0.9998\n",
      "Epoch 280/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8300 - accuracy: 0.9999 - val_loss: 28.4037 - val_accuracy: 0.9998\n",
      "Epoch 281/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8464 - accuracy: 0.9999 - val_loss: 28.4424 - val_accuracy: 0.9998\n",
      "Epoch 282/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8387 - accuracy: 0.9999 - val_loss: 28.3324 - val_accuracy: 0.9998\n",
      "Epoch 283/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9658 - accuracy: 0.9999 - val_loss: 28.4231 - val_accuracy: 0.9998\n",
      "Epoch 284/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8955 - accuracy: 0.9999 - val_loss: 28.5160 - val_accuracy: 0.9998\n",
      "Epoch 285/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9042 - accuracy: 0.9999 - val_loss: 28.5079 - val_accuracy: 0.9998\n",
      "Epoch 286/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8099 - accuracy: 0.9999 - val_loss: 28.3076 - val_accuracy: 0.9998\n",
      "Epoch 287/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8158 - accuracy: 0.9999 - val_loss: 28.3696 - val_accuracy: 0.9998\n",
      "Epoch 288/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8692 - accuracy: 0.9999 - val_loss: 28.3483 - val_accuracy: 0.9998\n",
      "Epoch 289/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8230 - accuracy: 0.9999 - val_loss: 28.3752 - val_accuracy: 0.9998\n",
      "Epoch 290/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.8918 - accuracy: 0.9999 - val_loss: 28.6384 - val_accuracy: 0.9998\n",
      "Epoch 291/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9108 - accuracy: 0.9999 - val_loss: 28.3077 - val_accuracy: 0.9998\n",
      "Epoch 292/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8616 - accuracy: 0.9999 - val_loss: 28.3058 - val_accuracy: 0.9998\n",
      "Epoch 293/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8191 - accuracy: 0.9999 - val_loss: 28.2364 - val_accuracy: 0.9998\n",
      "Epoch 294/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9006 - accuracy: 0.9999 - val_loss: 28.1435 - val_accuracy: 0.9998\n",
      "Epoch 295/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.8382 - accuracy: 0.9999 - val_loss: 28.1968 - val_accuracy: 0.9998\n",
      "Epoch 296/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.9031 - accuracy: 0.9999 - val_loss: 28.2483 - val_accuracy: 0.9998\n",
      "Epoch 297/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8244 - accuracy: 0.9999 - val_loss: 28.0892 - val_accuracy: 0.9998\n",
      "Epoch 298/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9893 - accuracy: 0.9999 - val_loss: 28.8160 - val_accuracy: 0.9998\n",
      "Epoch 299/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9739 - accuracy: 0.9999 - val_loss: 28.0946 - val_accuracy: 0.9998\n",
      "Epoch 300/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9242 - accuracy: 0.9999 - val_loss: 28.4185 - val_accuracy: 0.9998\n",
      "Epoch 301/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9032 - accuracy: 0.9999 - val_loss: 28.1108 - val_accuracy: 0.9998\n",
      "Epoch 302/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9810 - accuracy: 0.9999 - val_loss: 28.3951 - val_accuracy: 0.9998\n",
      "Epoch 303/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8299 - accuracy: 0.9999 - val_loss: 28.4936 - val_accuracy: 0.9998\n",
      "Epoch 304/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8356 - accuracy: 0.9999 - val_loss: 28.2476 - val_accuracy: 0.9998\n",
      "Epoch 305/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9699 - accuracy: 0.9999 - val_loss: 28.3065 - val_accuracy: 0.9998\n",
      "Epoch 306/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.9137 - accuracy: 0.9999 - val_loss: 28.0563 - val_accuracy: 0.9998\n",
      "Epoch 307/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7738 - accuracy: 0.9999 - val_loss: 28.1863 - val_accuracy: 0.9998\n",
      "Epoch 308/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7756 - accuracy: 0.9999 - val_loss: 28.0899 - val_accuracy: 0.9998\n",
      "Epoch 309/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8043 - accuracy: 0.9999 - val_loss: 28.1413 - val_accuracy: 0.9998\n",
      "Epoch 310/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.8324 - accuracy: 0.9999 - val_loss: 28.5833 - val_accuracy: 0.9998\n",
      "Epoch 311/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8182 - accuracy: 0.9999 - val_loss: 28.3007 - val_accuracy: 0.9998\n",
      "Epoch 312/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9759 - accuracy: 0.9999 - val_loss: 28.6163 - val_accuracy: 0.9998\n",
      "Epoch 313/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.9324 - accuracy: 0.9999 - val_loss: 28.5388 - val_accuracy: 0.9998\n",
      "Epoch 314/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.0067 - accuracy: 0.9999 - val_loss: 28.1779 - val_accuracy: 0.9998\n",
      "Epoch 315/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7345 - accuracy: 0.9999 - val_loss: 28.1653 - val_accuracy: 0.9998\n",
      "Epoch 316/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.7953 - accuracy: 0.9999 - val_loss: 28.1404 - val_accuracy: 0.9998\n",
      "Epoch 317/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8026 - accuracy: 0.9999 - val_loss: 28.1770 - val_accuracy: 0.9998\n",
      "Epoch 318/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.7504 - accuracy: 0.9999 - val_loss: 28.1671 - val_accuracy: 0.9998\n",
      "Epoch 319/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7722 - accuracy: 0.9999 - val_loss: 27.9136 - val_accuracy: 0.9998\n",
      "Epoch 320/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.7421 - accuracy: 0.9999 - val_loss: 28.1328 - val_accuracy: 0.9998\n",
      "Epoch 321/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7723 - accuracy: 0.9999 - val_loss: 28.4712 - val_accuracy: 0.9998\n",
      "Epoch 322/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.7099 - accuracy: 0.9999 - val_loss: 27.7993 - val_accuracy: 0.9998\n",
      "Epoch 323/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.6920 - accuracy: 0.9999 - val_loss: 28.3534 - val_accuracy: 0.9998\n",
      "Epoch 324/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7972 - accuracy: 0.9999 - val_loss: 27.9275 - val_accuracy: 0.9998\n",
      "Epoch 325/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8871 - accuracy: 0.9999 - val_loss: 28.0718 - val_accuracy: 0.9998\n",
      "Epoch 326/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8536 - accuracy: 0.9999 - val_loss: 27.9311 - val_accuracy: 0.9998\n",
      "Epoch 327/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.7345 - accuracy: 0.9999 - val_loss: 28.2299 - val_accuracy: 0.9998\n",
      "Epoch 328/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7697 - accuracy: 0.9999 - val_loss: 27.9773 - val_accuracy: 0.9998\n",
      "Epoch 329/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7480 - accuracy: 0.9999 - val_loss: 28.3060 - val_accuracy: 0.9998\n",
      "Epoch 330/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8468 - accuracy: 0.9999 - val_loss: 27.9619 - val_accuracy: 0.9998\n",
      "Epoch 331/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6924 - accuracy: 0.9999 - val_loss: 28.0961 - val_accuracy: 0.9998\n",
      "Epoch 332/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.6606 - accuracy: 0.9999 - val_loss: 28.0837 - val_accuracy: 0.9998\n",
      "Epoch 333/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.7355 - accuracy: 0.9999 - val_loss: 27.9695 - val_accuracy: 0.9998\n",
      "Epoch 334/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.8113 - accuracy: 0.9999 - val_loss: 27.9588 - val_accuracy: 0.9998\n",
      "Epoch 335/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7036 - accuracy: 0.9999 - val_loss: 28.0340 - val_accuracy: 0.9998\n",
      "Epoch 336/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6673 - accuracy: 0.9999 - val_loss: 28.2569 - val_accuracy: 0.9998\n",
      "Epoch 337/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6791 - accuracy: 0.9999 - val_loss: 28.2240 - val_accuracy: 0.9998\n",
      "Epoch 338/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7330 - accuracy: 0.9999 - val_loss: 28.0842 - val_accuracy: 0.9998\n",
      "Epoch 339/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.7594 - accuracy: 0.9999 - val_loss: 27.9546 - val_accuracy: 0.9998\n",
      "Epoch 340/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.7287 - accuracy: 0.9999 - val_loss: 28.1772 - val_accuracy: 0.9998\n",
      "Epoch 341/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.7971 - accuracy: 0.9999 - val_loss: 27.8979 - val_accuracy: 0.9998\n",
      "Epoch 342/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.6276 - accuracy: 0.9999 - val_loss: 27.9020 - val_accuracy: 0.9998\n",
      "Epoch 343/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.6172 - accuracy: 0.9999 - val_loss: 27.8863 - val_accuracy: 0.9998\n",
      "Epoch 344/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6456 - accuracy: 0.9999 - val_loss: 27.9173 - val_accuracy: 0.9998\n",
      "Epoch 345/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.5927 - accuracy: 0.9999 - val_loss: 27.8673 - val_accuracy: 0.9998\n",
      "Epoch 346/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6301 - accuracy: 0.9999 - val_loss: 28.0252 - val_accuracy: 0.9998\n",
      "Epoch 347/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.6055 - accuracy: 0.9999 - val_loss: 27.9989 - val_accuracy: 0.9998\n",
      "Epoch 348/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.8558 - accuracy: 0.9999 - val_loss: 27.9385 - val_accuracy: 0.9998\n",
      "Epoch 349/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6995 - accuracy: 0.9999 - val_loss: 27.8390 - val_accuracy: 0.9998\n",
      "Epoch 350/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5967 - accuracy: 0.9999 - val_loss: 27.9581 - val_accuracy: 0.9998\n",
      "Epoch 351/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5662 - accuracy: 0.9999 - val_loss: 28.0141 - val_accuracy: 0.9998\n",
      "Epoch 352/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6164 - accuracy: 0.9999 - val_loss: 27.8368 - val_accuracy: 0.9998\n",
      "Epoch 353/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.6108 - accuracy: 0.9999 - val_loss: 28.0768 - val_accuracy: 0.9998\n",
      "Epoch 354/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.5703 - accuracy: 0.9999 - val_loss: 27.7896 - val_accuracy: 0.9998\n",
      "Epoch 355/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5546 - accuracy: 0.9999 - val_loss: 27.7910 - val_accuracy: 0.9998\n",
      "Epoch 356/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5445 - accuracy: 0.9999 - val_loss: 27.9679 - val_accuracy: 0.9998\n",
      "Epoch 357/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.5602 - accuracy: 0.9999 - val_loss: 27.6489 - val_accuracy: 0.9998\n",
      "Epoch 358/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5868 - accuracy: 0.9999 - val_loss: 28.0465 - val_accuracy: 0.9998\n",
      "Epoch 359/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6480 - accuracy: 0.9999 - val_loss: 27.9364 - val_accuracy: 0.9998\n",
      "Epoch 360/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5641 - accuracy: 0.9999 - val_loss: 27.8136 - val_accuracy: 0.9998\n",
      "Epoch 361/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.5207 - accuracy: 0.9999 - val_loss: 28.1179 - val_accuracy: 0.9998\n",
      "Epoch 362/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.5484 - accuracy: 0.9999 - val_loss: 27.6785 - val_accuracy: 0.9998\n",
      "Epoch 363/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5635 - accuracy: 0.9999 - val_loss: 27.6142 - val_accuracy: 0.9998\n",
      "Epoch 364/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.5191 - accuracy: 0.9999 - val_loss: 28.0026 - val_accuracy: 0.9998\n",
      "Epoch 365/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.4727 - accuracy: 0.9999 - val_loss: 27.6015 - val_accuracy: 0.9998\n",
      "Epoch 366/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6337 - accuracy: 0.9999 - val_loss: 27.8617 - val_accuracy: 0.9998\n",
      "Epoch 367/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.5503 - accuracy: 0.9999 - val_loss: 27.6484 - val_accuracy: 0.9998\n",
      "Epoch 368/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.5066 - accuracy: 0.9999 - val_loss: 27.7514 - val_accuracy: 0.9998\n",
      "Epoch 369/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5604 - accuracy: 0.9999 - val_loss: 27.7174 - val_accuracy: 0.9998\n",
      "Epoch 370/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5444 - accuracy: 0.9999 - val_loss: 27.7248 - val_accuracy: 0.9998\n",
      "Epoch 371/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5383 - accuracy: 0.9999 - val_loss: 27.8310 - val_accuracy: 0.9998\n",
      "Epoch 372/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5125 - accuracy: 0.9999 - val_loss: 27.4777 - val_accuracy: 0.9998\n",
      "Epoch 373/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.4507 - accuracy: 0.9999 - val_loss: 27.5726 - val_accuracy: 0.9998\n",
      "Epoch 374/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.4163 - accuracy: 0.9999 - val_loss: 27.7110 - val_accuracy: 0.9998\n",
      "Epoch 375/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.4238 - accuracy: 0.9999 - val_loss: 27.6084 - val_accuracy: 0.9998\n",
      "Epoch 376/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.4740 - accuracy: 0.9999 - val_loss: 27.7348 - val_accuracy: 0.9998\n",
      "Epoch 377/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6039 - accuracy: 0.9999 - val_loss: 27.9107 - val_accuracy: 0.9998\n",
      "Epoch 378/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.4512 - accuracy: 0.9999 - val_loss: 27.5528 - val_accuracy: 0.9998\n",
      "Epoch 379/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.4779 - accuracy: 0.9999 - val_loss: 28.0288 - val_accuracy: 0.9998\n",
      "Epoch 380/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3890 - accuracy: 0.9999 - val_loss: 27.7603 - val_accuracy: 0.9998\n",
      "Epoch 381/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.4512 - accuracy: 0.9999 - val_loss: 27.6139 - val_accuracy: 0.9998\n",
      "Epoch 382/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.6058 - accuracy: 0.9999 - val_loss: 27.6153 - val_accuracy: 0.9998\n",
      "Epoch 383/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3786 - accuracy: 0.9999 - val_loss: 27.5284 - val_accuracy: 0.9998\n",
      "Epoch 384/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.4238 - accuracy: 0.9999 - val_loss: 27.4727 - val_accuracy: 0.9998\n",
      "Epoch 385/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3771 - accuracy: 0.9999 - val_loss: 27.5319 - val_accuracy: 0.9998\n",
      "Epoch 386/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3545 - accuracy: 0.9999 - val_loss: 27.7181 - val_accuracy: 0.9998\n",
      "Epoch 387/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3899 - accuracy: 0.9999 - val_loss: 27.5500 - val_accuracy: 0.9998\n",
      "Epoch 388/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3519 - accuracy: 0.9999 - val_loss: 27.5755 - val_accuracy: 0.9998\n",
      "Epoch 389/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.4129 - accuracy: 0.9999 - val_loss: 27.7548 - val_accuracy: 0.9998\n",
      "Epoch 390/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.4393 - accuracy: 0.9999 - val_loss: 27.7635 - val_accuracy: 0.9998\n",
      "Epoch 391/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3651 - accuracy: 0.9999 - val_loss: 27.3843 - val_accuracy: 0.9998\n",
      "Epoch 392/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.3358 - accuracy: 0.9999 - val_loss: 27.4689 - val_accuracy: 0.9998\n",
      "Epoch 393/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.3098 - accuracy: 0.9999 - val_loss: 27.3649 - val_accuracy: 0.9998\n",
      "Epoch 394/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3759 - accuracy: 0.9999 - val_loss: 27.7685 - val_accuracy: 0.9998\n",
      "Epoch 395/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.3154 - accuracy: 0.9999 - val_loss: 27.4851 - val_accuracy: 0.9998\n",
      "Epoch 396/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.3228 - accuracy: 0.9999 - val_loss: 27.3976 - val_accuracy: 0.9998\n",
      "Epoch 397/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.4846 - accuracy: 0.9999 - val_loss: 27.2612 - val_accuracy: 0.9998\n",
      "Epoch 398/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.2883 - accuracy: 0.9999 - val_loss: 27.5327 - val_accuracy: 0.9998\n",
      "Epoch 399/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.2409 - accuracy: 0.9999 - val_loss: 27.2925 - val_accuracy: 0.9998\n",
      "Epoch 400/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3957 - accuracy: 0.9999 - val_loss: 27.5043 - val_accuracy: 0.9998\n",
      "Epoch 401/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.5013 - accuracy: 0.9999 - val_loss: 27.2630 - val_accuracy: 0.9998\n",
      "Epoch 402/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3315 - accuracy: 0.9999 - val_loss: 27.4241 - val_accuracy: 0.9998\n",
      "Epoch 403/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3229 - accuracy: 0.9999 - val_loss: 27.4973 - val_accuracy: 0.9998\n",
      "Epoch 404/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.2220 - accuracy: 0.9999 - val_loss: 27.1304 - val_accuracy: 0.9998\n",
      "Epoch 405/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.3515 - accuracy: 0.9999 - val_loss: 27.5085 - val_accuracy: 0.9998\n",
      "Epoch 406/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3101 - accuracy: 0.9999 - val_loss: 27.2527 - val_accuracy: 0.9998\n",
      "Epoch 407/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.2293 - accuracy: 0.9999 - val_loss: 27.4545 - val_accuracy: 0.9998\n",
      "Epoch 408/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.3774 - accuracy: 0.9999 - val_loss: 27.2382 - val_accuracy: 0.9998\n",
      "Epoch 409/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1978 - accuracy: 0.9999 - val_loss: 27.2110 - val_accuracy: 0.9998\n",
      "Epoch 410/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1650 - accuracy: 0.9999 - val_loss: 27.1872 - val_accuracy: 0.9998\n",
      "Epoch 411/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.2044 - accuracy: 0.9999 - val_loss: 27.1313 - val_accuracy: 0.9998\n",
      "Epoch 412/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.1437 - accuracy: 0.9999 - val_loss: 27.1707 - val_accuracy: 0.9998\n",
      "Epoch 413/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1276 - accuracy: 0.9999 - val_loss: 27.3096 - val_accuracy: 0.9998\n",
      "Epoch 414/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1686 - accuracy: 0.9999 - val_loss: 27.1117 - val_accuracy: 0.9998\n",
      "Epoch 415/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.2043 - accuracy: 0.9999 - val_loss: 27.2233 - val_accuracy: 0.9998\n",
      "Epoch 416/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.1957 - accuracy: 0.9999 - val_loss: 27.1083 - val_accuracy: 0.9998\n",
      "Epoch 417/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.2261 - accuracy: 0.9999 - val_loss: 27.2436 - val_accuracy: 0.9998\n",
      "Epoch 418/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.1095 - accuracy: 0.9999 - val_loss: 26.9949 - val_accuracy: 0.9998\n",
      "Epoch 419/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0715 - accuracy: 0.9999 - val_loss: 27.0794 - val_accuracy: 0.9998\n",
      "Epoch 420/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1190 - accuracy: 0.9999 - val_loss: 27.2938 - val_accuracy: 0.9998\n",
      "Epoch 421/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1835 - accuracy: 0.9999 - val_loss: 27.0878 - val_accuracy: 0.9998\n",
      "Epoch 422/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.1940 - accuracy: 0.9999 - val_loss: 27.2756 - val_accuracy: 0.9998\n",
      "Epoch 423/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.2906 - accuracy: 0.9999 - val_loss: 27.2644 - val_accuracy: 0.9998\n",
      "Epoch 424/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.2095 - accuracy: 0.9999 - val_loss: 27.1949 - val_accuracy: 0.9998\n",
      "Epoch 425/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0931 - accuracy: 0.9999 - val_loss: 27.0521 - val_accuracy: 0.9998\n",
      "Epoch 426/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.1345 - accuracy: 0.9999 - val_loss: 27.1521 - val_accuracy: 0.9998\n",
      "Epoch 427/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0825 - accuracy: 0.9999 - val_loss: 26.8888 - val_accuracy: 0.9998\n",
      "Epoch 428/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.0590 - accuracy: 0.9999 - val_loss: 27.0421 - val_accuracy: 0.9998\n",
      "Epoch 429/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0238 - accuracy: 0.9999 - val_loss: 26.9583 - val_accuracy: 0.9998\n",
      "Epoch 430/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0655 - accuracy: 0.9999 - val_loss: 27.1651 - val_accuracy: 0.9998\n",
      "Epoch 431/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.9976 - accuracy: 0.9999 - val_loss: 27.0840 - val_accuracy: 0.9998\n",
      "Epoch 432/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1434 - accuracy: 0.9999 - val_loss: 27.1077 - val_accuracy: 0.9998\n",
      "Epoch 433/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0947 - accuracy: 0.9999 - val_loss: 27.1218 - val_accuracy: 0.9998\n",
      "Epoch 434/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0355 - accuracy: 0.9999 - val_loss: 27.1055 - val_accuracy: 0.9998\n",
      "Epoch 435/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.1417 - accuracy: 0.9999 - val_loss: 26.9136 - val_accuracy: 0.9998\n",
      "Epoch 436/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0849 - accuracy: 0.9999 - val_loss: 26.8153 - val_accuracy: 0.9998\n",
      "Epoch 437/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0170 - accuracy: 0.9999 - val_loss: 27.1764 - val_accuracy: 0.9998\n",
      "Epoch 438/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.1189 - accuracy: 0.9999 - val_loss: 26.9090 - val_accuracy: 0.9998\n",
      "Epoch 439/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0754 - accuracy: 0.9999 - val_loss: 26.9485 - val_accuracy: 0.9998\n",
      "Epoch 440/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0612 - accuracy: 0.9999 - val_loss: 26.9694 - val_accuracy: 0.9998\n",
      "Epoch 441/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0159 - accuracy: 0.9999 - val_loss: 26.9567 - val_accuracy: 0.9998\n",
      "Epoch 442/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0044 - accuracy: 0.9999 - val_loss: 26.8016 - val_accuracy: 0.9998\n",
      "Epoch 443/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0144 - accuracy: 0.9999 - val_loss: 26.9440 - val_accuracy: 0.9998\n",
      "Epoch 444/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.9618 - accuracy: 0.9999 - val_loss: 27.0576 - val_accuracy: 0.9998\n",
      "Epoch 445/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.9584 - accuracy: 0.9999 - val_loss: 26.6947 - val_accuracy: 0.9998\n",
      "Epoch 446/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9116 - accuracy: 0.9999 - val_loss: 26.9744 - val_accuracy: 0.9998\n",
      "Epoch 447/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.2066 - accuracy: 0.9999 - val_loss: 26.9523 - val_accuracy: 0.9998\n",
      "Epoch 448/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9323 - accuracy: 0.9999 - val_loss: 26.7127 - val_accuracy: 0.9998\n",
      "Epoch 449/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.9152 - accuracy: 0.9999 - val_loss: 26.8170 - val_accuracy: 0.9998\n",
      "Epoch 450/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9903 - accuracy: 0.9999 - val_loss: 26.8716 - val_accuracy: 0.9998\n",
      "Epoch 451/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9064 - accuracy: 0.9999 - val_loss: 26.6557 - val_accuracy: 0.9998\n",
      "Epoch 452/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.9603 - accuracy: 0.9999 - val_loss: 26.7018 - val_accuracy: 0.9998\n",
      "Epoch 453/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 24.0288 - accuracy: 0.9999 - val_loss: 26.9594 - val_accuracy: 0.9998\n",
      "Epoch 454/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.9220 - accuracy: 0.9999 - val_loss: 26.7287 - val_accuracy: 0.9998\n",
      "Epoch 455/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.9737 - accuracy: 0.9999 - val_loss: 26.8305 - val_accuracy: 0.9998\n",
      "Epoch 456/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.9930 - accuracy: 0.9999 - val_loss: 26.6119 - val_accuracy: 0.9998\n",
      "Epoch 457/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8820 - accuracy: 0.9999 - val_loss: 27.1245 - val_accuracy: 0.9998\n",
      "Epoch 458/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.9667 - accuracy: 0.9999 - val_loss: 26.8480 - val_accuracy: 0.9998\n",
      "Epoch 459/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 24.0672 - accuracy: 0.9999 - val_loss: 26.4509 - val_accuracy: 0.9998\n",
      "Epoch 460/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8807 - accuracy: 0.9999 - val_loss: 26.7188 - val_accuracy: 0.9998\n",
      "Epoch 461/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9737 - accuracy: 0.9999 - val_loss: 26.6385 - val_accuracy: 0.9998\n",
      "Epoch 462/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9358 - accuracy: 0.9999 - val_loss: 26.5991 - val_accuracy: 0.9998\n",
      "Epoch 463/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8679 - accuracy: 0.9999 - val_loss: 26.6355 - val_accuracy: 0.9998\n",
      "Epoch 464/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.8715 - accuracy: 0.9999 - val_loss: 26.5329 - val_accuracy: 0.9998\n",
      "Epoch 465/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8934 - accuracy: 0.9999 - val_loss: 26.5994 - val_accuracy: 0.9998\n",
      "Epoch 466/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.8480 - accuracy: 0.9999 - val_loss: 26.6459 - val_accuracy: 0.9998\n",
      "Epoch 467/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.8832 - accuracy: 0.9999 - val_loss: 26.5834 - val_accuracy: 0.9998\n",
      "Epoch 468/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9464 - accuracy: 0.9999 - val_loss: 26.4746 - val_accuracy: 0.9998\n",
      "Epoch 469/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9621 - accuracy: 0.9999 - val_loss: 26.5626 - val_accuracy: 0.9998\n",
      "Epoch 470/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.8472 - accuracy: 0.9999 - val_loss: 26.5418 - val_accuracy: 0.9998\n",
      "Epoch 471/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8331 - accuracy: 0.9999 - val_loss: 26.5038 - val_accuracy: 0.9998\n",
      "Epoch 472/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8530 - accuracy: 0.9999 - val_loss: 26.4785 - val_accuracy: 0.9998\n",
      "Epoch 473/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7973 - accuracy: 0.9999 - val_loss: 26.4621 - val_accuracy: 0.9998\n",
      "Epoch 474/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8901 - accuracy: 0.9999 - val_loss: 26.4772 - val_accuracy: 0.9998\n",
      "Epoch 475/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 24.0991 - accuracy: 0.9999 - val_loss: 26.7104 - val_accuracy: 0.9998\n",
      "Epoch 476/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.9342 - accuracy: 0.9999 - val_loss: 26.4029 - val_accuracy: 0.9998\n",
      "Epoch 477/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8533 - accuracy: 0.9999 - val_loss: 26.6875 - val_accuracy: 0.9998\n",
      "Epoch 478/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8506 - accuracy: 0.9999 - val_loss: 26.8295 - val_accuracy: 0.9998\n",
      "Epoch 479/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.0468 - accuracy: 0.9999 - val_loss: 26.8878 - val_accuracy: 0.9998\n",
      "Epoch 480/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.8054 - accuracy: 0.9999 - val_loss: 26.4349 - val_accuracy: 0.9998\n",
      "Epoch 481/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8504 - accuracy: 0.9999 - val_loss: 26.8093 - val_accuracy: 0.9998\n",
      "Epoch 482/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8450 - accuracy: 0.9999 - val_loss: 26.4475 - val_accuracy: 0.9998\n",
      "Epoch 483/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7646 - accuracy: 0.9999 - val_loss: 26.4551 - val_accuracy: 0.9998\n",
      "Epoch 484/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7943 - accuracy: 0.9999 - val_loss: 26.6922 - val_accuracy: 0.9998\n",
      "Epoch 485/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8128 - accuracy: 0.9999 - val_loss: 26.4644 - val_accuracy: 0.9998\n",
      "Epoch 486/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7890 - accuracy: 0.9999 - val_loss: 26.4879 - val_accuracy: 0.9998\n",
      "Epoch 487/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.7725 - accuracy: 0.9999 - val_loss: 26.2673 - val_accuracy: 0.9998\n",
      "Epoch 488/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7615 - accuracy: 0.9999 - val_loss: 26.4056 - val_accuracy: 0.9998\n",
      "Epoch 489/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8587 - accuracy: 0.9999 - val_loss: 26.3005 - val_accuracy: 0.9998\n",
      "Epoch 490/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7669 - accuracy: 0.9999 - val_loss: 26.4815 - val_accuracy: 0.9998\n",
      "Epoch 491/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8054 - accuracy: 0.9999 - val_loss: 26.3143 - val_accuracy: 0.9998\n",
      "Epoch 492/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.8945 - accuracy: 0.9999 - val_loss: 26.6530 - val_accuracy: 0.9998\n",
      "Epoch 493/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.8228 - accuracy: 0.9999 - val_loss: 26.2243 - val_accuracy: 0.9998\n",
      "Epoch 494/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7639 - accuracy: 0.9999 - val_loss: 26.4707 - val_accuracy: 0.9998\n",
      "Epoch 495/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.8327 - accuracy: 0.9999 - val_loss: 26.1947 - val_accuracy: 0.9998\n",
      "Epoch 496/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7338 - accuracy: 0.9999 - val_loss: 26.2575 - val_accuracy: 0.9998\n",
      "Epoch 497/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7222 - accuracy: 0.9999 - val_loss: 26.1748 - val_accuracy: 0.9998\n",
      "Epoch 498/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8462 - accuracy: 0.9999 - val_loss: 26.3962 - val_accuracy: 0.9998\n",
      "Epoch 499/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7050 - accuracy: 0.9999 - val_loss: 26.3464 - val_accuracy: 0.9998\n",
      "Epoch 500/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8415 - accuracy: 0.9999 - val_loss: 26.4781 - val_accuracy: 0.9998\n",
      "Epoch 501/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.8141 - accuracy: 0.9999 - val_loss: 26.7270 - val_accuracy: 0.9998\n",
      "Epoch 502/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8343 - accuracy: 0.9999 - val_loss: 26.5928 - val_accuracy: 0.9998\n",
      "Epoch 503/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 24.1119 - accuracy: 0.9999 - val_loss: 26.2088 - val_accuracy: 0.9998\n",
      "Epoch 504/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7522 - accuracy: 0.9999 - val_loss: 26.3491 - val_accuracy: 0.9998\n",
      "Epoch 505/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7035 - accuracy: 0.9999 - val_loss: 26.4691 - val_accuracy: 0.9998\n",
      "Epoch 506/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7151 - accuracy: 0.9999 - val_loss: 26.2329 - val_accuracy: 0.9998\n",
      "Epoch 507/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6828 - accuracy: 0.9999 - val_loss: 26.3211 - val_accuracy: 0.9998\n",
      "Epoch 508/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7208 - accuracy: 0.9999 - val_loss: 26.1837 - val_accuracy: 0.9998\n",
      "Epoch 509/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.6768 - accuracy: 0.9999 - val_loss: 26.2191 - val_accuracy: 0.9998\n",
      "Epoch 510/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6575 - accuracy: 0.9999 - val_loss: 26.2681 - val_accuracy: 0.9998\n",
      "Epoch 511/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7098 - accuracy: 0.9999 - val_loss: 26.1255 - val_accuracy: 0.9998\n",
      "Epoch 512/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7256 - accuracy: 0.9999 - val_loss: 26.2711 - val_accuracy: 0.9998\n",
      "Epoch 513/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6838 - accuracy: 0.9999 - val_loss: 26.0763 - val_accuracy: 0.9998\n",
      "Epoch 514/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7080 - accuracy: 0.9999 - val_loss: 26.3157 - val_accuracy: 0.9998\n",
      "Epoch 515/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8281 - accuracy: 0.9999 - val_loss: 26.2568 - val_accuracy: 0.9998\n",
      "Epoch 516/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.8053 - accuracy: 0.9999 - val_loss: 26.1150 - val_accuracy: 0.9998\n",
      "Epoch 517/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7489 - accuracy: 0.9999 - val_loss: 26.2612 - val_accuracy: 0.9998\n",
      "Epoch 518/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6354 - accuracy: 0.9999 - val_loss: 26.0855 - val_accuracy: 0.9998\n",
      "Epoch 519/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.6299 - accuracy: 0.9999 - val_loss: 26.2514 - val_accuracy: 0.9998\n",
      "Epoch 520/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6804 - accuracy: 0.9999 - val_loss: 26.0935 - val_accuracy: 0.9998\n",
      "Epoch 521/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7214 - accuracy: 0.9999 - val_loss: 26.0061 - val_accuracy: 0.9998\n",
      "Epoch 522/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6505 - accuracy: 0.9999 - val_loss: 26.1690 - val_accuracy: 0.9998\n",
      "Epoch 523/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.7239 - accuracy: 0.9999 - val_loss: 26.1680 - val_accuracy: 0.9998\n",
      "Epoch 524/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.6985 - accuracy: 0.9999 - val_loss: 26.5106 - val_accuracy: 0.9998\n",
      "Epoch 525/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7131 - accuracy: 0.9999 - val_loss: 26.4141 - val_accuracy: 0.9998\n",
      "Epoch 526/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7195 - accuracy: 0.9999 - val_loss: 26.1294 - val_accuracy: 0.9998\n",
      "Epoch 527/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7016 - accuracy: 0.9999 - val_loss: 26.3976 - val_accuracy: 0.9998\n",
      "Epoch 528/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.7190 - accuracy: 0.9999 - val_loss: 26.2385 - val_accuracy: 0.9998\n",
      "Epoch 529/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6478 - accuracy: 0.9999 - val_loss: 25.9796 - val_accuracy: 0.9998\n",
      "Epoch 530/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.6005 - accuracy: 0.9999 - val_loss: 26.1137 - val_accuracy: 0.9998\n",
      "Epoch 531/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6158 - accuracy: 0.9999 - val_loss: 26.0023 - val_accuracy: 0.9998\n",
      "Epoch 532/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6405 - accuracy: 0.9999 - val_loss: 26.0075 - val_accuracy: 0.9998\n",
      "Epoch 533/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7547 - accuracy: 0.9999 - val_loss: 26.1729 - val_accuracy: 0.9998\n",
      "Epoch 534/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7368 - accuracy: 0.9999 - val_loss: 25.9930 - val_accuracy: 0.9998\n",
      "Epoch 535/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.7165 - accuracy: 0.9999 - val_loss: 26.3545 - val_accuracy: 0.9998\n",
      "Epoch 536/1500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 23.8248 - accuracy: 0.9999 - val_loss: 25.9278 - val_accuracy: 0.9998\n",
      "Epoch 537/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.7113 - accuracy: 0.9999 - val_loss: 26.1284 - val_accuracy: 0.9998\n",
      "Epoch 538/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6588 - accuracy: 0.9999 - val_loss: 26.0453 - val_accuracy: 0.9998\n",
      "Epoch 539/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.6080 - accuracy: 0.9999 - val_loss: 26.1029 - val_accuracy: 0.9998\n",
      "Epoch 540/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.6178 - accuracy: 0.9999 - val_loss: 26.0728 - val_accuracy: 0.9998\n",
      "Epoch 541/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6005 - accuracy: 0.9999 - val_loss: 26.1791 - val_accuracy: 0.9998\n",
      "Epoch 542/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5893 - accuracy: 0.9999 - val_loss: 26.0340 - val_accuracy: 0.9998\n",
      "Epoch 543/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5891 - accuracy: 0.9999 - val_loss: 26.1346 - val_accuracy: 0.9998\n",
      "Epoch 544/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6277 - accuracy: 0.9999 - val_loss: 26.1807 - val_accuracy: 0.9998\n",
      "Epoch 545/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5560 - accuracy: 0.9999 - val_loss: 26.0185 - val_accuracy: 0.9998\n",
      "Epoch 546/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5881 - accuracy: 0.9999 - val_loss: 26.0407 - val_accuracy: 0.9998\n",
      "Epoch 547/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5793 - accuracy: 0.9999 - val_loss: 26.0055 - val_accuracy: 0.9998\n",
      "Epoch 548/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6664 - accuracy: 0.9999 - val_loss: 25.9577 - val_accuracy: 0.9998\n",
      "Epoch 549/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5974 - accuracy: 0.9999 - val_loss: 26.0621 - val_accuracy: 0.9998\n",
      "Epoch 550/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5505 - accuracy: 0.9999 - val_loss: 25.9373 - val_accuracy: 0.9998\n",
      "Epoch 551/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6335 - accuracy: 0.9999 - val_loss: 25.9848 - val_accuracy: 0.9998\n",
      "Epoch 552/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5813 - accuracy: 0.9999 - val_loss: 25.9357 - val_accuracy: 0.9998\n",
      "Epoch 553/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5885 - accuracy: 0.9999 - val_loss: 26.1081 - val_accuracy: 0.9998\n",
      "Epoch 554/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6418 - accuracy: 0.9999 - val_loss: 25.8925 - val_accuracy: 0.9998\n",
      "Epoch 555/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6081 - accuracy: 0.9999 - val_loss: 26.1242 - val_accuracy: 0.9998\n",
      "Epoch 556/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.6102 - accuracy: 0.9999 - val_loss: 25.8015 - val_accuracy: 0.9998\n",
      "Epoch 557/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5784 - accuracy: 0.9999 - val_loss: 25.9443 - val_accuracy: 0.9998\n",
      "Epoch 558/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5551 - accuracy: 0.9999 - val_loss: 25.9771 - val_accuracy: 0.9998\n",
      "Epoch 559/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.7151 - accuracy: 0.9999 - val_loss: 25.7437 - val_accuracy: 0.9998\n",
      "Epoch 560/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5310 - accuracy: 0.9999 - val_loss: 25.9901 - val_accuracy: 0.9998\n",
      "Epoch 561/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6729 - accuracy: 0.9999 - val_loss: 25.8245 - val_accuracy: 0.9998\n",
      "Epoch 562/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5588 - accuracy: 0.9999 - val_loss: 26.0860 - val_accuracy: 0.9998\n",
      "Epoch 563/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5925 - accuracy: 0.9999 - val_loss: 25.8253 - val_accuracy: 0.9998\n",
      "Epoch 564/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5492 - accuracy: 0.9999 - val_loss: 25.8670 - val_accuracy: 0.9998\n",
      "Epoch 565/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5733 - accuracy: 0.9999 - val_loss: 26.0169 - val_accuracy: 0.9998\n",
      "Epoch 566/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5996 - accuracy: 0.9999 - val_loss: 25.9024 - val_accuracy: 0.9998\n",
      "Epoch 567/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6960 - accuracy: 0.9999 - val_loss: 25.8866 - val_accuracy: 0.9998\n",
      "Epoch 568/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5861 - accuracy: 0.9999 - val_loss: 25.9940 - val_accuracy: 0.9998\n",
      "Epoch 569/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6767 - accuracy: 0.9999 - val_loss: 25.9697 - val_accuracy: 0.9998\n",
      "Epoch 570/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6007 - accuracy: 0.9999 - val_loss: 25.8938 - val_accuracy: 0.9998\n",
      "Epoch 571/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6572 - accuracy: 0.9999 - val_loss: 26.0044 - val_accuracy: 0.9998\n",
      "Epoch 572/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.7017 - accuracy: 0.9999 - val_loss: 25.8639 - val_accuracy: 0.9998\n",
      "Epoch 573/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.7411 - accuracy: 0.9999 - val_loss: 26.2023 - val_accuracy: 0.9998\n",
      "Epoch 574/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.6750 - accuracy: 0.9999 - val_loss: 26.0686 - val_accuracy: 0.9998\n",
      "Epoch 575/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5581 - accuracy: 0.9999 - val_loss: 25.8935 - val_accuracy: 0.9998\n",
      "Epoch 576/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5533 - accuracy: 0.9999 - val_loss: 25.8047 - val_accuracy: 0.9998\n",
      "Epoch 577/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.6216 - accuracy: 0.9999 - val_loss: 25.9607 - val_accuracy: 0.9998\n",
      "Epoch 578/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.6389 - accuracy: 0.9999 - val_loss: 25.8025 - val_accuracy: 0.9998\n",
      "Epoch 579/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5605 - accuracy: 0.9999 - val_loss: 25.9145 - val_accuracy: 0.9998\n",
      "Epoch 580/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5128 - accuracy: 0.9999 - val_loss: 25.6963 - val_accuracy: 0.9998\n",
      "Epoch 581/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5874 - accuracy: 0.9999 - val_loss: 26.3056 - val_accuracy: 0.9998\n",
      "Epoch 582/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5780 - accuracy: 0.9999 - val_loss: 25.7917 - val_accuracy: 0.9998\n",
      "Epoch 583/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4976 - accuracy: 0.9999 - val_loss: 25.7904 - val_accuracy: 0.9998\n",
      "Epoch 584/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5779 - accuracy: 0.9999 - val_loss: 25.6875 - val_accuracy: 0.9998\n",
      "Epoch 585/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5164 - accuracy: 0.9999 - val_loss: 25.7928 - val_accuracy: 0.9998\n",
      "Epoch 586/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4870 - accuracy: 0.9999 - val_loss: 25.7160 - val_accuracy: 0.9998\n",
      "Epoch 587/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5319 - accuracy: 0.9999 - val_loss: 25.8746 - val_accuracy: 0.9998\n",
      "Epoch 588/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4861 - accuracy: 0.9999 - val_loss: 25.7538 - val_accuracy: 0.9998\n",
      "Epoch 589/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5409 - accuracy: 0.9999 - val_loss: 25.9135 - val_accuracy: 0.9998\n",
      "Epoch 590/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4916 - accuracy: 0.9999 - val_loss: 25.6226 - val_accuracy: 0.9998\n",
      "Epoch 591/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5259 - accuracy: 0.9999 - val_loss: 26.0158 - val_accuracy: 0.9998\n",
      "Epoch 592/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5108 - accuracy: 0.9999 - val_loss: 25.8102 - val_accuracy: 0.9998\n",
      "Epoch 593/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5273 - accuracy: 0.9999 - val_loss: 25.7120 - val_accuracy: 0.9998\n",
      "Epoch 594/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5294 - accuracy: 0.9999 - val_loss: 25.9965 - val_accuracy: 0.9998\n",
      "Epoch 595/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4736 - accuracy: 0.9999 - val_loss: 25.8928 - val_accuracy: 0.9998\n",
      "Epoch 596/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5364 - accuracy: 0.9999 - val_loss: 25.6612 - val_accuracy: 0.9998\n",
      "Epoch 597/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4952 - accuracy: 0.9999 - val_loss: 25.9544 - val_accuracy: 0.9998\n",
      "Epoch 598/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5741 - accuracy: 0.9999 - val_loss: 25.6975 - val_accuracy: 0.9998\n",
      "Epoch 599/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4971 - accuracy: 0.9999 - val_loss: 25.7371 - val_accuracy: 0.9998\n",
      "Epoch 600/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4771 - accuracy: 0.9999 - val_loss: 25.6557 - val_accuracy: 0.9998\n",
      "Epoch 601/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5237 - accuracy: 0.9999 - val_loss: 25.7973 - val_accuracy: 0.9998\n",
      "Epoch 602/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4753 - accuracy: 0.9999 - val_loss: 25.5723 - val_accuracy: 0.9998\n",
      "Epoch 603/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5292 - accuracy: 0.9999 - val_loss: 25.9118 - val_accuracy: 0.9998\n",
      "Epoch 604/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4969 - accuracy: 0.9999 - val_loss: 25.6969 - val_accuracy: 0.9998\n",
      "Epoch 605/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4147 - accuracy: 0.9999 - val_loss: 25.7190 - val_accuracy: 0.9998\n",
      "Epoch 606/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4933 - accuracy: 0.9999 - val_loss: 25.6820 - val_accuracy: 0.9998\n",
      "Epoch 607/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4824 - accuracy: 0.9999 - val_loss: 25.7637 - val_accuracy: 0.9998\n",
      "Epoch 608/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5383 - accuracy: 0.9999 - val_loss: 25.6283 - val_accuracy: 0.9998\n",
      "Epoch 609/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5139 - accuracy: 0.9999 - val_loss: 25.6301 - val_accuracy: 0.9998\n",
      "Epoch 610/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5565 - accuracy: 0.9999 - val_loss: 25.6505 - val_accuracy: 0.9998\n",
      "Epoch 611/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4577 - accuracy: 0.9999 - val_loss: 25.5674 - val_accuracy: 0.9998\n",
      "Epoch 612/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.5664 - accuracy: 0.9999 - val_loss: 25.7044 - val_accuracy: 0.9998\n",
      "Epoch 613/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.6675 - accuracy: 0.9999 - val_loss: 25.5143 - val_accuracy: 0.9998\n",
      "Epoch 614/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4375 - accuracy: 0.9999 - val_loss: 25.7356 - val_accuracy: 0.9998\n",
      "Epoch 615/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4322 - accuracy: 0.9999 - val_loss: 25.7061 - val_accuracy: 0.9998\n",
      "Epoch 616/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4526 - accuracy: 0.9999 - val_loss: 25.6497 - val_accuracy: 0.9998\n",
      "Epoch 617/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4147 - accuracy: 0.9999 - val_loss: 25.6151 - val_accuracy: 0.9998\n",
      "Epoch 618/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4129 - accuracy: 0.9999 - val_loss: 25.6161 - val_accuracy: 0.9998\n",
      "Epoch 619/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4647 - accuracy: 0.9999 - val_loss: 25.5373 - val_accuracy: 0.9998\n",
      "Epoch 620/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.5135 - accuracy: 0.9999 - val_loss: 25.5757 - val_accuracy: 0.9998\n",
      "Epoch 621/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4344 - accuracy: 0.9999 - val_loss: 25.6728 - val_accuracy: 0.9998\n",
      "Epoch 622/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5185 - accuracy: 0.9999 - val_loss: 25.6812 - val_accuracy: 0.9998\n",
      "Epoch 623/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4390 - accuracy: 0.9999 - val_loss: 25.5647 - val_accuracy: 0.9998\n",
      "Epoch 624/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4140 - accuracy: 0.9999 - val_loss: 25.6672 - val_accuracy: 0.9998\n",
      "Epoch 625/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4521 - accuracy: 0.9999 - val_loss: 25.7656 - val_accuracy: 0.9998\n",
      "Epoch 626/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4351 - accuracy: 0.9999 - val_loss: 25.6941 - val_accuracy: 0.9998\n",
      "Epoch 627/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4113 - accuracy: 0.9999 - val_loss: 25.9818 - val_accuracy: 0.9998\n",
      "Epoch 628/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4816 - accuracy: 0.9999 - val_loss: 25.6335 - val_accuracy: 0.9998\n",
      "Epoch 629/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.5010 - accuracy: 0.9999 - val_loss: 25.8053 - val_accuracy: 0.9998\n",
      "Epoch 630/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4435 - accuracy: 0.9999 - val_loss: 25.5604 - val_accuracy: 0.9998\n",
      "Epoch 631/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4305 - accuracy: 0.9999 - val_loss: 25.5539 - val_accuracy: 0.9998\n",
      "Epoch 632/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4955 - accuracy: 0.9999 - val_loss: 25.4219 - val_accuracy: 0.9998\n",
      "Epoch 633/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3626 - accuracy: 0.9999 - val_loss: 25.6728 - val_accuracy: 0.9998\n",
      "Epoch 634/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3991 - accuracy: 0.9999 - val_loss: 25.4840 - val_accuracy: 0.9998\n",
      "Epoch 635/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4402 - accuracy: 0.9999 - val_loss: 25.7549 - val_accuracy: 0.9998\n",
      "Epoch 636/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4387 - accuracy: 0.9999 - val_loss: 25.4400 - val_accuracy: 0.9998\n",
      "Epoch 637/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4346 - accuracy: 0.9999 - val_loss: 25.4909 - val_accuracy: 0.9998\n",
      "Epoch 638/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3867 - accuracy: 0.9999 - val_loss: 25.4593 - val_accuracy: 0.9998\n",
      "Epoch 639/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3754 - accuracy: 0.9999 - val_loss: 25.5317 - val_accuracy: 0.9998\n",
      "Epoch 640/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4123 - accuracy: 0.9999 - val_loss: 25.6472 - val_accuracy: 0.9998\n",
      "Epoch 641/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4051 - accuracy: 0.9999 - val_loss: 25.6815 - val_accuracy: 0.9998\n",
      "Epoch 642/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4219 - accuracy: 0.9999 - val_loss: 25.5283 - val_accuracy: 0.9998\n",
      "Epoch 643/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3546 - accuracy: 0.9999 - val_loss: 25.5672 - val_accuracy: 0.9998\n",
      "Epoch 644/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4295 - accuracy: 0.9999 - val_loss: 25.4562 - val_accuracy: 0.9998\n",
      "Epoch 645/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4058 - accuracy: 0.9999 - val_loss: 25.5158 - val_accuracy: 0.9998\n",
      "Epoch 646/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3621 - accuracy: 0.9999 - val_loss: 25.5573 - val_accuracy: 0.9998\n",
      "Epoch 647/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4684 - accuracy: 0.9999 - val_loss: 25.4497 - val_accuracy: 0.9998\n",
      "Epoch 648/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4391 - accuracy: 0.9999 - val_loss: 25.3891 - val_accuracy: 0.9998\n",
      "Epoch 649/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4487 - accuracy: 0.9999 - val_loss: 25.5784 - val_accuracy: 0.9998\n",
      "Epoch 650/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3939 - accuracy: 0.9999 - val_loss: 25.4251 - val_accuracy: 0.9998\n",
      "Epoch 651/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4247 - accuracy: 0.9999 - val_loss: 25.4669 - val_accuracy: 0.9998\n",
      "Epoch 652/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3935 - accuracy: 0.9999 - val_loss: 25.5265 - val_accuracy: 0.9998\n",
      "Epoch 653/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4940 - accuracy: 0.9999 - val_loss: 25.4401 - val_accuracy: 0.9998\n",
      "Epoch 654/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3626 - accuracy: 0.9999 - val_loss: 25.5137 - val_accuracy: 0.9998\n",
      "Epoch 655/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4035 - accuracy: 0.9999 - val_loss: 25.3645 - val_accuracy: 0.9998\n",
      "Epoch 656/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3473 - accuracy: 0.9999 - val_loss: 25.3491 - val_accuracy: 0.9998\n",
      "Epoch 657/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4720 - accuracy: 0.9999 - val_loss: 25.6815 - val_accuracy: 0.9998\n",
      "Epoch 658/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4315 - accuracy: 0.9999 - val_loss: 25.3722 - val_accuracy: 0.9998\n",
      "Epoch 659/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3414 - accuracy: 0.9999 - val_loss: 25.4771 - val_accuracy: 0.9998\n",
      "Epoch 660/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4508 - accuracy: 0.9999 - val_loss: 25.4960 - val_accuracy: 0.9998\n",
      "Epoch 661/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4683 - accuracy: 0.9999 - val_loss: 25.4981 - val_accuracy: 0.9998\n",
      "Epoch 662/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4009 - accuracy: 0.9999 - val_loss: 25.3557 - val_accuracy: 0.9998\n",
      "Epoch 663/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3174 - accuracy: 0.9999 - val_loss: 25.3852 - val_accuracy: 0.9998\n",
      "Epoch 664/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3631 - accuracy: 0.9999 - val_loss: 25.3228 - val_accuracy: 0.9998\n",
      "Epoch 665/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3675 - accuracy: 0.9999 - val_loss: 25.4388 - val_accuracy: 0.9998\n",
      "Epoch 666/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4004 - accuracy: 0.9999 - val_loss: 25.3896 - val_accuracy: 0.9998\n",
      "Epoch 667/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4533 - accuracy: 0.9999 - val_loss: 25.3253 - val_accuracy: 0.9998\n",
      "Epoch 668/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3346 - accuracy: 0.9999 - val_loss: 25.4439 - val_accuracy: 0.9998\n",
      "Epoch 669/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3603 - accuracy: 0.9999 - val_loss: 25.4711 - val_accuracy: 0.9998\n",
      "Epoch 670/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.4152 - accuracy: 0.9999 - val_loss: 25.3428 - val_accuracy: 0.9998\n",
      "Epoch 671/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3967 - accuracy: 0.9999 - val_loss: 25.3518 - val_accuracy: 0.9998\n",
      "Epoch 672/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3639 - accuracy: 0.9999 - val_loss: 25.3667 - val_accuracy: 0.9998\n",
      "Epoch 673/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4181 - accuracy: 0.9999 - val_loss: 25.4057 - val_accuracy: 0.9998\n",
      "Epoch 674/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4001 - accuracy: 0.9999 - val_loss: 25.3882 - val_accuracy: 0.9998\n",
      "Epoch 675/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3201 - accuracy: 0.9999 - val_loss: 25.3001 - val_accuracy: 0.9998\n",
      "Epoch 676/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3174 - accuracy: 0.9999 - val_loss: 25.4577 - val_accuracy: 0.9998\n",
      "Epoch 677/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3450 - accuracy: 0.9999 - val_loss: 25.2997 - val_accuracy: 0.9998\n",
      "Epoch 678/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3560 - accuracy: 0.9999 - val_loss: 25.4421 - val_accuracy: 0.9998\n",
      "Epoch 679/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3668 - accuracy: 0.9999 - val_loss: 25.5294 - val_accuracy: 0.9998\n",
      "Epoch 680/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4366 - accuracy: 0.9999 - val_loss: 25.3221 - val_accuracy: 0.9998\n",
      "Epoch 681/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.4024 - accuracy: 0.9999 - val_loss: 25.4259 - val_accuracy: 0.9998\n",
      "Epoch 682/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3124 - accuracy: 0.9999 - val_loss: 25.3660 - val_accuracy: 0.9998\n",
      "Epoch 683/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3374 - accuracy: 0.9999 - val_loss: 25.3082 - val_accuracy: 0.9998\n",
      "Epoch 684/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3457 - accuracy: 0.9999 - val_loss: 25.5213 - val_accuracy: 0.9998\n",
      "Epoch 685/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3619 - accuracy: 0.9999 - val_loss: 25.2834 - val_accuracy: 0.9998\n",
      "Epoch 686/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3363 - accuracy: 0.9999 - val_loss: 25.3540 - val_accuracy: 0.9998\n",
      "Epoch 687/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.4870 - accuracy: 0.9999 - val_loss: 25.8253 - val_accuracy: 0.9998\n",
      "Epoch 688/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4289 - accuracy: 0.9999 - val_loss: 25.3298 - val_accuracy: 0.9998\n",
      "Epoch 689/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3212 - accuracy: 0.9999 - val_loss: 25.3229 - val_accuracy: 0.9998\n",
      "Epoch 690/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3889 - accuracy: 0.9999 - val_loss: 25.5133 - val_accuracy: 0.9998\n",
      "Epoch 691/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2941 - accuracy: 0.9999 - val_loss: 25.2083 - val_accuracy: 0.9998\n",
      "Epoch 692/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3062 - accuracy: 0.9999 - val_loss: 25.3721 - val_accuracy: 0.9998\n",
      "Epoch 693/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.5064 - accuracy: 0.9999 - val_loss: 25.3686 - val_accuracy: 0.9998\n",
      "Epoch 694/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3072 - accuracy: 0.9999 - val_loss: 25.2642 - val_accuracy: 0.9998\n",
      "Epoch 695/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.3173 - accuracy: 0.9999 - val_loss: 25.2520 - val_accuracy: 0.9998\n",
      "Epoch 696/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2989 - accuracy: 0.9999 - val_loss: 25.3304 - val_accuracy: 0.9998\n",
      "Epoch 697/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2940 - accuracy: 0.9999 - val_loss: 25.5108 - val_accuracy: 0.9998\n",
      "Epoch 698/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.3417 - accuracy: 0.9999 - val_loss: 25.2857 - val_accuracy: 0.9998\n",
      "Epoch 699/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3767 - accuracy: 0.9999 - val_loss: 25.2310 - val_accuracy: 0.9998\n",
      "Epoch 700/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2699 - accuracy: 0.9999 - val_loss: 25.2564 - val_accuracy: 0.9998\n",
      "Epoch 701/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3538 - accuracy: 0.9999 - val_loss: 25.3178 - val_accuracy: 0.9998\n",
      "Epoch 702/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3232 - accuracy: 0.9999 - val_loss: 25.2331 - val_accuracy: 0.9998\n",
      "Epoch 703/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3346 - accuracy: 0.9999 - val_loss: 25.2292 - val_accuracy: 0.9998\n",
      "Epoch 704/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2999 - accuracy: 0.9999 - val_loss: 25.3913 - val_accuracy: 0.9998\n",
      "Epoch 705/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2790 - accuracy: 0.9999 - val_loss: 25.2893 - val_accuracy: 0.9998\n",
      "Epoch 706/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3328 - accuracy: 0.9999 - val_loss: 25.3165 - val_accuracy: 0.9998\n",
      "Epoch 707/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2924 - accuracy: 0.9999 - val_loss: 25.3409 - val_accuracy: 0.9998\n",
      "Epoch 708/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2774 - accuracy: 0.9999 - val_loss: 25.2475 - val_accuracy: 0.9998\n",
      "Epoch 709/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2462 - accuracy: 0.9999 - val_loss: 25.1808 - val_accuracy: 0.9998\n",
      "Epoch 710/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2847 - accuracy: 0.9999 - val_loss: 25.2175 - val_accuracy: 0.9998\n",
      "Epoch 711/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.3547 - accuracy: 0.9999 - val_loss: 25.3324 - val_accuracy: 0.9998\n",
      "Epoch 712/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.4701 - accuracy: 0.9999 - val_loss: 25.2623 - val_accuracy: 0.9998\n",
      "Epoch 713/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3547 - accuracy: 0.9999 - val_loss: 25.2277 - val_accuracy: 0.9998\n",
      "Epoch 714/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3369 - accuracy: 0.9999 - val_loss: 25.1859 - val_accuracy: 0.9998\n",
      "Epoch 715/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3871 - accuracy: 0.9999 - val_loss: 25.1711 - val_accuracy: 0.9998\n",
      "Epoch 716/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3204 - accuracy: 0.9999 - val_loss: 25.3103 - val_accuracy: 0.9998\n",
      "Epoch 717/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3110 - accuracy: 0.9999 - val_loss: 25.2030 - val_accuracy: 0.9998\n",
      "Epoch 718/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2874 - accuracy: 0.9999 - val_loss: 25.1681 - val_accuracy: 0.9998\n",
      "Epoch 719/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2710 - accuracy: 0.9999 - val_loss: 25.5224 - val_accuracy: 0.9998\n",
      "Epoch 720/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3349 - accuracy: 0.9999 - val_loss: 25.1963 - val_accuracy: 0.9998\n",
      "Epoch 721/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2513 - accuracy: 0.9999 - val_loss: 25.1558 - val_accuracy: 0.9998\n",
      "Epoch 722/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3277 - accuracy: 0.9999 - val_loss: 25.1654 - val_accuracy: 0.9998\n",
      "Epoch 723/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2474 - accuracy: 0.9999 - val_loss: 25.1782 - val_accuracy: 0.9998\n",
      "Epoch 724/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2412 - accuracy: 0.9999 - val_loss: 25.0823 - val_accuracy: 0.9998\n",
      "Epoch 725/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2333 - accuracy: 0.9999 - val_loss: 25.1874 - val_accuracy: 0.9998\n",
      "Epoch 726/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2778 - accuracy: 0.9999 - val_loss: 25.1999 - val_accuracy: 0.9998\n",
      "Epoch 727/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2610 - accuracy: 0.9999 - val_loss: 25.1892 - val_accuracy: 0.9998\n",
      "Epoch 728/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3044 - accuracy: 0.9999 - val_loss: 25.0653 - val_accuracy: 0.9998\n",
      "Epoch 729/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2760 - accuracy: 0.9999 - val_loss: 25.4919 - val_accuracy: 0.9998\n",
      "Epoch 730/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3085 - accuracy: 0.9999 - val_loss: 25.2251 - val_accuracy: 0.9998\n",
      "Epoch 731/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2788 - accuracy: 0.9999 - val_loss: 25.1051 - val_accuracy: 0.9998\n",
      "Epoch 732/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3710 - accuracy: 0.9999 - val_loss: 25.3862 - val_accuracy: 0.9998\n",
      "Epoch 733/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3765 - accuracy: 0.9999 - val_loss: 25.1779 - val_accuracy: 0.9998\n",
      "Epoch 734/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2599 - accuracy: 0.9999 - val_loss: 25.1772 - val_accuracy: 0.9998\n",
      "Epoch 735/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2336 - accuracy: 0.9999 - val_loss: 25.1559 - val_accuracy: 0.9998\n",
      "Epoch 736/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2616 - accuracy: 0.9999 - val_loss: 25.0409 - val_accuracy: 0.9998\n",
      "Epoch 737/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2457 - accuracy: 0.9999 - val_loss: 25.1994 - val_accuracy: 0.9998\n",
      "Epoch 738/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2615 - accuracy: 0.9999 - val_loss: 25.0107 - val_accuracy: 0.9998\n",
      "Epoch 739/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3338 - accuracy: 0.9999 - val_loss: 25.1423 - val_accuracy: 0.9998\n",
      "Epoch 740/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2481 - accuracy: 0.9999 - val_loss: 25.1521 - val_accuracy: 0.9998\n",
      "Epoch 741/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2430 - accuracy: 0.9999 - val_loss: 25.1749 - val_accuracy: 0.9998\n",
      "Epoch 742/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2032 - accuracy: 0.9999 - val_loss: 25.0995 - val_accuracy: 0.9998\n",
      "Epoch 743/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3470 - accuracy: 0.9999 - val_loss: 25.1796 - val_accuracy: 0.9998\n",
      "Epoch 744/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2311 - accuracy: 0.9999 - val_loss: 25.1593 - val_accuracy: 0.9998\n",
      "Epoch 745/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2430 - accuracy: 0.9999 - val_loss: 25.0478 - val_accuracy: 0.9998\n",
      "Epoch 746/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1948 - accuracy: 0.9999 - val_loss: 25.0947 - val_accuracy: 0.9998\n",
      "Epoch 747/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2217 - accuracy: 0.9999 - val_loss: 25.2236 - val_accuracy: 0.9998\n",
      "Epoch 748/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3073 - accuracy: 0.9999 - val_loss: 25.0376 - val_accuracy: 0.9998\n",
      "Epoch 749/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2629 - accuracy: 0.9999 - val_loss: 25.0619 - val_accuracy: 0.9998\n",
      "Epoch 750/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2097 - accuracy: 0.9999 - val_loss: 25.1446 - val_accuracy: 0.9998\n",
      "Epoch 751/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2123 - accuracy: 0.9999 - val_loss: 25.0678 - val_accuracy: 0.9998\n",
      "Epoch 752/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1976 - accuracy: 0.9999 - val_loss: 25.0114 - val_accuracy: 0.9998\n",
      "Epoch 753/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2097 - accuracy: 0.9999 - val_loss: 25.0967 - val_accuracy: 0.9998\n",
      "Epoch 754/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2315 - accuracy: 0.9999 - val_loss: 25.1006 - val_accuracy: 0.9998\n",
      "Epoch 755/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2653 - accuracy: 0.9999 - val_loss: 25.0666 - val_accuracy: 0.9998\n",
      "Epoch 756/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2636 - accuracy: 0.9999 - val_loss: 25.2204 - val_accuracy: 0.9998\n",
      "Epoch 757/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2449 - accuracy: 0.9999 - val_loss: 25.0832 - val_accuracy: 0.9998\n",
      "Epoch 758/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2288 - accuracy: 0.9999 - val_loss: 25.1402 - val_accuracy: 0.9998\n",
      "Epoch 759/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3343 - accuracy: 0.9999 - val_loss: 25.2622 - val_accuracy: 0.9998\n",
      "Epoch 760/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2631 - accuracy: 0.9999 - val_loss: 25.0499 - val_accuracy: 0.9998\n",
      "Epoch 761/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1988 - accuracy: 0.9999 - val_loss: 25.0234 - val_accuracy: 0.9998\n",
      "Epoch 762/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3589 - accuracy: 0.9999 - val_loss: 25.0108 - val_accuracy: 0.9998\n",
      "Epoch 763/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3118 - accuracy: 0.9999 - val_loss: 24.9604 - val_accuracy: 0.9998\n",
      "Epoch 764/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2394 - accuracy: 0.9999 - val_loss: 25.0411 - val_accuracy: 0.9998\n",
      "Epoch 765/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2119 - accuracy: 0.9999 - val_loss: 25.2018 - val_accuracy: 0.9998\n",
      "Epoch 766/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2254 - accuracy: 0.9999 - val_loss: 24.9524 - val_accuracy: 0.9998\n",
      "Epoch 767/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2059 - accuracy: 0.9999 - val_loss: 25.0631 - val_accuracy: 0.9998\n",
      "Epoch 768/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2237 - accuracy: 0.9999 - val_loss: 24.9981 - val_accuracy: 0.9998\n",
      "Epoch 769/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2127 - accuracy: 0.9999 - val_loss: 25.0941 - val_accuracy: 0.9998\n",
      "Epoch 770/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1570 - accuracy: 0.9999 - val_loss: 25.0209 - val_accuracy: 0.9998\n",
      "Epoch 771/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2013 - accuracy: 0.9999 - val_loss: 25.0128 - val_accuracy: 0.9998\n",
      "Epoch 772/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2059 - accuracy: 0.9999 - val_loss: 25.0414 - val_accuracy: 0.9998\n",
      "Epoch 773/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2038 - accuracy: 0.9999 - val_loss: 25.1814 - val_accuracy: 0.9998\n",
      "Epoch 774/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2634 - accuracy: 0.9999 - val_loss: 24.9595 - val_accuracy: 0.9998\n",
      "Epoch 775/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2034 - accuracy: 0.9999 - val_loss: 24.9734 - val_accuracy: 0.9998\n",
      "Epoch 776/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2465 - accuracy: 0.9999 - val_loss: 25.0190 - val_accuracy: 0.9998\n",
      "Epoch 777/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2373 - accuracy: 0.9999 - val_loss: 24.9792 - val_accuracy: 0.9998\n",
      "Epoch 778/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 23.1853 - accuracy: 0.9999 - val_loss: 25.0941 - val_accuracy: 0.9998\n",
      "Epoch 779/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2967 - accuracy: 0.9999 - val_loss: 24.9126 - val_accuracy: 0.9998\n",
      "Epoch 780/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3260 - accuracy: 0.9999 - val_loss: 25.1697 - val_accuracy: 0.9998\n",
      "Epoch 781/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2007 - accuracy: 0.9999 - val_loss: 24.9793 - val_accuracy: 0.9998\n",
      "Epoch 782/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2334 - accuracy: 0.9999 - val_loss: 24.9122 - val_accuracy: 0.9998\n",
      "Epoch 783/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2064 - accuracy: 0.9999 - val_loss: 24.9137 - val_accuracy: 0.9998\n",
      "Epoch 784/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2070 - accuracy: 0.9999 - val_loss: 24.9498 - val_accuracy: 0.9998\n",
      "Epoch 785/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2612 - accuracy: 0.9999 - val_loss: 25.0573 - val_accuracy: 0.9998\n",
      "Epoch 786/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2479 - accuracy: 0.9999 - val_loss: 25.0066 - val_accuracy: 0.9998\n",
      "Epoch 787/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2464 - accuracy: 0.9999 - val_loss: 24.9623 - val_accuracy: 0.9998\n",
      "Epoch 788/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2949 - accuracy: 0.9999 - val_loss: 25.1197 - val_accuracy: 0.9998\n",
      "Epoch 789/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2119 - accuracy: 0.9999 - val_loss: 25.1474 - val_accuracy: 0.9998\n",
      "Epoch 790/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.3033 - accuracy: 0.9999 - val_loss: 24.8863 - val_accuracy: 0.9998\n",
      "Epoch 791/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2932 - accuracy: 0.9999 - val_loss: 25.0634 - val_accuracy: 0.9998\n",
      "Epoch 792/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2817 - accuracy: 0.9999 - val_loss: 24.9859 - val_accuracy: 0.9998\n",
      "Epoch 793/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1832 - accuracy: 0.9999 - val_loss: 24.9314 - val_accuracy: 0.9998\n",
      "Epoch 794/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1490 - accuracy: 0.9999 - val_loss: 24.9026 - val_accuracy: 0.9998\n",
      "Epoch 795/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1630 - accuracy: 0.9999 - val_loss: 24.9572 - val_accuracy: 0.9998\n",
      "Epoch 796/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1569 - accuracy: 0.9999 - val_loss: 24.9833 - val_accuracy: 0.9998\n",
      "Epoch 797/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1380 - accuracy: 0.9999 - val_loss: 24.9342 - val_accuracy: 0.9998\n",
      "Epoch 798/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1790 - accuracy: 0.9999 - val_loss: 24.9459 - val_accuracy: 0.9998\n",
      "Epoch 799/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1376 - accuracy: 0.9999 - val_loss: 24.8843 - val_accuracy: 0.9998\n",
      "Epoch 800/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2776 - accuracy: 0.9999 - val_loss: 25.4535 - val_accuracy: 0.9998\n",
      "Epoch 801/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.3379 - accuracy: 0.9999 - val_loss: 24.9910 - val_accuracy: 0.9998\n",
      "Epoch 802/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2589 - accuracy: 0.9999 - val_loss: 25.3645 - val_accuracy: 0.9998\n",
      "Epoch 803/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2832 - accuracy: 0.9999 - val_loss: 25.1043 - val_accuracy: 0.9998\n",
      "Epoch 804/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.2188 - accuracy: 0.9999 - val_loss: 25.0282 - val_accuracy: 0.9998\n",
      "Epoch 805/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1443 - accuracy: 0.9999 - val_loss: 24.9139 - val_accuracy: 0.9998\n",
      "Epoch 806/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1031 - accuracy: 0.9999 - val_loss: 24.9287 - val_accuracy: 0.9998\n",
      "Epoch 807/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1225 - accuracy: 0.9999 - val_loss: 24.9188 - val_accuracy: 0.9998\n",
      "Epoch 808/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1265 - accuracy: 0.9999 - val_loss: 24.9086 - val_accuracy: 0.9998\n",
      "Epoch 809/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1292 - accuracy: 0.9999 - val_loss: 24.8895 - val_accuracy: 0.9998\n",
      "Epoch 810/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1098 - accuracy: 0.9999 - val_loss: 24.8569 - val_accuracy: 0.9998\n",
      "Epoch 811/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1373 - accuracy: 0.9999 - val_loss: 24.9171 - val_accuracy: 0.9998\n",
      "Epoch 812/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1022 - accuracy: 0.9999 - val_loss: 24.9991 - val_accuracy: 0.9998\n",
      "Epoch 813/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1444 - accuracy: 0.9999 - val_loss: 24.8839 - val_accuracy: 0.9998\n",
      "Epoch 814/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1346 - accuracy: 0.9999 - val_loss: 24.9004 - val_accuracy: 0.9998\n",
      "Epoch 815/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1140 - accuracy: 0.9999 - val_loss: 24.8241 - val_accuracy: 0.9998\n",
      "Epoch 816/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1060 - accuracy: 0.9999 - val_loss: 24.8465 - val_accuracy: 0.9998\n",
      "Epoch 817/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1741 - accuracy: 0.9999 - val_loss: 24.8134 - val_accuracy: 0.9998\n",
      "Epoch 818/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1070 - accuracy: 0.9999 - val_loss: 24.8268 - val_accuracy: 0.9998\n",
      "Epoch 819/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0751 - accuracy: 0.9999 - val_loss: 24.9826 - val_accuracy: 0.9998\n",
      "Epoch 820/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1320 - accuracy: 0.9999 - val_loss: 24.8314 - val_accuracy: 0.9998\n",
      "Epoch 821/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1267 - accuracy: 0.9999 - val_loss: 25.0047 - val_accuracy: 0.9998\n",
      "Epoch 822/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0944 - accuracy: 0.9999 - val_loss: 24.8301 - val_accuracy: 0.9998\n",
      "Epoch 823/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1183 - accuracy: 0.9999 - val_loss: 25.1087 - val_accuracy: 0.9998\n",
      "Epoch 824/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1579 - accuracy: 0.9999 - val_loss: 24.9571 - val_accuracy: 0.9998\n",
      "Epoch 825/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.0880 - accuracy: 0.9999 - val_loss: 24.8177 - val_accuracy: 0.9998\n",
      "Epoch 826/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0993 - accuracy: 0.9999 - val_loss: 24.8557 - val_accuracy: 0.9998\n",
      "Epoch 827/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1218 - accuracy: 0.9999 - val_loss: 24.8752 - val_accuracy: 0.9998\n",
      "Epoch 828/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1720 - accuracy: 0.9999 - val_loss: 24.8458 - val_accuracy: 0.9998\n",
      "Epoch 829/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1733 - accuracy: 0.9999 - val_loss: 24.7563 - val_accuracy: 0.9998\n",
      "Epoch 830/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0931 - accuracy: 0.9999 - val_loss: 24.9163 - val_accuracy: 0.9998\n",
      "Epoch 831/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1568 - accuracy: 0.9999 - val_loss: 24.9516 - val_accuracy: 0.9998\n",
      "Epoch 832/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0904 - accuracy: 0.9999 - val_loss: 24.7788 - val_accuracy: 0.9998\n",
      "Epoch 833/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1992 - accuracy: 0.9999 - val_loss: 24.8482 - val_accuracy: 0.9998\n",
      "Epoch 834/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1387 - accuracy: 0.9999 - val_loss: 24.7931 - val_accuracy: 0.9998\n",
      "Epoch 835/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0939 - accuracy: 0.9999 - val_loss: 24.8293 - val_accuracy: 0.9998\n",
      "Epoch 836/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0546 - accuracy: 0.9999 - val_loss: 24.8469 - val_accuracy: 0.9998\n",
      "Epoch 837/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0997 - accuracy: 0.9999 - val_loss: 24.9994 - val_accuracy: 0.9998\n",
      "Epoch 838/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.2415 - accuracy: 0.9999 - val_loss: 24.8597 - val_accuracy: 0.9998\n",
      "Epoch 839/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2163 - accuracy: 0.9999 - val_loss: 24.8157 - val_accuracy: 0.9998\n",
      "Epoch 840/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.2701 - accuracy: 0.9999 - val_loss: 24.7413 - val_accuracy: 0.9998\n",
      "Epoch 841/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1630 - accuracy: 0.9999 - val_loss: 24.7207 - val_accuracy: 0.9998\n",
      "Epoch 842/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0983 - accuracy: 0.9999 - val_loss: 24.8201 - val_accuracy: 0.9998\n",
      "Epoch 843/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1474 - accuracy: 0.9999 - val_loss: 24.7428 - val_accuracy: 0.9998\n",
      "Epoch 844/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1822 - accuracy: 0.9999 - val_loss: 24.8200 - val_accuracy: 0.9998\n",
      "Epoch 845/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1299 - accuracy: 0.9999 - val_loss: 24.8799 - val_accuracy: 0.9998\n",
      "Epoch 846/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0563 - accuracy: 0.9999 - val_loss: 24.8666 - val_accuracy: 0.9998\n",
      "Epoch 847/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0926 - accuracy: 0.9999 - val_loss: 24.7991 - val_accuracy: 0.9998\n",
      "Epoch 848/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0850 - accuracy: 0.9999 - val_loss: 24.7514 - val_accuracy: 0.9998\n",
      "Epoch 849/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.0882 - accuracy: 0.9999 - val_loss: 24.8582 - val_accuracy: 0.9998\n",
      "Epoch 850/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1068 - accuracy: 0.9999 - val_loss: 25.0330 - val_accuracy: 0.9998\n",
      "Epoch 851/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1507 - accuracy: 0.9999 - val_loss: 24.9557 - val_accuracy: 0.9998\n",
      "Epoch 852/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1333 - accuracy: 0.9999 - val_loss: 24.7356 - val_accuracy: 0.9998\n",
      "Epoch 853/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0804 - accuracy: 0.9999 - val_loss: 24.7015 - val_accuracy: 0.9998\n",
      "Epoch 854/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0503 - accuracy: 0.9999 - val_loss: 24.7446 - val_accuracy: 0.9998\n",
      "Epoch 855/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1014 - accuracy: 0.9999 - val_loss: 24.8032 - val_accuracy: 0.9998\n",
      "Epoch 856/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1335 - accuracy: 0.9999 - val_loss: 24.8404 - val_accuracy: 0.9998\n",
      "Epoch 857/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0233 - accuracy: 0.9999 - val_loss: 24.6711 - val_accuracy: 0.9998\n",
      "Epoch 858/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.1013 - accuracy: 0.9999 - val_loss: 24.8009 - val_accuracy: 0.9998\n",
      "Epoch 859/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1000 - accuracy: 0.9999 - val_loss: 24.7127 - val_accuracy: 0.9998\n",
      "Epoch 860/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1530 - accuracy: 0.9999 - val_loss: 24.6996 - val_accuracy: 0.9998\n",
      "Epoch 861/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0791 - accuracy: 0.9999 - val_loss: 24.7017 - val_accuracy: 0.9998\n",
      "Epoch 862/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1210 - accuracy: 0.9999 - val_loss: 24.8769 - val_accuracy: 0.9998\n",
      "Epoch 863/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0624 - accuracy: 0.9999 - val_loss: 24.7049 - val_accuracy: 0.9998\n",
      "Epoch 864/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0092 - accuracy: 0.9999 - val_loss: 24.7710 - val_accuracy: 0.9998\n",
      "Epoch 865/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0183 - accuracy: 0.9999 - val_loss: 24.7596 - val_accuracy: 0.9998\n",
      "Epoch 866/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0429 - accuracy: 0.9999 - val_loss: 24.7492 - val_accuracy: 0.9998\n",
      "Epoch 867/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0401 - accuracy: 0.9999 - val_loss: 24.6986 - val_accuracy: 0.9998\n",
      "Epoch 868/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0089 - accuracy: 0.9999 - val_loss: 24.7258 - val_accuracy: 0.9998\n",
      "Epoch 869/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0268 - accuracy: 0.9999 - val_loss: 24.6461 - val_accuracy: 0.9998\n",
      "Epoch 870/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.0412 - accuracy: 0.9999 - val_loss: 24.7797 - val_accuracy: 0.9998\n",
      "Epoch 871/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0485 - accuracy: 0.9999 - val_loss: 24.7221 - val_accuracy: 0.9998\n",
      "Epoch 872/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1171 - accuracy: 0.9999 - val_loss: 24.7018 - val_accuracy: 0.9998\n",
      "Epoch 873/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0271 - accuracy: 0.9999 - val_loss: 24.6905 - val_accuracy: 0.9998\n",
      "Epoch 874/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0345 - accuracy: 0.9999 - val_loss: 24.6887 - val_accuracy: 0.9998\n",
      "Epoch 875/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0509 - accuracy: 0.9999 - val_loss: 24.8652 - val_accuracy: 0.9998\n",
      "Epoch 876/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0081 - accuracy: 0.9999 - val_loss: 24.7207 - val_accuracy: 0.9998\n",
      "Epoch 877/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0171 - accuracy: 0.9999 - val_loss: 24.6834 - val_accuracy: 0.9998\n",
      "Epoch 878/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 23.0118 - accuracy: 0.9999 - val_loss: 24.6579 - val_accuracy: 0.9998\n",
      "Epoch 879/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0929 - accuracy: 0.9999 - val_loss: 24.7411 - val_accuracy: 0.9998\n",
      "Epoch 880/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.1948 - accuracy: 0.9999 - val_loss: 24.6229 - val_accuracy: 0.9998\n",
      "Epoch 881/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0988 - accuracy: 0.9999 - val_loss: 24.7046 - val_accuracy: 0.9998\n",
      "Epoch 882/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0343 - accuracy: 0.9999 - val_loss: 24.5732 - val_accuracy: 0.9998\n",
      "Epoch 883/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9988 - accuracy: 0.9999 - val_loss: 24.5948 - val_accuracy: 0.9998\n",
      "Epoch 884/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0699 - accuracy: 0.9999 - val_loss: 24.6743 - val_accuracy: 0.9998\n",
      "Epoch 885/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9817 - accuracy: 0.9999 - val_loss: 24.6289 - val_accuracy: 0.9998\n",
      "Epoch 886/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0033 - accuracy: 0.9999 - val_loss: 24.6440 - val_accuracy: 0.9998\n",
      "Epoch 887/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.1604 - accuracy: 0.9999 - val_loss: 24.7590 - val_accuracy: 0.9998\n",
      "Epoch 888/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0191 - accuracy: 0.9999 - val_loss: 24.6972 - val_accuracy: 0.9998\n",
      "Epoch 889/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0989 - accuracy: 0.9999 - val_loss: 24.6977 - val_accuracy: 0.9998\n",
      "Epoch 890/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0023 - accuracy: 0.9999 - val_loss: 24.6310 - val_accuracy: 0.9998\n",
      "Epoch 891/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9702 - accuracy: 0.9999 - val_loss: 24.6020 - val_accuracy: 0.9998\n",
      "Epoch 892/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9905 - accuracy: 0.9999 - val_loss: 24.5938 - val_accuracy: 0.9998\n",
      "Epoch 893/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.9909 - accuracy: 0.9999 - val_loss: 24.6875 - val_accuracy: 0.9998\n",
      "Epoch 894/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0007 - accuracy: 0.9999 - val_loss: 24.5772 - val_accuracy: 0.9998\n",
      "Epoch 895/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9784 - accuracy: 0.9999 - val_loss: 24.5650 - val_accuracy: 0.9998\n",
      "Epoch 896/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9584 - accuracy: 0.9999 - val_loss: 24.6584 - val_accuracy: 0.9998\n",
      "Epoch 897/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9658 - accuracy: 0.9999 - val_loss: 24.5533 - val_accuracy: 0.9998\n",
      "Epoch 898/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9749 - accuracy: 0.9999 - val_loss: 24.5553 - val_accuracy: 0.9998\n",
      "Epoch 899/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9534 - accuracy: 0.9999 - val_loss: 24.5361 - val_accuracy: 0.9998\n",
      "Epoch 900/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9658 - accuracy: 0.9999 - val_loss: 24.5742 - val_accuracy: 0.9998\n",
      "Epoch 901/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9951 - accuracy: 0.9999 - val_loss: 24.7643 - val_accuracy: 0.9998\n",
      "Epoch 902/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9683 - accuracy: 0.9999 - val_loss: 24.6067 - val_accuracy: 0.9998\n",
      "Epoch 903/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9789 - accuracy: 0.9999 - val_loss: 24.5945 - val_accuracy: 0.9998\n",
      "Epoch 904/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0596 - accuracy: 0.9999 - val_loss: 24.6607 - val_accuracy: 0.9998\n",
      "Epoch 905/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0079 - accuracy: 0.9999 - val_loss: 24.5403 - val_accuracy: 0.9998\n",
      "Epoch 906/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9682 - accuracy: 0.9999 - val_loss: 24.4972 - val_accuracy: 1.0000\n",
      "Epoch 907/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0670 - accuracy: 0.9999 - val_loss: 24.5815 - val_accuracy: 0.9998\n",
      "Epoch 908/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.9541 - accuracy: 0.9999 - val_loss: 24.5903 - val_accuracy: 0.9998\n",
      "Epoch 909/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9929 - accuracy: 0.9999 - val_loss: 24.5824 - val_accuracy: 0.9998\n",
      "Epoch 910/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9817 - accuracy: 0.9999 - val_loss: 24.5316 - val_accuracy: 0.9998\n",
      "Epoch 911/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9569 - accuracy: 0.9999 - val_loss: 24.5811 - val_accuracy: 0.9998\n",
      "Epoch 912/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9395 - accuracy: 0.9999 - val_loss: 24.4865 - val_accuracy: 0.9998\n",
      "Epoch 913/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0395 - accuracy: 1.0000 - val_loss: 24.5304 - val_accuracy: 1.0000\n",
      "Epoch 914/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9544 - accuracy: 0.9999 - val_loss: 24.6078 - val_accuracy: 0.9998\n",
      "Epoch 915/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9789 - accuracy: 0.9999 - val_loss: 24.4582 - val_accuracy: 0.9998\n",
      "Epoch 916/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9775 - accuracy: 0.9999 - val_loss: 24.5065 - val_accuracy: 0.9998\n",
      "Epoch 917/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9950 - accuracy: 0.9999 - val_loss: 24.6704 - val_accuracy: 0.9998\n",
      "Epoch 918/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9183 - accuracy: 0.9999 - val_loss: 24.5669 - val_accuracy: 0.9998\n",
      "Epoch 919/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9658 - accuracy: 0.9999 - val_loss: 24.5347 - val_accuracy: 0.9998\n",
      "Epoch 920/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9466 - accuracy: 0.9999 - val_loss: 24.5349 - val_accuracy: 0.9998\n",
      "Epoch 921/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.9635 - accuracy: 0.9999 - val_loss: 24.6280 - val_accuracy: 0.9998\n",
      "Epoch 922/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9345 - accuracy: 0.9999 - val_loss: 24.5241 - val_accuracy: 0.9998\n",
      "Epoch 923/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0118 - accuracy: 0.9999 - val_loss: 24.5743 - val_accuracy: 0.9998\n",
      "Epoch 924/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0052 - accuracy: 0.9999 - val_loss: 24.4565 - val_accuracy: 1.0000\n",
      "Epoch 925/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9504 - accuracy: 0.9999 - val_loss: 24.5607 - val_accuracy: 0.9998\n",
      "Epoch 926/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9481 - accuracy: 0.9999 - val_loss: 24.3961 - val_accuracy: 1.0000\n",
      "Epoch 927/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.9347 - accuracy: 0.9999 - val_loss: 24.5495 - val_accuracy: 0.9998\n",
      "Epoch 928/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9251 - accuracy: 0.9999 - val_loss: 24.4503 - val_accuracy: 0.9998\n",
      "Epoch 929/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9395 - accuracy: 0.9999 - val_loss: 24.6231 - val_accuracy: 0.9998\n",
      "Epoch 930/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9448 - accuracy: 0.9999 - val_loss: 24.4462 - val_accuracy: 0.9998\n",
      "Epoch 931/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9028 - accuracy: 0.9999 - val_loss: 24.4577 - val_accuracy: 0.9998\n",
      "Epoch 932/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.9239 - accuracy: 0.9999 - val_loss: 24.4395 - val_accuracy: 0.9998\n",
      "Epoch 933/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9275 - accuracy: 0.9999 - val_loss: 24.5494 - val_accuracy: 0.9998\n",
      "Epoch 934/1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 22.9294 - accuracy: 0.9999 - val_loss: 24.4874 - val_accuracy: 1.0000\n",
      "Epoch 935/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9296 - accuracy: 0.9999 - val_loss: 24.4240 - val_accuracy: 0.9998\n",
      "Epoch 936/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9592 - accuracy: 0.9999 - val_loss: 24.5355 - val_accuracy: 0.9998\n",
      "Epoch 937/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9418 - accuracy: 0.9999 - val_loss: 24.4360 - val_accuracy: 1.0000\n",
      "Epoch 938/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9561 - accuracy: 0.9999 - val_loss: 24.4885 - val_accuracy: 0.9998\n",
      "Epoch 939/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9924 - accuracy: 0.9999 - val_loss: 24.5707 - val_accuracy: 1.0000\n",
      "Epoch 940/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9414 - accuracy: 0.9999 - val_loss: 24.3930 - val_accuracy: 0.9998\n",
      "Epoch 941/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9781 - accuracy: 0.9999 - val_loss: 24.4189 - val_accuracy: 0.9998\n",
      "Epoch 942/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9343 - accuracy: 1.0000 - val_loss: 24.4824 - val_accuracy: 1.0000\n",
      "Epoch 943/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9452 - accuracy: 0.9999 - val_loss: 24.5425 - val_accuracy: 0.9998\n",
      "Epoch 944/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9646 - accuracy: 0.9999 - val_loss: 24.5618 - val_accuracy: 0.9998\n",
      "Epoch 945/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.9209 - accuracy: 0.9999 - val_loss: 24.5583 - val_accuracy: 1.0000\n",
      "Epoch 946/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9553 - accuracy: 0.9999 - val_loss: 24.3721 - val_accuracy: 1.0000\n",
      "Epoch 947/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9096 - accuracy: 0.9999 - val_loss: 24.4700 - val_accuracy: 0.9998\n",
      "Epoch 948/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9240 - accuracy: 0.9999 - val_loss: 24.7409 - val_accuracy: 1.0000\n",
      "Epoch 949/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0589 - accuracy: 0.9999 - val_loss: 24.3929 - val_accuracy: 0.9998\n",
      "Epoch 950/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 23.0073 - accuracy: 0.9999 - val_loss: 24.6163 - val_accuracy: 0.9998\n",
      "Epoch 951/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9739 - accuracy: 0.9999 - val_loss: 24.3714 - val_accuracy: 1.0000\n",
      "Epoch 952/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8826 - accuracy: 0.9999 - val_loss: 24.4288 - val_accuracy: 0.9998\n",
      "Epoch 953/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8695 - accuracy: 0.9999 - val_loss: 24.4475 - val_accuracy: 0.9998\n",
      "Epoch 954/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8935 - accuracy: 0.9999 - val_loss: 24.3569 - val_accuracy: 1.0000\n",
      "Epoch 955/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9430 - accuracy: 0.9999 - val_loss: 24.3957 - val_accuracy: 0.9998\n",
      "Epoch 956/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9094 - accuracy: 0.9999 - val_loss: 24.3977 - val_accuracy: 0.9998\n",
      "Epoch 957/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9197 - accuracy: 0.9999 - val_loss: 24.3741 - val_accuracy: 1.0000\n",
      "Epoch 958/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8704 - accuracy: 0.9999 - val_loss: 24.4072 - val_accuracy: 0.9998\n",
      "Epoch 959/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8898 - accuracy: 0.9999 - val_loss: 24.3051 - val_accuracy: 1.0000\n",
      "Epoch 960/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8841 - accuracy: 0.9999 - val_loss: 24.4034 - val_accuracy: 0.9998\n",
      "Epoch 961/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8801 - accuracy: 0.9999 - val_loss: 24.3513 - val_accuracy: 0.9998\n",
      "Epoch 962/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8524 - accuracy: 0.9999 - val_loss: 24.3544 - val_accuracy: 1.0000\n",
      "Epoch 963/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9129 - accuracy: 0.9999 - val_loss: 24.4068 - val_accuracy: 0.9998\n",
      "Epoch 964/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9410 - accuracy: 0.9999 - val_loss: 24.2982 - val_accuracy: 1.0000\n",
      "Epoch 965/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9089 - accuracy: 0.9999 - val_loss: 24.3807 - val_accuracy: 1.0000\n",
      "Epoch 966/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9468 - accuracy: 0.9999 - val_loss: 24.3407 - val_accuracy: 0.9998\n",
      "Epoch 967/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9699 - accuracy: 0.9999 - val_loss: 24.6331 - val_accuracy: 1.0000\n",
      "Epoch 968/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9531 - accuracy: 0.9999 - val_loss: 24.2843 - val_accuracy: 0.9998\n",
      "Epoch 969/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8434 - accuracy: 0.9999 - val_loss: 24.3551 - val_accuracy: 1.0000\n",
      "Epoch 970/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8850 - accuracy: 0.9999 - val_loss: 24.3578 - val_accuracy: 1.0000\n",
      "Epoch 971/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9352 - accuracy: 0.9999 - val_loss: 24.3006 - val_accuracy: 1.0000\n",
      "Epoch 972/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9314 - accuracy: 0.9999 - val_loss: 24.3053 - val_accuracy: 1.0000\n",
      "Epoch 973/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9036 - accuracy: 0.9999 - val_loss: 24.4281 - val_accuracy: 0.9998\n",
      "Epoch 974/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9178 - accuracy: 0.9999 - val_loss: 24.3572 - val_accuracy: 0.9998\n",
      "Epoch 975/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8634 - accuracy: 0.9999 - val_loss: 24.4178 - val_accuracy: 1.0000\n",
      "Epoch 976/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8829 - accuracy: 0.9999 - val_loss: 24.2729 - val_accuracy: 1.0000\n",
      "Epoch 977/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8821 - accuracy: 0.9999 - val_loss: 24.3606 - val_accuracy: 0.9998\n",
      "Epoch 978/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8713 - accuracy: 0.9999 - val_loss: 24.3800 - val_accuracy: 1.0000\n",
      "Epoch 979/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8816 - accuracy: 0.9999 - val_loss: 24.2887 - val_accuracy: 0.9998\n",
      "Epoch 980/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8720 - accuracy: 0.9999 - val_loss: 24.3675 - val_accuracy: 1.0000\n",
      "Epoch 981/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9305 - accuracy: 0.9999 - val_loss: 24.3989 - val_accuracy: 1.0000\n",
      "Epoch 982/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8944 - accuracy: 0.9999 - val_loss: 24.3461 - val_accuracy: 1.0000\n",
      "Epoch 983/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8978 - accuracy: 0.9999 - val_loss: 24.3629 - val_accuracy: 1.0000\n",
      "Epoch 984/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8694 - accuracy: 0.9999 - val_loss: 24.3805 - val_accuracy: 1.0000\n",
      "Epoch 985/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9313 - accuracy: 0.9999 - val_loss: 24.3107 - val_accuracy: 0.9998\n",
      "Epoch 986/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8265 - accuracy: 0.9999 - val_loss: 24.4595 - val_accuracy: 1.0000\n",
      "Epoch 987/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9603 - accuracy: 0.9999 - val_loss: 24.2994 - val_accuracy: 1.0000\n",
      "Epoch 988/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8849 - accuracy: 0.9999 - val_loss: 24.3231 - val_accuracy: 1.0000\n",
      "Epoch 989/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8882 - accuracy: 0.9999 - val_loss: 24.3177 - val_accuracy: 1.0000\n",
      "Epoch 990/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8698 - accuracy: 0.9999 - val_loss: 24.3018 - val_accuracy: 1.0000\n",
      "Epoch 991/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8476 - accuracy: 0.9999 - val_loss: 24.2946 - val_accuracy: 0.9998\n",
      "Epoch 992/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8443 - accuracy: 0.9999 - val_loss: 24.2456 - val_accuracy: 1.0000\n",
      "Epoch 993/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8841 - accuracy: 0.9999 - val_loss: 24.3931 - val_accuracy: 1.0000\n",
      "Epoch 994/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9394 - accuracy: 0.9999 - val_loss: 24.6654 - val_accuracy: 0.9998\n",
      "Epoch 995/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.9507 - accuracy: 0.9999 - val_loss: 24.2845 - val_accuracy: 1.0000\n",
      "Epoch 996/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8674 - accuracy: 0.9999 - val_loss: 24.3308 - val_accuracy: 1.0000\n",
      "Epoch 997/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8833 - accuracy: 0.9999 - val_loss: 24.2351 - val_accuracy: 1.0000\n",
      "Epoch 998/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8973 - accuracy: 0.9999 - val_loss: 24.2316 - val_accuracy: 1.0000\n",
      "Epoch 999/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8237 - accuracy: 0.9999 - val_loss: 24.2614 - val_accuracy: 0.9998\n",
      "Epoch 1000/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8928 - accuracy: 0.9999 - val_loss: 24.3373 - val_accuracy: 1.0000\n",
      "Epoch 1001/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8970 - accuracy: 0.9999 - val_loss: 24.2814 - val_accuracy: 1.0000\n",
      "Epoch 1002/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8265 - accuracy: 0.9999 - val_loss: 24.2422 - val_accuracy: 1.0000\n",
      "Epoch 1003/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8574 - accuracy: 0.9999 - val_loss: 24.3142 - val_accuracy: 1.0000\n",
      "Epoch 1004/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8524 - accuracy: 0.9999 - val_loss: 24.2021 - val_accuracy: 1.0000\n",
      "Epoch 1005/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8331 - accuracy: 0.9999 - val_loss: 24.2650 - val_accuracy: 0.9998\n",
      "Epoch 1006/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8385 - accuracy: 0.9999 - val_loss: 24.2254 - val_accuracy: 1.0000\n",
      "Epoch 1007/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8101 - accuracy: 0.9999 - val_loss: 24.3209 - val_accuracy: 1.0000\n",
      "Epoch 1008/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.0080 - accuracy: 0.9999 - val_loss: 24.3710 - val_accuracy: 1.0000\n",
      "Epoch 1009/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9004 - accuracy: 0.9999 - val_loss: 24.4149 - val_accuracy: 0.9998\n",
      "Epoch 1010/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8543 - accuracy: 0.9999 - val_loss: 24.2339 - val_accuracy: 1.0000\n",
      "Epoch 1011/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8349 - accuracy: 0.9999 - val_loss: 24.2047 - val_accuracy: 1.0000\n",
      "Epoch 1012/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8164 - accuracy: 0.9999 - val_loss: 24.3330 - val_accuracy: 1.0000\n",
      "Epoch 1013/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8310 - accuracy: 0.9999 - val_loss: 24.1589 - val_accuracy: 1.0000\n",
      "Epoch 1014/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8105 - accuracy: 0.9999 - val_loss: 24.2265 - val_accuracy: 1.0000\n",
      "Epoch 1015/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8851 - accuracy: 0.9999 - val_loss: 24.2977 - val_accuracy: 1.0000\n",
      "Epoch 1016/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8662 - accuracy: 0.9999 - val_loss: 24.2256 - val_accuracy: 1.0000\n",
      "Epoch 1017/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8562 - accuracy: 0.9999 - val_loss: 24.1755 - val_accuracy: 1.0000\n",
      "Epoch 1018/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8372 - accuracy: 0.9999 - val_loss: 24.2600 - val_accuracy: 1.0000\n",
      "Epoch 1019/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8742 - accuracy: 0.9999 - val_loss: 24.1527 - val_accuracy: 1.0000\n",
      "Epoch 1020/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9020 - accuracy: 1.0000 - val_loss: 24.2511 - val_accuracy: 1.0000\n",
      "Epoch 1021/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8138 - accuracy: 0.9999 - val_loss: 24.2517 - val_accuracy: 1.0000\n",
      "Epoch 1022/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8019 - accuracy: 0.9999 - val_loss: 24.2127 - val_accuracy: 1.0000\n",
      "Epoch 1023/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8051 - accuracy: 0.9999 - val_loss: 24.1999 - val_accuracy: 1.0000\n",
      "Epoch 1024/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8298 - accuracy: 0.9999 - val_loss: 24.2255 - val_accuracy: 1.0000\n",
      "Epoch 1025/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7909 - accuracy: 0.9999 - val_loss: 24.2096 - val_accuracy: 1.0000\n",
      "Epoch 1026/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8690 - accuracy: 0.9999 - val_loss: 24.6468 - val_accuracy: 1.0000\n",
      "Epoch 1027/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8811 - accuracy: 0.9999 - val_loss: 24.3513 - val_accuracy: 1.0000\n",
      "Epoch 1028/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.8092 - accuracy: 0.9999 - val_loss: 24.1968 - val_accuracy: 1.0000\n",
      "Epoch 1029/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8228 - accuracy: 0.9999 - val_loss: 24.1273 - val_accuracy: 1.0000\n",
      "Epoch 1030/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8550 - accuracy: 0.9999 - val_loss: 24.1669 - val_accuracy: 1.0000\n",
      "Epoch 1031/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7954 - accuracy: 1.0000 - val_loss: 24.2224 - val_accuracy: 1.0000\n",
      "Epoch 1032/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8081 - accuracy: 0.9999 - val_loss: 24.1446 - val_accuracy: 1.0000\n",
      "Epoch 1033/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7552 - accuracy: 0.9999 - val_loss: 24.2091 - val_accuracy: 1.0000\n",
      "Epoch 1034/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7884 - accuracy: 0.9999 - val_loss: 24.1040 - val_accuracy: 1.0000\n",
      "Epoch 1035/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8086 - accuracy: 0.9999 - val_loss: 24.1232 - val_accuracy: 1.0000\n",
      "Epoch 1036/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8005 - accuracy: 0.9999 - val_loss: 24.2179 - val_accuracy: 1.0000\n",
      "Epoch 1037/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9307 - accuracy: 1.0000 - val_loss: 24.5041 - val_accuracy: 1.0000\n",
      "Epoch 1038/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8498 - accuracy: 0.9999 - val_loss: 24.2035 - val_accuracy: 1.0000\n",
      "Epoch 1039/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7543 - accuracy: 0.9999 - val_loss: 24.1758 - val_accuracy: 1.0000\n",
      "Epoch 1040/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7587 - accuracy: 0.9999 - val_loss: 24.1333 - val_accuracy: 1.0000\n",
      "Epoch 1041/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7717 - accuracy: 0.9999 - val_loss: 24.1262 - val_accuracy: 1.0000\n",
      "Epoch 1042/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8026 - accuracy: 0.9999 - val_loss: 24.0537 - val_accuracy: 1.0000\n",
      "Epoch 1043/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7372 - accuracy: 0.9999 - val_loss: 24.1509 - val_accuracy: 1.0000\n",
      "Epoch 1044/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7878 - accuracy: 0.9999 - val_loss: 24.2009 - val_accuracy: 1.0000\n",
      "Epoch 1045/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7440 - accuracy: 0.9999 - val_loss: 24.1213 - val_accuracy: 1.0000\n",
      "Epoch 1046/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8064 - accuracy: 1.0000 - val_loss: 24.1828 - val_accuracy: 1.0000\n",
      "Epoch 1047/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8024 - accuracy: 0.9999 - val_loss: 24.0557 - val_accuracy: 1.0000\n",
      "Epoch 1048/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7743 - accuracy: 0.9999 - val_loss: 24.1141 - val_accuracy: 1.0000\n",
      "Epoch 1049/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7627 - accuracy: 1.0000 - val_loss: 24.1457 - val_accuracy: 1.0000\n",
      "Epoch 1050/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7694 - accuracy: 0.9999 - val_loss: 24.1403 - val_accuracy: 1.0000\n",
      "Epoch 1051/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8222 - accuracy: 0.9999 - val_loss: 24.1428 - val_accuracy: 1.0000\n",
      "Epoch 1052/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7832 - accuracy: 0.9999 - val_loss: 24.1601 - val_accuracy: 1.0000\n",
      "Epoch 1053/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7474 - accuracy: 0.9999 - val_loss: 24.2250 - val_accuracy: 1.0000\n",
      "Epoch 1054/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7838 - accuracy: 0.9999 - val_loss: 24.1926 - val_accuracy: 1.0000\n",
      "Epoch 1055/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7573 - accuracy: 1.0000 - val_loss: 24.1082 - val_accuracy: 1.0000\n",
      "Epoch 1056/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7655 - accuracy: 0.9999 - val_loss: 24.2250 - val_accuracy: 1.0000\n",
      "Epoch 1057/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7609 - accuracy: 0.9999 - val_loss: 24.0933 - val_accuracy: 1.0000\n",
      "Epoch 1058/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7161 - accuracy: 0.9999 - val_loss: 24.0702 - val_accuracy: 1.0000\n",
      "Epoch 1059/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7233 - accuracy: 0.9999 - val_loss: 24.1347 - val_accuracy: 1.0000\n",
      "Epoch 1060/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7615 - accuracy: 0.9999 - val_loss: 24.1151 - val_accuracy: 1.0000\n",
      "Epoch 1061/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8302 - accuracy: 0.9999 - val_loss: 24.0037 - val_accuracy: 1.0000\n",
      "Epoch 1062/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8466 - accuracy: 0.9999 - val_loss: 24.0740 - val_accuracy: 1.0000\n",
      "Epoch 1063/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8241 - accuracy: 0.9999 - val_loss: 24.0383 - val_accuracy: 1.0000\n",
      "Epoch 1064/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7543 - accuracy: 0.9999 - val_loss: 24.0129 - val_accuracy: 1.0000\n",
      "Epoch 1065/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8267 - accuracy: 0.9999 - val_loss: 24.1785 - val_accuracy: 1.0000\n",
      "Epoch 1066/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8208 - accuracy: 0.9999 - val_loss: 24.1010 - val_accuracy: 1.0000\n",
      "Epoch 1067/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7641 - accuracy: 0.9999 - val_loss: 24.0149 - val_accuracy: 1.0000\n",
      "Epoch 1068/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7117 - accuracy: 0.9999 - val_loss: 24.0634 - val_accuracy: 1.0000\n",
      "Epoch 1069/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7264 - accuracy: 0.9999 - val_loss: 24.0286 - val_accuracy: 1.0000\n",
      "Epoch 1070/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7511 - accuracy: 0.9999 - val_loss: 24.0010 - val_accuracy: 1.0000\n",
      "Epoch 1071/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7329 - accuracy: 0.9999 - val_loss: 24.0080 - val_accuracy: 1.0000\n",
      "Epoch 1072/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7260 - accuracy: 0.9999 - val_loss: 24.1563 - val_accuracy: 1.0000\n",
      "Epoch 1073/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7118 - accuracy: 1.0000 - val_loss: 24.0124 - val_accuracy: 1.0000\n",
      "Epoch 1074/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7399 - accuracy: 0.9999 - val_loss: 24.0258 - val_accuracy: 1.0000\n",
      "Epoch 1075/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6989 - accuracy: 0.9999 - val_loss: 24.0308 - val_accuracy: 1.0000\n",
      "Epoch 1076/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7875 - accuracy: 0.9999 - val_loss: 24.0469 - val_accuracy: 1.0000\n",
      "Epoch 1077/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7769 - accuracy: 0.9999 - val_loss: 24.0565 - val_accuracy: 1.0000\n",
      "Epoch 1078/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.8322 - accuracy: 0.9999 - val_loss: 24.1116 - val_accuracy: 1.0000\n",
      "Epoch 1079/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7274 - accuracy: 1.0000 - val_loss: 24.0623 - val_accuracy: 1.0000\n",
      "Epoch 1080/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6976 - accuracy: 0.9999 - val_loss: 24.0447 - val_accuracy: 1.0000\n",
      "Epoch 1081/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7070 - accuracy: 0.9999 - val_loss: 24.0944 - val_accuracy: 1.0000\n",
      "Epoch 1082/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.8182 - accuracy: 1.0000 - val_loss: 24.3976 - val_accuracy: 1.0000\n",
      "Epoch 1083/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7507 - accuracy: 0.9999 - val_loss: 24.0232 - val_accuracy: 1.0000\n",
      "Epoch 1084/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6930 - accuracy: 0.9999 - val_loss: 24.0240 - val_accuracy: 1.0000\n",
      "Epoch 1085/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7466 - accuracy: 0.9999 - val_loss: 23.9453 - val_accuracy: 1.0000\n",
      "Epoch 1086/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7041 - accuracy: 0.9999 - val_loss: 24.0459 - val_accuracy: 1.0000\n",
      "Epoch 1087/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7245 - accuracy: 0.9999 - val_loss: 24.0095 - val_accuracy: 1.0000\n",
      "Epoch 1088/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7023 - accuracy: 0.9999 - val_loss: 24.0706 - val_accuracy: 1.0000\n",
      "Epoch 1089/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7978 - accuracy: 0.9999 - val_loss: 24.1627 - val_accuracy: 1.0000\n",
      "Epoch 1090/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6786 - accuracy: 0.9999 - val_loss: 23.9986 - val_accuracy: 1.0000\n",
      "Epoch 1091/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7085 - accuracy: 1.0000 - val_loss: 23.9736 - val_accuracy: 1.0000\n",
      "Epoch 1092/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7509 - accuracy: 0.9999 - val_loss: 24.0294 - val_accuracy: 1.0000\n",
      "Epoch 1093/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7059 - accuracy: 1.0000 - val_loss: 24.0148 - val_accuracy: 1.0000\n",
      "Epoch 1094/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6885 - accuracy: 0.9999 - val_loss: 23.9909 - val_accuracy: 1.0000\n",
      "Epoch 1095/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6530 - accuracy: 0.9999 - val_loss: 24.0289 - val_accuracy: 1.0000\n",
      "Epoch 1096/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6924 - accuracy: 0.9999 - val_loss: 23.9234 - val_accuracy: 1.0000\n",
      "Epoch 1097/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6686 - accuracy: 0.9999 - val_loss: 24.0989 - val_accuracy: 1.0000\n",
      "Epoch 1098/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7211 - accuracy: 1.0000 - val_loss: 23.9290 - val_accuracy: 1.0000\n",
      "Epoch 1099/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7221 - accuracy: 0.9999 - val_loss: 23.9995 - val_accuracy: 1.0000\n",
      "Epoch 1100/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6475 - accuracy: 0.9999 - val_loss: 23.9333 - val_accuracy: 1.0000\n",
      "Epoch 1101/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7167 - accuracy: 0.9999 - val_loss: 24.1054 - val_accuracy: 1.0000\n",
      "Epoch 1102/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7329 - accuracy: 1.0000 - val_loss: 23.9508 - val_accuracy: 1.0000\n",
      "Epoch 1103/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6678 - accuracy: 1.0000 - val_loss: 24.0022 - val_accuracy: 1.0000\n",
      "Epoch 1104/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6435 - accuracy: 0.9999 - val_loss: 23.9060 - val_accuracy: 1.0000\n",
      "Epoch 1105/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6482 - accuracy: 0.9999 - val_loss: 24.1102 - val_accuracy: 1.0000\n",
      "Epoch 1106/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7581 - accuracy: 0.9999 - val_loss: 24.0185 - val_accuracy: 1.0000\n",
      "Epoch 1107/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7943 - accuracy: 0.9999 - val_loss: 24.0993 - val_accuracy: 1.0000\n",
      "Epoch 1108/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.9312 - accuracy: 1.0000 - val_loss: 24.1577 - val_accuracy: 1.0000\n",
      "Epoch 1109/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7041 - accuracy: 0.9999 - val_loss: 23.9136 - val_accuracy: 1.0000\n",
      "Epoch 1110/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6815 - accuracy: 0.9999 - val_loss: 24.0356 - val_accuracy: 1.0000\n",
      "Epoch 1111/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6915 - accuracy: 1.0000 - val_loss: 23.9231 - val_accuracy: 1.0000\n",
      "Epoch 1112/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6824 - accuracy: 0.9999 - val_loss: 23.9475 - val_accuracy: 1.0000\n",
      "Epoch 1113/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7030 - accuracy: 0.9999 - val_loss: 24.0503 - val_accuracy: 1.0000\n",
      "Epoch 1114/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6977 - accuracy: 0.9999 - val_loss: 23.9109 - val_accuracy: 1.0000\n",
      "Epoch 1115/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6539 - accuracy: 1.0000 - val_loss: 24.0924 - val_accuracy: 1.0000\n",
      "Epoch 1116/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6970 - accuracy: 0.9999 - val_loss: 24.0002 - val_accuracy: 1.0000\n",
      "Epoch 1117/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6326 - accuracy: 0.9999 - val_loss: 23.9132 - val_accuracy: 1.0000\n",
      "Epoch 1118/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6867 - accuracy: 1.0000 - val_loss: 23.9762 - val_accuracy: 1.0000\n",
      "Epoch 1119/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6754 - accuracy: 0.9999 - val_loss: 24.0547 - val_accuracy: 1.0000\n",
      "Epoch 1120/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6493 - accuracy: 0.9999 - val_loss: 23.8731 - val_accuracy: 1.0000\n",
      "Epoch 1121/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6359 - accuracy: 0.9999 - val_loss: 23.8571 - val_accuracy: 1.0000\n",
      "Epoch 1122/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7437 - accuracy: 0.9999 - val_loss: 23.9786 - val_accuracy: 1.0000\n",
      "Epoch 1123/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7448 - accuracy: 0.9999 - val_loss: 23.9244 - val_accuracy: 1.0000\n",
      "Epoch 1124/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6675 - accuracy: 0.9999 - val_loss: 23.9741 - val_accuracy: 1.0000\n",
      "Epoch 1125/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7163 - accuracy: 1.0000 - val_loss: 23.9233 - val_accuracy: 1.0000\n",
      "Epoch 1126/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.7728 - accuracy: 1.0000 - val_loss: 23.8526 - val_accuracy: 1.0000\n",
      "Epoch 1127/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7511 - accuracy: 0.9999 - val_loss: 23.9131 - val_accuracy: 1.0000\n",
      "Epoch 1128/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6355 - accuracy: 0.9999 - val_loss: 23.8203 - val_accuracy: 1.0000\n",
      "Epoch 1129/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6634 - accuracy: 0.9999 - val_loss: 23.9255 - val_accuracy: 1.0000\n",
      "Epoch 1130/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6402 - accuracy: 0.9999 - val_loss: 23.8905 - val_accuracy: 1.0000\n",
      "Epoch 1131/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6774 - accuracy: 0.9999 - val_loss: 23.9066 - val_accuracy: 1.0000\n",
      "Epoch 1132/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6942 - accuracy: 1.0000 - val_loss: 23.9500 - val_accuracy: 1.0000\n",
      "Epoch 1133/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6644 - accuracy: 0.9999 - val_loss: 23.8173 - val_accuracy: 1.0000\n",
      "Epoch 1134/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5978 - accuracy: 0.9999 - val_loss: 23.8487 - val_accuracy: 1.0000\n",
      "Epoch 1135/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6342 - accuracy: 0.9999 - val_loss: 23.8644 - val_accuracy: 1.0000\n",
      "Epoch 1136/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6155 - accuracy: 0.9999 - val_loss: 23.8024 - val_accuracy: 1.0000\n",
      "Epoch 1137/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6104 - accuracy: 0.9999 - val_loss: 23.8195 - val_accuracy: 1.0000\n",
      "Epoch 1138/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.7025 - accuracy: 1.0000 - val_loss: 23.8452 - val_accuracy: 1.0000\n",
      "Epoch 1139/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6054 - accuracy: 0.9999 - val_loss: 23.7916 - val_accuracy: 1.0000\n",
      "Epoch 1140/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6511 - accuracy: 0.9999 - val_loss: 23.7879 - val_accuracy: 1.0000\n",
      "Epoch 1141/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6062 - accuracy: 1.0000 - val_loss: 23.8630 - val_accuracy: 1.0000\n",
      "Epoch 1142/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6278 - accuracy: 0.9999 - val_loss: 23.8393 - val_accuracy: 1.0000\n",
      "Epoch 1143/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6248 - accuracy: 0.9999 - val_loss: 23.8694 - val_accuracy: 1.0000\n",
      "Epoch 1144/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5998 - accuracy: 0.9999 - val_loss: 23.8398 - val_accuracy: 1.0000\n",
      "Epoch 1145/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6057 - accuracy: 0.9999 - val_loss: 23.8052 - val_accuracy: 1.0000\n",
      "Epoch 1146/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5848 - accuracy: 1.0000 - val_loss: 23.8620 - val_accuracy: 1.0000\n",
      "Epoch 1147/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6581 - accuracy: 0.9999 - val_loss: 23.7972 - val_accuracy: 1.0000\n",
      "Epoch 1148/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6427 - accuracy: 0.9999 - val_loss: 23.8120 - val_accuracy: 1.0000\n",
      "Epoch 1149/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6587 - accuracy: 0.9999 - val_loss: 23.9914 - val_accuracy: 1.0000\n",
      "Epoch 1150/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6838 - accuracy: 0.9999 - val_loss: 23.8613 - val_accuracy: 1.0000\n",
      "Epoch 1151/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5872 - accuracy: 0.9999 - val_loss: 23.7883 - val_accuracy: 1.0000\n",
      "Epoch 1152/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6306 - accuracy: 0.9999 - val_loss: 23.7561 - val_accuracy: 1.0000\n",
      "Epoch 1153/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6280 - accuracy: 0.9999 - val_loss: 23.8405 - val_accuracy: 1.0000\n",
      "Epoch 1154/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5956 - accuracy: 0.9999 - val_loss: 23.7894 - val_accuracy: 1.0000\n",
      "Epoch 1155/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6150 - accuracy: 0.9999 - val_loss: 23.7797 - val_accuracy: 1.0000\n",
      "Epoch 1156/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5859 - accuracy: 0.9999 - val_loss: 23.8214 - val_accuracy: 1.0000\n",
      "Epoch 1157/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6183 - accuracy: 0.9999 - val_loss: 23.7536 - val_accuracy: 1.0000\n",
      "Epoch 1158/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6806 - accuracy: 0.9999 - val_loss: 23.7747 - val_accuracy: 1.0000\n",
      "Epoch 1159/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5772 - accuracy: 0.9999 - val_loss: 23.7721 - val_accuracy: 1.0000\n",
      "Epoch 1160/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6162 - accuracy: 1.0000 - val_loss: 23.9708 - val_accuracy: 1.0000\n",
      "Epoch 1161/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6393 - accuracy: 0.9999 - val_loss: 23.7838 - val_accuracy: 1.0000\n",
      "Epoch 1162/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5799 - accuracy: 0.9999 - val_loss: 23.7756 - val_accuracy: 1.0000\n",
      "Epoch 1163/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6533 - accuracy: 0.9999 - val_loss: 23.7729 - val_accuracy: 1.0000\n",
      "Epoch 1164/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5989 - accuracy: 0.9999 - val_loss: 23.7100 - val_accuracy: 1.0000\n",
      "Epoch 1165/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6608 - accuracy: 0.9999 - val_loss: 23.8644 - val_accuracy: 1.0000\n",
      "Epoch 1166/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6325 - accuracy: 0.9999 - val_loss: 23.7001 - val_accuracy: 1.0000\n",
      "Epoch 1167/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6034 - accuracy: 0.9999 - val_loss: 23.8651 - val_accuracy: 1.0000\n",
      "Epoch 1168/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6521 - accuracy: 0.9999 - val_loss: 23.7814 - val_accuracy: 1.0000\n",
      "Epoch 1169/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6267 - accuracy: 0.9999 - val_loss: 23.8057 - val_accuracy: 1.0000\n",
      "Epoch 1170/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6436 - accuracy: 0.9999 - val_loss: 23.7875 - val_accuracy: 1.0000\n",
      "Epoch 1171/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5666 - accuracy: 0.9999 - val_loss: 23.6915 - val_accuracy: 1.0000\n",
      "Epoch 1172/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6201 - accuracy: 0.9999 - val_loss: 23.7890 - val_accuracy: 1.0000\n",
      "Epoch 1173/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6320 - accuracy: 0.9999 - val_loss: 23.8224 - val_accuracy: 1.0000\n",
      "Epoch 1174/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5538 - accuracy: 0.9999 - val_loss: 23.7265 - val_accuracy: 1.0000\n",
      "Epoch 1175/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6578 - accuracy: 0.9999 - val_loss: 23.8831 - val_accuracy: 1.0000\n",
      "Epoch 1176/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6061 - accuracy: 0.9999 - val_loss: 23.6554 - val_accuracy: 1.0000\n",
      "Epoch 1177/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6028 - accuracy: 0.9999 - val_loss: 23.7494 - val_accuracy: 1.0000\n",
      "Epoch 1178/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5641 - accuracy: 0.9999 - val_loss: 23.7393 - val_accuracy: 1.0000\n",
      "Epoch 1179/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5854 - accuracy: 0.9999 - val_loss: 23.6813 - val_accuracy: 1.0000\n",
      "Epoch 1180/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5571 - accuracy: 0.9999 - val_loss: 23.8313 - val_accuracy: 1.0000\n",
      "Epoch 1181/1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 22.6058 - accuracy: 0.9999 - val_loss: 23.7994 - val_accuracy: 1.0000\n",
      "Epoch 1182/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6360 - accuracy: 0.9999 - val_loss: 23.6815 - val_accuracy: 1.0000\n",
      "Epoch 1183/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5783 - accuracy: 1.0000 - val_loss: 23.7046 - val_accuracy: 1.0000\n",
      "Epoch 1184/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5765 - accuracy: 0.9999 - val_loss: 23.6779 - val_accuracy: 1.0000\n",
      "Epoch 1185/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5698 - accuracy: 0.9999 - val_loss: 23.6791 - val_accuracy: 1.0000\n",
      "Epoch 1186/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6068 - accuracy: 0.9999 - val_loss: 23.7018 - val_accuracy: 1.0000\n",
      "Epoch 1187/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5811 - accuracy: 0.9999 - val_loss: 23.8553 - val_accuracy: 1.0000\n",
      "Epoch 1188/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6020 - accuracy: 1.0000 - val_loss: 23.7216 - val_accuracy: 1.0000\n",
      "Epoch 1189/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7049 - accuracy: 0.9999 - val_loss: 23.6511 - val_accuracy: 1.0000\n",
      "Epoch 1190/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.7006 - accuracy: 0.9999 - val_loss: 23.7357 - val_accuracy: 1.0000\n",
      "Epoch 1191/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6453 - accuracy: 0.9999 - val_loss: 23.7695 - val_accuracy: 1.0000\n",
      "Epoch 1192/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5957 - accuracy: 0.9999 - val_loss: 23.6514 - val_accuracy: 1.0000\n",
      "Epoch 1193/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5588 - accuracy: 0.9999 - val_loss: 23.7423 - val_accuracy: 1.0000\n",
      "Epoch 1194/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6392 - accuracy: 0.9999 - val_loss: 23.7083 - val_accuracy: 1.0000\n",
      "Epoch 1195/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5538 - accuracy: 0.9999 - val_loss: 23.7089 - val_accuracy: 1.0000\n",
      "Epoch 1196/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5564 - accuracy: 0.9999 - val_loss: 23.6582 - val_accuracy: 1.0000\n",
      "Epoch 1197/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5806 - accuracy: 1.0000 - val_loss: 23.8838 - val_accuracy: 1.0000\n",
      "Epoch 1198/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5703 - accuracy: 1.0000 - val_loss: 23.6338 - val_accuracy: 1.0000\n",
      "Epoch 1199/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5743 - accuracy: 0.9999 - val_loss: 23.6386 - val_accuracy: 1.0000\n",
      "Epoch 1200/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5962 - accuracy: 0.9999 - val_loss: 23.9676 - val_accuracy: 1.0000\n",
      "Epoch 1201/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6508 - accuracy: 1.0000 - val_loss: 23.6176 - val_accuracy: 1.0000\n",
      "Epoch 1202/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5435 - accuracy: 0.9999 - val_loss: 23.6317 - val_accuracy: 1.0000\n",
      "Epoch 1203/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5375 - accuracy: 0.9999 - val_loss: 23.7239 - val_accuracy: 1.0000\n",
      "Epoch 1204/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5409 - accuracy: 0.9999 - val_loss: 23.6430 - val_accuracy: 1.0000\n",
      "Epoch 1205/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5616 - accuracy: 0.9999 - val_loss: 23.7592 - val_accuracy: 1.0000\n",
      "Epoch 1206/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5727 - accuracy: 0.9999 - val_loss: 23.6669 - val_accuracy: 1.0000\n",
      "Epoch 1207/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5916 - accuracy: 0.9999 - val_loss: 23.7655 - val_accuracy: 1.0000\n",
      "Epoch 1208/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6011 - accuracy: 0.9999 - val_loss: 23.6230 - val_accuracy: 1.0000\n",
      "Epoch 1209/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5458 - accuracy: 0.9999 - val_loss: 23.6872 - val_accuracy: 1.0000\n",
      "Epoch 1210/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6247 - accuracy: 0.9999 - val_loss: 23.6742 - val_accuracy: 1.0000\n",
      "Epoch 1211/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 22.5609 - accuracy: 0.9999 - val_loss: 23.6620 - val_accuracy: 1.0000\n",
      "Epoch 1212/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5594 - accuracy: 0.9999 - val_loss: 23.8268 - val_accuracy: 1.0000\n",
      "Epoch 1213/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5884 - accuracy: 1.0000 - val_loss: 23.7703 - val_accuracy: 1.0000\n",
      "Epoch 1214/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5191 - accuracy: 0.9999 - val_loss: 23.6764 - val_accuracy: 1.0000\n",
      "Epoch 1215/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5686 - accuracy: 0.9999 - val_loss: 23.5659 - val_accuracy: 1.0000\n",
      "Epoch 1216/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5542 - accuracy: 0.9999 - val_loss: 23.6613 - val_accuracy: 1.0000\n",
      "Epoch 1217/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5461 - accuracy: 0.9999 - val_loss: 23.6557 - val_accuracy: 1.0000\n",
      "Epoch 1218/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5234 - accuracy: 0.9999 - val_loss: 23.7367 - val_accuracy: 1.0000\n",
      "Epoch 1219/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5771 - accuracy: 0.9999 - val_loss: 23.7568 - val_accuracy: 1.0000\n",
      "Epoch 1220/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5952 - accuracy: 0.9999 - val_loss: 23.7216 - val_accuracy: 1.0000\n",
      "Epoch 1221/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6002 - accuracy: 0.9999 - val_loss: 23.6077 - val_accuracy: 1.0000\n",
      "Epoch 1222/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5804 - accuracy: 0.9999 - val_loss: 23.7099 - val_accuracy: 1.0000\n",
      "Epoch 1223/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5580 - accuracy: 0.9999 - val_loss: 23.6634 - val_accuracy: 1.0000\n",
      "Epoch 1224/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5254 - accuracy: 0.9999 - val_loss: 23.6777 - val_accuracy: 1.0000\n",
      "Epoch 1225/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5092 - accuracy: 0.9999 - val_loss: 23.6495 - val_accuracy: 1.0000\n",
      "Epoch 1226/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5208 - accuracy: 1.0000 - val_loss: 23.6481 - val_accuracy: 1.0000\n",
      "Epoch 1227/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 22.5054 - accuracy: 0.9999 - val_loss: 23.6494 - val_accuracy: 1.0000\n",
      "Epoch 1228/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5607 - accuracy: 0.9999 - val_loss: 23.7029 - val_accuracy: 1.0000\n",
      "Epoch 1229/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5504 - accuracy: 1.0000 - val_loss: 23.7596 - val_accuracy: 1.0000\n",
      "Epoch 1230/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5262 - accuracy: 0.9999 - val_loss: 23.6562 - val_accuracy: 1.0000\n",
      "Epoch 1231/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5454 - accuracy: 0.9999 - val_loss: 23.6420 - val_accuracy: 1.0000\n",
      "Epoch 1232/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5979 - accuracy: 0.9999 - val_loss: 23.5849 - val_accuracy: 1.0000\n",
      "Epoch 1233/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5508 - accuracy: 0.9999 - val_loss: 23.6927 - val_accuracy: 1.0000\n",
      "Epoch 1234/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5403 - accuracy: 0.9999 - val_loss: 23.6632 - val_accuracy: 1.0000\n",
      "Epoch 1235/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5302 - accuracy: 0.9999 - val_loss: 23.7064 - val_accuracy: 1.0000\n",
      "Epoch 1236/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5177 - accuracy: 0.9999 - val_loss: 23.6072 - val_accuracy: 1.0000\n",
      "Epoch 1237/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5256 - accuracy: 0.9999 - val_loss: 23.6333 - val_accuracy: 1.0000\n",
      "Epoch 1238/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5382 - accuracy: 0.9999 - val_loss: 23.6467 - val_accuracy: 1.0000\n",
      "Epoch 1239/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4961 - accuracy: 0.9999 - val_loss: 23.6142 - val_accuracy: 1.0000\n",
      "Epoch 1240/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5299 - accuracy: 0.9999 - val_loss: 23.7939 - val_accuracy: 1.0000\n",
      "Epoch 1241/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6306 - accuracy: 0.9999 - val_loss: 23.6887 - val_accuracy: 1.0000\n",
      "Epoch 1242/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5133 - accuracy: 0.9999 - val_loss: 23.6558 - val_accuracy: 1.0000\n",
      "Epoch 1243/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5723 - accuracy: 0.9999 - val_loss: 23.5904 - val_accuracy: 1.0000\n",
      "Epoch 1244/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6131 - accuracy: 0.9999 - val_loss: 23.7648 - val_accuracy: 1.0000\n",
      "Epoch 1245/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5318 - accuracy: 0.9999 - val_loss: 23.7239 - val_accuracy: 1.0000\n",
      "Epoch 1246/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.6220 - accuracy: 0.9999 - val_loss: 23.6950 - val_accuracy: 1.0000\n",
      "Epoch 1247/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5376 - accuracy: 0.9999 - val_loss: 23.6716 - val_accuracy: 1.0000\n",
      "Epoch 1248/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4998 - accuracy: 1.0000 - val_loss: 23.6338 - val_accuracy: 1.0000\n",
      "Epoch 1249/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5206 - accuracy: 0.9999 - val_loss: 23.6583 - val_accuracy: 1.0000\n",
      "Epoch 1250/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5325 - accuracy: 0.9999 - val_loss: 23.7472 - val_accuracy: 1.0000\n",
      "Epoch 1251/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5390 - accuracy: 0.9999 - val_loss: 23.6554 - val_accuracy: 1.0000\n",
      "Epoch 1252/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5253 - accuracy: 0.9999 - val_loss: 23.5824 - val_accuracy: 1.0000\n",
      "Epoch 1253/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5009 - accuracy: 0.9999 - val_loss: 23.6260 - val_accuracy: 1.0000\n",
      "Epoch 1254/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5429 - accuracy: 0.9999 - val_loss: 23.5945 - val_accuracy: 1.0000\n",
      "Epoch 1255/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5254 - accuracy: 0.9999 - val_loss: 23.7229 - val_accuracy: 1.0000\n",
      "Epoch 1256/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 22.5810 - accuracy: 0.9999 - val_loss: 23.5938 - val_accuracy: 1.0000\n",
      "Epoch 1257/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5621 - accuracy: 0.9999 - val_loss: 23.7162 - val_accuracy: 1.0000\n",
      "Epoch 1258/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5734 - accuracy: 0.9999 - val_loss: 23.6818 - val_accuracy: 1.0000\n",
      "Epoch 1259/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5244 - accuracy: 0.9999 - val_loss: 23.5585 - val_accuracy: 1.0000\n",
      "Epoch 1260/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4894 - accuracy: 0.9999 - val_loss: 23.6764 - val_accuracy: 1.0000\n",
      "Epoch 1261/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5325 - accuracy: 0.9999 - val_loss: 23.7532 - val_accuracy: 1.0000\n",
      "Epoch 1262/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5367 - accuracy: 1.0000 - val_loss: 23.6650 - val_accuracy: 1.0000\n",
      "Epoch 1263/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5076 - accuracy: 0.9999 - val_loss: 23.7019 - val_accuracy: 1.0000\n",
      "Epoch 1264/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5660 - accuracy: 0.9999 - val_loss: 23.7206 - val_accuracy: 1.0000\n",
      "Epoch 1265/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5532 - accuracy: 1.0000 - val_loss: 23.7095 - val_accuracy: 1.0000\n",
      "Epoch 1266/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5974 - accuracy: 0.9999 - val_loss: 23.5189 - val_accuracy: 1.0000\n",
      "Epoch 1267/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5159 - accuracy: 1.0000 - val_loss: 23.6673 - val_accuracy: 1.0000\n",
      "Epoch 1268/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5427 - accuracy: 0.9999 - val_loss: 23.8195 - val_accuracy: 1.0000\n",
      "Epoch 1269/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5864 - accuracy: 0.9999 - val_loss: 23.6672 - val_accuracy: 1.0000\n",
      "Epoch 1270/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5392 - accuracy: 0.9999 - val_loss: 23.6691 - val_accuracy: 1.0000\n",
      "Epoch 1271/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5208 - accuracy: 1.0000 - val_loss: 23.6985 - val_accuracy: 1.0000\n",
      "Epoch 1272/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5233 - accuracy: 0.9999 - val_loss: 23.6599 - val_accuracy: 1.0000\n",
      "Epoch 1273/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4989 - accuracy: 0.9999 - val_loss: 23.6724 - val_accuracy: 1.0000\n",
      "Epoch 1274/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5153 - accuracy: 0.9999 - val_loss: 23.5579 - val_accuracy: 1.0000\n",
      "Epoch 1275/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4995 - accuracy: 0.9999 - val_loss: 23.5927 - val_accuracy: 1.0000\n",
      "Epoch 1276/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5005 - accuracy: 0.9999 - val_loss: 23.6035 - val_accuracy: 1.0000\n",
      "Epoch 1277/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5107 - accuracy: 0.9999 - val_loss: 23.5860 - val_accuracy: 1.0000\n",
      "Epoch 1278/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4867 - accuracy: 1.0000 - val_loss: 23.6381 - val_accuracy: 1.0000\n",
      "Epoch 1279/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5106 - accuracy: 0.9999 - val_loss: 23.6535 - val_accuracy: 1.0000\n",
      "Epoch 1280/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5045 - accuracy: 0.9999 - val_loss: 23.6622 - val_accuracy: 1.0000\n",
      "Epoch 1281/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5040 - accuracy: 0.9999 - val_loss: 23.6145 - val_accuracy: 1.0000\n",
      "Epoch 1282/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4923 - accuracy: 0.9999 - val_loss: 23.5430 - val_accuracy: 1.0000\n",
      "Epoch 1283/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4953 - accuracy: 0.9999 - val_loss: 23.6440 - val_accuracy: 1.0000\n",
      "Epoch 1284/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5002 - accuracy: 0.9999 - val_loss: 23.5950 - val_accuracy: 1.0000\n",
      "Epoch 1285/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5227 - accuracy: 1.0000 - val_loss: 23.6636 - val_accuracy: 1.0000\n",
      "Epoch 1286/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5835 - accuracy: 0.9999 - val_loss: 23.5676 - val_accuracy: 1.0000\n",
      "Epoch 1287/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5050 - accuracy: 0.9999 - val_loss: 23.5574 - val_accuracy: 1.0000\n",
      "Epoch 1288/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5493 - accuracy: 0.9999 - val_loss: 23.8155 - val_accuracy: 1.0000\n",
      "Epoch 1289/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6104 - accuracy: 1.0000 - val_loss: 23.7767 - val_accuracy: 1.0000\n",
      "Epoch 1290/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5798 - accuracy: 0.9999 - val_loss: 23.5937 - val_accuracy: 1.0000\n",
      "Epoch 1291/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5161 - accuracy: 0.9999 - val_loss: 23.6978 - val_accuracy: 1.0000\n",
      "Epoch 1292/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5283 - accuracy: 0.9999 - val_loss: 23.7187 - val_accuracy: 1.0000\n",
      "Epoch 1293/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5254 - accuracy: 0.9999 - val_loss: 23.6108 - val_accuracy: 1.0000\n",
      "Epoch 1294/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4750 - accuracy: 0.9999 - val_loss: 23.6051 - val_accuracy: 1.0000\n",
      "Epoch 1295/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4934 - accuracy: 0.9999 - val_loss: 23.5966 - val_accuracy: 1.0000\n",
      "Epoch 1296/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5201 - accuracy: 0.9999 - val_loss: 23.6518 - val_accuracy: 1.0000\n",
      "Epoch 1297/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5281 - accuracy: 0.9999 - val_loss: 23.5524 - val_accuracy: 1.0000\n",
      "Epoch 1298/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5579 - accuracy: 0.9999 - val_loss: 23.5681 - val_accuracy: 1.0000\n",
      "Epoch 1299/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5297 - accuracy: 0.9999 - val_loss: 23.7089 - val_accuracy: 1.0000\n",
      "Epoch 1300/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4861 - accuracy: 0.9999 - val_loss: 23.5637 - val_accuracy: 1.0000\n",
      "Epoch 1301/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5136 - accuracy: 0.9999 - val_loss: 23.6441 - val_accuracy: 1.0000\n",
      "Epoch 1302/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5671 - accuracy: 0.9999 - val_loss: 23.5705 - val_accuracy: 1.0000\n",
      "Epoch 1303/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4859 - accuracy: 0.9999 - val_loss: 23.6303 - val_accuracy: 1.0000\n",
      "Epoch 1304/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4881 - accuracy: 0.9999 - val_loss: 23.5589 - val_accuracy: 1.0000\n",
      "Epoch 1305/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4651 - accuracy: 0.9999 - val_loss: 23.7096 - val_accuracy: 1.0000\n",
      "Epoch 1306/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5013 - accuracy: 0.9999 - val_loss: 23.7794 - val_accuracy: 1.0000\n",
      "Epoch 1307/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5421 - accuracy: 1.0000 - val_loss: 23.6037 - val_accuracy: 1.0000\n",
      "Epoch 1308/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5425 - accuracy: 0.9999 - val_loss: 23.5829 - val_accuracy: 1.0000\n",
      "Epoch 1309/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5743 - accuracy: 0.9999 - val_loss: 23.5515 - val_accuracy: 1.0000\n",
      "Epoch 1310/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5158 - accuracy: 0.9999 - val_loss: 23.5705 - val_accuracy: 1.0000\n",
      "Epoch 1311/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4783 - accuracy: 0.9999 - val_loss: 23.6759 - val_accuracy: 1.0000\n",
      "Epoch 1312/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4935 - accuracy: 0.9999 - val_loss: 23.5416 - val_accuracy: 1.0000\n",
      "Epoch 1313/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4969 - accuracy: 0.9999 - val_loss: 23.7228 - val_accuracy: 1.0000\n",
      "Epoch 1314/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6100 - accuracy: 0.9999 - val_loss: 23.7287 - val_accuracy: 1.0000\n",
      "Epoch 1315/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5438 - accuracy: 0.9999 - val_loss: 23.5315 - val_accuracy: 1.0000\n",
      "Epoch 1316/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5053 - accuracy: 0.9999 - val_loss: 23.5676 - val_accuracy: 1.0000\n",
      "Epoch 1317/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4564 - accuracy: 0.9999 - val_loss: 23.5983 - val_accuracy: 1.0000\n",
      "Epoch 1318/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4624 - accuracy: 0.9999 - val_loss: 23.6163 - val_accuracy: 1.0000\n",
      "Epoch 1319/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5013 - accuracy: 0.9999 - val_loss: 23.6022 - val_accuracy: 1.0000\n",
      "Epoch 1320/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5895 - accuracy: 1.0000 - val_loss: 23.6999 - val_accuracy: 1.0000\n",
      "Epoch 1321/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6321 - accuracy: 0.9999 - val_loss: 23.5124 - val_accuracy: 1.0000\n",
      "Epoch 1322/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.6816 - accuracy: 0.9999 - val_loss: 23.6123 - val_accuracy: 1.0000\n",
      "Epoch 1323/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.6452 - accuracy: 0.9999 - val_loss: 23.6562 - val_accuracy: 1.0000\n",
      "Epoch 1324/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4974 - accuracy: 0.9999 - val_loss: 23.6458 - val_accuracy: 1.0000\n",
      "Epoch 1325/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4486 - accuracy: 1.0000 - val_loss: 23.7770 - val_accuracy: 1.0000\n",
      "Epoch 1326/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5551 - accuracy: 0.9999 - val_loss: 23.5623 - val_accuracy: 1.0000\n",
      "Epoch 1327/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4769 - accuracy: 0.9999 - val_loss: 23.6133 - val_accuracy: 1.0000\n",
      "Epoch 1328/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4505 - accuracy: 1.0000 - val_loss: 23.6856 - val_accuracy: 1.0000\n",
      "Epoch 1329/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4726 - accuracy: 0.9999 - val_loss: 23.4874 - val_accuracy: 1.0000\n",
      "Epoch 1330/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4704 - accuracy: 0.9999 - val_loss: 23.7129 - val_accuracy: 1.0000\n",
      "Epoch 1331/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4863 - accuracy: 1.0000 - val_loss: 23.5878 - val_accuracy: 1.0000\n",
      "Epoch 1332/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4574 - accuracy: 0.9999 - val_loss: 23.6319 - val_accuracy: 1.0000\n",
      "Epoch 1333/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5029 - accuracy: 0.9999 - val_loss: 23.7550 - val_accuracy: 1.0000\n",
      "Epoch 1334/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5028 - accuracy: 0.9999 - val_loss: 23.5500 - val_accuracy: 1.0000\n",
      "Epoch 1335/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4852 - accuracy: 0.9999 - val_loss: 23.5094 - val_accuracy: 1.0000\n",
      "Epoch 1336/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5416 - accuracy: 0.9999 - val_loss: 23.6038 - val_accuracy: 1.0000\n",
      "Epoch 1337/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4683 - accuracy: 0.9999 - val_loss: 23.6014 - val_accuracy: 1.0000\n",
      "Epoch 1338/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5237 - accuracy: 0.9999 - val_loss: 23.5688 - val_accuracy: 1.0000\n",
      "Epoch 1339/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4843 - accuracy: 0.9999 - val_loss: 23.6353 - val_accuracy: 1.0000\n",
      "Epoch 1340/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4734 - accuracy: 0.9999 - val_loss: 23.5932 - val_accuracy: 1.0000\n",
      "Epoch 1341/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4547 - accuracy: 0.9999 - val_loss: 23.5574 - val_accuracy: 1.0000\n",
      "Epoch 1342/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4540 - accuracy: 0.9999 - val_loss: 23.6011 - val_accuracy: 1.0000\n",
      "Epoch 1343/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4773 - accuracy: 0.9999 - val_loss: 23.6169 - val_accuracy: 1.0000\n",
      "Epoch 1344/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4836 - accuracy: 0.9999 - val_loss: 23.5436 - val_accuracy: 1.0000\n",
      "Epoch 1345/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5036 - accuracy: 0.9999 - val_loss: 23.6408 - val_accuracy: 1.0000\n",
      "Epoch 1346/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4505 - accuracy: 1.0000 - val_loss: 23.5782 - val_accuracy: 1.0000\n",
      "Epoch 1347/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4696 - accuracy: 0.9999 - val_loss: 23.5717 - val_accuracy: 1.0000\n",
      "Epoch 1348/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4749 - accuracy: 0.9999 - val_loss: 23.6425 - val_accuracy: 1.0000\n",
      "Epoch 1349/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4986 - accuracy: 0.9999 - val_loss: 23.5565 - val_accuracy: 1.0000\n",
      "Epoch 1350/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4998 - accuracy: 0.9999 - val_loss: 23.6313 - val_accuracy: 1.0000\n",
      "Epoch 1351/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5499 - accuracy: 1.0000 - val_loss: 23.7788 - val_accuracy: 1.0000\n",
      "Epoch 1352/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4485 - accuracy: 0.9999 - val_loss: 23.6930 - val_accuracy: 1.0000\n",
      "Epoch 1353/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5079 - accuracy: 0.9999 - val_loss: 23.5385 - val_accuracy: 1.0000\n",
      "Epoch 1354/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5030 - accuracy: 0.9999 - val_loss: 23.5617 - val_accuracy: 1.0000\n",
      "Epoch 1355/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4865 - accuracy: 0.9999 - val_loss: 23.5585 - val_accuracy: 1.0000\n",
      "Epoch 1356/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4411 - accuracy: 1.0000 - val_loss: 23.5405 - val_accuracy: 1.0000\n",
      "Epoch 1357/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4477 - accuracy: 1.0000 - val_loss: 23.5664 - val_accuracy: 1.0000\n",
      "Epoch 1358/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4536 - accuracy: 0.9999 - val_loss: 23.5292 - val_accuracy: 1.0000\n",
      "Epoch 1359/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4791 - accuracy: 0.9999 - val_loss: 23.5580 - val_accuracy: 1.0000\n",
      "Epoch 1360/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4946 - accuracy: 0.9999 - val_loss: 23.5626 - val_accuracy: 1.0000\n",
      "Epoch 1361/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5158 - accuracy: 0.9999 - val_loss: 23.6016 - val_accuracy: 1.0000\n",
      "Epoch 1362/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5513 - accuracy: 0.9999 - val_loss: 23.6720 - val_accuracy: 1.0000\n",
      "Epoch 1363/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4392 - accuracy: 0.9999 - val_loss: 23.5088 - val_accuracy: 1.0000\n",
      "Epoch 1364/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4363 - accuracy: 0.9999 - val_loss: 23.6649 - val_accuracy: 1.0000\n",
      "Epoch 1365/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4583 - accuracy: 0.9999 - val_loss: 23.5162 - val_accuracy: 1.0000\n",
      "Epoch 1366/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4400 - accuracy: 0.9999 - val_loss: 23.6089 - val_accuracy: 1.0000\n",
      "Epoch 1367/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4709 - accuracy: 0.9999 - val_loss: 23.6749 - val_accuracy: 1.0000\n",
      "Epoch 1368/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4803 - accuracy: 0.9999 - val_loss: 23.6516 - val_accuracy: 1.0000\n",
      "Epoch 1369/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4645 - accuracy: 0.9999 - val_loss: 23.5039 - val_accuracy: 1.0000\n",
      "Epoch 1370/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4504 - accuracy: 1.0000 - val_loss: 23.5071 - val_accuracy: 1.0000\n",
      "Epoch 1371/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.5016 - accuracy: 0.9999 - val_loss: 23.6305 - val_accuracy: 1.0000\n",
      "Epoch 1372/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4562 - accuracy: 0.9999 - val_loss: 23.5310 - val_accuracy: 1.0000\n",
      "Epoch 1373/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4959 - accuracy: 1.0000 - val_loss: 23.5489 - val_accuracy: 1.0000\n",
      "Epoch 1374/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4521 - accuracy: 0.9999 - val_loss: 23.6037 - val_accuracy: 1.0000\n",
      "Epoch 1375/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4723 - accuracy: 0.9999 - val_loss: 23.5124 - val_accuracy: 1.0000\n",
      "Epoch 1376/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4380 - accuracy: 1.0000 - val_loss: 23.5455 - val_accuracy: 1.0000\n",
      "Epoch 1377/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4495 - accuracy: 1.0000 - val_loss: 23.6635 - val_accuracy: 1.0000\n",
      "Epoch 1378/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4721 - accuracy: 0.9999 - val_loss: 23.5753 - val_accuracy: 1.0000\n",
      "Epoch 1379/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4420 - accuracy: 0.9999 - val_loss: 23.5327 - val_accuracy: 1.0000\n",
      "Epoch 1380/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4552 - accuracy: 0.9999 - val_loss: 23.5319 - val_accuracy: 1.0000\n",
      "Epoch 1381/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4396 - accuracy: 0.9999 - val_loss: 23.5592 - val_accuracy: 1.0000\n",
      "Epoch 1382/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4894 - accuracy: 1.0000 - val_loss: 23.5884 - val_accuracy: 1.0000\n",
      "Epoch 1383/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4984 - accuracy: 0.9999 - val_loss: 23.5829 - val_accuracy: 1.0000\n",
      "Epoch 1384/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5332 - accuracy: 1.0000 - val_loss: 23.7214 - val_accuracy: 1.0000\n",
      "Epoch 1385/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4697 - accuracy: 0.9999 - val_loss: 23.5386 - val_accuracy: 1.0000\n",
      "Epoch 1386/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4711 - accuracy: 0.9999 - val_loss: 23.5543 - val_accuracy: 1.0000\n",
      "Epoch 1387/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4286 - accuracy: 1.0000 - val_loss: 23.6169 - val_accuracy: 1.0000\n",
      "Epoch 1388/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5487 - accuracy: 0.9999 - val_loss: 23.6007 - val_accuracy: 1.0000\n",
      "Epoch 1389/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4935 - accuracy: 0.9999 - val_loss: 23.6411 - val_accuracy: 1.0000\n",
      "Epoch 1390/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5622 - accuracy: 0.9999 - val_loss: 23.5305 - val_accuracy: 1.0000\n",
      "Epoch 1391/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4793 - accuracy: 0.9999 - val_loss: 23.5642 - val_accuracy: 1.0000\n",
      "Epoch 1392/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4263 - accuracy: 1.0000 - val_loss: 23.5421 - val_accuracy: 1.0000\n",
      "Epoch 1393/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5024 - accuracy: 0.9999 - val_loss: 23.6256 - val_accuracy: 1.0000\n",
      "Epoch 1394/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4948 - accuracy: 0.9999 - val_loss: 23.5090 - val_accuracy: 1.0000\n",
      "Epoch 1395/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4766 - accuracy: 0.9999 - val_loss: 23.5445 - val_accuracy: 1.0000\n",
      "Epoch 1396/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4087 - accuracy: 0.9999 - val_loss: 23.5682 - val_accuracy: 1.0000\n",
      "Epoch 1397/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4416 - accuracy: 1.0000 - val_loss: 23.5625 - val_accuracy: 1.0000\n",
      "Epoch 1398/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4585 - accuracy: 0.9999 - val_loss: 23.5357 - val_accuracy: 1.0000\n",
      "Epoch 1399/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4260 - accuracy: 1.0000 - val_loss: 23.5029 - val_accuracy: 1.0000\n",
      "Epoch 1400/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4303 - accuracy: 0.9999 - val_loss: 23.5282 - val_accuracy: 1.0000\n",
      "Epoch 1401/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4230 - accuracy: 0.9999 - val_loss: 23.5089 - val_accuracy: 1.0000\n",
      "Epoch 1402/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4356 - accuracy: 0.9999 - val_loss: 23.4973 - val_accuracy: 1.0000\n",
      "Epoch 1403/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4211 - accuracy: 1.0000 - val_loss: 23.5464 - val_accuracy: 1.0000\n",
      "Epoch 1404/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4815 - accuracy: 0.9999 - val_loss: 23.5394 - val_accuracy: 1.0000\n",
      "Epoch 1405/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4877 - accuracy: 0.9999 - val_loss: 23.7088 - val_accuracy: 1.0000\n",
      "Epoch 1406/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4934 - accuracy: 0.9999 - val_loss: 23.4825 - val_accuracy: 1.0000\n",
      "Epoch 1407/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4687 - accuracy: 1.0000 - val_loss: 23.6867 - val_accuracy: 1.0000\n",
      "Epoch 1408/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4472 - accuracy: 1.0000 - val_loss: 23.4513 - val_accuracy: 1.0000\n",
      "Epoch 1409/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4210 - accuracy: 0.9999 - val_loss: 23.5208 - val_accuracy: 1.0000\n",
      "Epoch 1410/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4744 - accuracy: 0.9999 - val_loss: 23.5520 - val_accuracy: 1.0000\n",
      "Epoch 1411/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4614 - accuracy: 0.9999 - val_loss: 23.5024 - val_accuracy: 1.0000\n",
      "Epoch 1412/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4286 - accuracy: 0.9999 - val_loss: 23.5020 - val_accuracy: 1.0000\n",
      "Epoch 1413/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5028 - accuracy: 1.0000 - val_loss: 23.5659 - val_accuracy: 1.0000\n",
      "Epoch 1414/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4036 - accuracy: 0.9999 - val_loss: 23.5210 - val_accuracy: 1.0000\n",
      "Epoch 1415/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4136 - accuracy: 0.9999 - val_loss: 23.4898 - val_accuracy: 1.0000\n",
      "Epoch 1416/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4199 - accuracy: 0.9999 - val_loss: 23.4915 - val_accuracy: 1.0000\n",
      "Epoch 1417/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4240 - accuracy: 0.9999 - val_loss: 23.5914 - val_accuracy: 1.0000\n",
      "Epoch 1418/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4415 - accuracy: 0.9999 - val_loss: 23.4740 - val_accuracy: 1.0000\n",
      "Epoch 1419/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4210 - accuracy: 0.9999 - val_loss: 23.5652 - val_accuracy: 1.0000\n",
      "Epoch 1420/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4480 - accuracy: 0.9999 - val_loss: 23.5577 - val_accuracy: 1.0000\n",
      "Epoch 1421/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4317 - accuracy: 1.0000 - val_loss: 23.5801 - val_accuracy: 1.0000\n",
      "Epoch 1422/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4514 - accuracy: 0.9999 - val_loss: 23.4816 - val_accuracy: 1.0000\n",
      "Epoch 1423/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3986 - accuracy: 1.0000 - val_loss: 23.5190 - val_accuracy: 1.0000\n",
      "Epoch 1424/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4393 - accuracy: 0.9999 - val_loss: 23.4817 - val_accuracy: 1.0000\n",
      "Epoch 1425/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4227 - accuracy: 1.0000 - val_loss: 23.5597 - val_accuracy: 1.0000\n",
      "Epoch 1426/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4590 - accuracy: 0.9999 - val_loss: 23.5043 - val_accuracy: 1.0000\n",
      "Epoch 1427/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4256 - accuracy: 0.9999 - val_loss: 23.5798 - val_accuracy: 1.0000\n",
      "Epoch 1428/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4489 - accuracy: 0.9999 - val_loss: 23.5150 - val_accuracy: 1.0000\n",
      "Epoch 1429/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4292 - accuracy: 0.9999 - val_loss: 23.4779 - val_accuracy: 1.0000\n",
      "Epoch 1430/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4510 - accuracy: 1.0000 - val_loss: 23.5881 - val_accuracy: 1.0000\n",
      "Epoch 1431/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4813 - accuracy: 0.9999 - val_loss: 23.4634 - val_accuracy: 1.0000\n",
      "Epoch 1432/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4739 - accuracy: 1.0000 - val_loss: 23.5219 - val_accuracy: 1.0000\n",
      "Epoch 1433/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.3953 - accuracy: 0.9999 - val_loss: 23.5391 - val_accuracy: 1.0000\n",
      "Epoch 1434/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4410 - accuracy: 0.9999 - val_loss: 23.4809 - val_accuracy: 1.0000\n",
      "Epoch 1435/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4317 - accuracy: 0.9999 - val_loss: 23.5371 - val_accuracy: 1.0000\n",
      "Epoch 1436/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4443 - accuracy: 0.9999 - val_loss: 23.5399 - val_accuracy: 1.0000\n",
      "Epoch 1437/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4200 - accuracy: 1.0000 - val_loss: 23.6081 - val_accuracy: 1.0000\n",
      "Epoch 1438/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4084 - accuracy: 0.9999 - val_loss: 23.4829 - val_accuracy: 1.0000\n",
      "Epoch 1439/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4775 - accuracy: 0.9999 - val_loss: 23.6232 - val_accuracy: 1.0000\n",
      "Epoch 1440/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.5265 - accuracy: 0.9999 - val_loss: 23.7007 - val_accuracy: 1.0000\n",
      "Epoch 1441/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4793 - accuracy: 1.0000 - val_loss: 23.5673 - val_accuracy: 1.0000\n",
      "Epoch 1442/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4063 - accuracy: 0.9999 - val_loss: 23.5959 - val_accuracy: 1.0000\n",
      "Epoch 1443/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4326 - accuracy: 1.0000 - val_loss: 23.5244 - val_accuracy: 1.0000\n",
      "Epoch 1444/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4141 - accuracy: 0.9999 - val_loss: 23.5090 - val_accuracy: 1.0000\n",
      "Epoch 1445/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3964 - accuracy: 0.9999 - val_loss: 23.4637 - val_accuracy: 1.0000\n",
      "Epoch 1446/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3963 - accuracy: 0.9999 - val_loss: 23.5567 - val_accuracy: 1.0000\n",
      "Epoch 1447/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4310 - accuracy: 0.9999 - val_loss: 23.5750 - val_accuracy: 1.0000\n",
      "Epoch 1448/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4593 - accuracy: 1.0000 - val_loss: 23.4832 - val_accuracy: 1.0000\n",
      "Epoch 1449/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5047 - accuracy: 0.9999 - val_loss: 23.5381 - val_accuracy: 1.0000\n",
      "Epoch 1450/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4218 - accuracy: 1.0000 - val_loss: 23.5577 - val_accuracy: 1.0000\n",
      "Epoch 1451/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4484 - accuracy: 1.0000 - val_loss: 23.4913 - val_accuracy: 1.0000\n",
      "Epoch 1452/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4610 - accuracy: 0.9999 - val_loss: 23.8136 - val_accuracy: 1.0000\n",
      "Epoch 1453/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4359 - accuracy: 0.9999 - val_loss: 23.4765 - val_accuracy: 1.0000\n",
      "Epoch 1454/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3962 - accuracy: 0.9999 - val_loss: 23.5294 - val_accuracy: 1.0000\n",
      "Epoch 1455/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4196 - accuracy: 0.9999 - val_loss: 23.4562 - val_accuracy: 1.0000\n",
      "Epoch 1456/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4135 - accuracy: 1.0000 - val_loss: 23.5145 - val_accuracy: 1.0000\n",
      "Epoch 1457/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3994 - accuracy: 0.9999 - val_loss: 23.4936 - val_accuracy: 1.0000\n",
      "Epoch 1458/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3868 - accuracy: 0.9999 - val_loss: 23.4665 - val_accuracy: 1.0000\n",
      "Epoch 1459/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4314 - accuracy: 0.9999 - val_loss: 23.4928 - val_accuracy: 1.0000\n",
      "Epoch 1460/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4116 - accuracy: 0.9999 - val_loss: 23.4519 - val_accuracy: 1.0000\n",
      "Epoch 1461/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3942 - accuracy: 0.9999 - val_loss: 23.5223 - val_accuracy: 1.0000\n",
      "Epoch 1462/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4420 - accuracy: 0.9999 - val_loss: 23.5280 - val_accuracy: 1.0000\n",
      "Epoch 1463/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4464 - accuracy: 0.9999 - val_loss: 23.4646 - val_accuracy: 1.0000\n",
      "Epoch 1464/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3905 - accuracy: 0.9999 - val_loss: 23.4634 - val_accuracy: 1.0000\n",
      "Epoch 1465/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4409 - accuracy: 1.0000 - val_loss: 23.4632 - val_accuracy: 1.0000\n",
      "Epoch 1466/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.3964 - accuracy: 0.9999 - val_loss: 23.5086 - val_accuracy: 1.0000\n",
      "Epoch 1467/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4245 - accuracy: 0.9999 - val_loss: 23.5253 - val_accuracy: 1.0000\n",
      "Epoch 1468/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4514 - accuracy: 1.0000 - val_loss: 23.5255 - val_accuracy: 1.0000\n",
      "Epoch 1469/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3886 - accuracy: 0.9999 - val_loss: 23.4980 - val_accuracy: 1.0000\n",
      "Epoch 1470/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4206 - accuracy: 0.9999 - val_loss: 23.4627 - val_accuracy: 1.0000\n",
      "Epoch 1471/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4020 - accuracy: 1.0000 - val_loss: 23.4841 - val_accuracy: 1.0000\n",
      "Epoch 1472/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4227 - accuracy: 0.9999 - val_loss: 23.4376 - val_accuracy: 1.0000\n",
      "Epoch 1473/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4234 - accuracy: 0.9999 - val_loss: 23.5985 - val_accuracy: 1.0000\n",
      "Epoch 1474/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4228 - accuracy: 1.0000 - val_loss: 23.4998 - val_accuracy: 1.0000\n",
      "Epoch 1475/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4585 - accuracy: 1.0000 - val_loss: 23.5225 - val_accuracy: 1.0000\n",
      "Epoch 1476/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4241 - accuracy: 1.0000 - val_loss: 23.5264 - val_accuracy: 1.0000\n",
      "Epoch 1477/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3778 - accuracy: 0.9999 - val_loss: 23.4429 - val_accuracy: 1.0000\n",
      "Epoch 1478/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3877 - accuracy: 0.9999 - val_loss: 23.5184 - val_accuracy: 1.0000\n",
      "Epoch 1479/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4166 - accuracy: 1.0000 - val_loss: 23.5035 - val_accuracy: 1.0000\n",
      "Epoch 1480/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.3774 - accuracy: 0.9999 - val_loss: 23.6383 - val_accuracy: 1.0000\n",
      "Epoch 1481/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4694 - accuracy: 0.9999 - val_loss: 23.5693 - val_accuracy: 1.0000\n",
      "Epoch 1482/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.4038 - accuracy: 0.9999 - val_loss: 23.4828 - val_accuracy: 1.0000\n",
      "Epoch 1483/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3861 - accuracy: 0.9999 - val_loss: 23.4616 - val_accuracy: 1.0000\n",
      "Epoch 1484/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4331 - accuracy: 1.0000 - val_loss: 23.4711 - val_accuracy: 1.0000\n",
      "Epoch 1485/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.4644 - accuracy: 0.9999 - val_loss: 23.4710 - val_accuracy: 1.0000\n",
      "Epoch 1486/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4406 - accuracy: 0.9999 - val_loss: 23.5138 - val_accuracy: 1.0000\n",
      "Epoch 1487/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3961 - accuracy: 0.9999 - val_loss: 23.4478 - val_accuracy: 1.0000\n",
      "Epoch 1488/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3835 - accuracy: 0.9999 - val_loss: 23.5059 - val_accuracy: 1.0000\n",
      "Epoch 1489/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3929 - accuracy: 0.9999 - val_loss: 23.4513 - val_accuracy: 1.0000\n",
      "Epoch 1490/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.3763 - accuracy: 1.0000 - val_loss: 23.4914 - val_accuracy: 1.0000\n",
      "Epoch 1491/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3968 - accuracy: 1.0000 - val_loss: 23.4814 - val_accuracy: 1.0000\n",
      "Epoch 1492/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3837 - accuracy: 0.9999 - val_loss: 23.4839 - val_accuracy: 1.0000\n",
      "Epoch 1493/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3838 - accuracy: 0.9999 - val_loss: 23.4328 - val_accuracy: 1.0000\n",
      "Epoch 1494/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3971 - accuracy: 0.9999 - val_loss: 23.4884 - val_accuracy: 1.0000\n",
      "Epoch 1495/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3990 - accuracy: 1.0000 - val_loss: 23.4311 - val_accuracy: 1.0000\n",
      "Epoch 1496/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3988 - accuracy: 0.9999 - val_loss: 23.4728 - val_accuracy: 1.0000\n",
      "Epoch 1497/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.3938 - accuracy: 1.0000 - val_loss: 23.5925 - val_accuracy: 1.0000\n",
      "Epoch 1498/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 22.4902 - accuracy: 0.9999 - val_loss: 23.5075 - val_accuracy: 1.0000\n",
      "Epoch 1499/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.3656 - accuracy: 0.9999 - val_loss: 23.4683 - val_accuracy: 1.0000\n",
      "Epoch 1500/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 22.3867 - accuracy: 1.0000 - val_loss: 23.4952 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#importlib.reload(Mtr)\n",
    "\n",
    "epochs     = 1500        # número de epocas\n",
    "batch_size = 1000         # tamaño del lote\n",
    "alpha      = 0.001     # razon de aprendizaje\n",
    "decay      = 0.0001    # decaimiento de alpha\n",
    "\n",
    "Jengi_train.compile(optimizer = optimizers.Adam(learning_rate=alpha, decay=decay),\n",
    "                    loss      = 'mse',\n",
    "                    metrics   = ['accuracy'])\n",
    "\n",
    "#Jengi_train.summary()\n",
    "\n",
    "history = Jengi_train.fit(x                = np.concatenate([log_data, np.zeros((log_data.shape[0],1))], axis = 1),\n",
    "                          y                = components,\n",
    "                          batch_size       = batch_size,\n",
    "                          epochs           = epochs,\n",
    "                          validation_split = 0.2,\n",
    "                          verbose          = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Locked!!\n"
     ]
    }
   ],
   "source": [
    "Xin = Input(shape=(12,),name='In')\n",
    "X = Jengi_train(Xin)\n",
    "X = Dense(2,activation=tf.keras.activations.softsign)(X)\n",
    "X = Dense(12,activation=tf.keras.activations.softsign)(X)\n",
    "Yout = Dense(1, activation='relu')(X)\n",
    "\n",
    "S4D_Her0 = Model(inputs = Xin, outputs = [Yout], name = \"S4D_Her0\")\n",
    "\n",
    "for layer in S4D_Her0.layers:\n",
    "    if layer.name in ['PCA_train']:\n",
    "        print(\"PCA Locked!!\")\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S4D_Her0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m alpha      \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m     \u001b[39m# razon de aprendizaje\u001b[39;00m\n\u001b[1;32m      4\u001b[0m decay      \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m    \u001b[39m# decaimiento de alpha\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m S4D_Her0\u001b[39m.\u001b[39mcompile(optimizer  \u001b[39m=\u001b[39m optimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39malpha, decay\u001b[39m=\u001b[39mdecay),\n\u001b[1;32m      7\u001b[0m                   loss      \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                   metrics   \u001b[39m=\u001b[39m [Mtr\u001b[39m.\u001b[39mmape_accuracy_p3])\n\u001b[1;32m     10\u001b[0m history \u001b[39m=\u001b[39m S4D_Her0\u001b[39m.\u001b[39mfit(x                 \u001b[39m=\u001b[39m log_data,\n\u001b[1;32m     11\u001b[0m                         y                \u001b[39m=\u001b[39m train_gt,\n\u001b[1;32m     12\u001b[0m                         batch_size       \u001b[39m=\u001b[39m batch_size,\n\u001b[1;32m     13\u001b[0m                         epochs           \u001b[39m=\u001b[39m epochs,\n\u001b[1;32m     14\u001b[0m                         validation_split \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,\n\u001b[1;32m     15\u001b[0m                         verbose          \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'S4D_Her0' is not defined"
     ]
    }
   ],
   "source": [
    "epochs     = 500        # número de epocas\n",
    "batch_size = 1000         # tamaño del lote\n",
    "alpha      = 10     # razon de aprendizaje\n",
    "decay      = 0.0001    # decaimiento de alpha\n",
    "\n",
    "S4D_Her0.compile(optimizer  = optimizers.Adam(learning_rate=alpha, decay=decay),\n",
    "                  loss      = 'mae',\n",
    "                  metrics   = [Mtr.mape_accuracy_p3])\n",
    "\n",
    "history = S4D_Her0.fit(x                 = log_data,\n",
    "                        y                = train_gt,\n",
    "                        batch_size       = batch_size,\n",
    "                        epochs           = epochs,\n",
    "                        validation_split = 0.2,\n",
    "                        verbose          = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "42599    False\n",
       "42600    False\n",
       "42601    False\n",
       "42602    False\n",
       "42603    False\n",
       "Name: Categoriadelbien, Length: 42604, dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_test['Categoriadelbien']**3 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 2ms/step - loss: 14.8729 - mape_accuracy_p3: 19.6141 - mse: 251.5887\n"
     ]
    }
   ],
   "source": [
    "S4D_jengi.compile(loss      = tf.losses.MeanAbsolutePercentageError(),\n",
    "                  metrics   = [Mtr.mape_accuracy_p3, 'mse'])\n",
    "\n",
    "score = S4D_jengi.evaluate(log_test, tester_data['Valorcomercial'].to_numpy(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 1s 990us/step\n"
     ]
    }
   ],
   "source": [
    "res = S4D_jengi.predict(np.concatenate([log_test, np.zeros((log_test.shape[0],1))], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbrtval = res.T[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5332726605764517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LMAPE(test_gt, cbrtval**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 151746.73 ,  326462.66 ,  146746.42 ,  110192.7  ,   65923.43 ,\n",
       "        115219.234,  182989.84 , 1679260.8  ,   64933.875,  897221.44 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbrtval[:10]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 160437,  294567,  124749,   97169,   12187,   57076,  217165,\n",
       "       7016452,   30683,  815163])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_res = cbrtval**3\n",
    "mape_list = np.array([ np.abs((test_gt[i] - scale_res[i])/test_gt[i])*100 for i in range(test_gt.shape[0])])\n",
    "#mape_list = np.array([val if val < 200 else 300 for val in mape_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27426,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27426, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_pca = PCA()\n",
    "data2_pca.fit(res)\n",
    "X = trainer_data.to_numpy().T\n",
    "components = (data_pca.components_@X).T\n",
    "\n",
    "components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/plotly/express/_core.py:137: FutureWarning:\n",
      "\n",
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "components_df = pd.DataFrame(components, columns=['PC'+str(i+1)+' ({:.1f})%'.format(data_pca.explained_variance_ratio_[i]*100) for i in range(8)])\n",
    "#components_df.insert(0, 'Valorcomercial', trainer_data['Valorcomercial'].to_numpy())\n",
    "components_df.insert(0, 'Valorcomercial', cbrtval)\n",
    "\n",
    "fig = px.scatter_matrix(components_df,\n",
    "    dimensions=['PC'+str(i+1)+' ({:.1f})%'.format(data_pca.explained_variance_ratio_[i]*100) for i in range(8)],\n",
    "    color=tier,#np.array([val if val < 200 else 300 for val in mape_list]),\n",
    "    title=\"PCA Pairs plot\",\n",
    "    labels=components_df.columns) # remove underscore\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.update_traces(marker_size=1)\n",
    "\n",
    "fig.update_layout(font=dict(size=10))\n",
    "\n",
    "fig.update_layout({\"xaxis\"+str(i+1): dict(showticklabels = False) for i in range(8)})\n",
    "fig.update_layout({\"yaxis\"+str(i+1): dict(showticklabels = False, title='PC'+str(i+1)) for i in range(8)})\n",
    "\n",
    "\n",
    "fig.update_layout(margin={\"r\":150,\"t\":20,\"l\":150,\"b\":20})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.32726605764517"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier = []\n",
    "mu = np.mean(mape_list)\n",
    "sigma = np.std(mape_list)\n",
    "for val in mape_list:\n",
    "    if val <= 10:\n",
    "        tier.append('Correct')\n",
    "        continue\n",
    "    if val <= 25:\n",
    "        tier.append('Acceptable')\n",
    "        continue\n",
    "    if val <= 100:\n",
    "        tier.append('Approximate')\n",
    "        continue\n",
    "    if val <= (mu + sigma):\n",
    "        tier.append('In range')\n",
    "        continue\n",
    "    else:\n",
    "        tier.append('Annomaly')\n",
    "\n",
    "tier = np.array(tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14991"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tier[tier == 'Correct'].shape[0] + tier[tier == 'Acceptable'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.977018  , 12.761486  , -0.33191112, ...,  0.516688  ,\n",
       "         1.5467876 , 53.357975  ],\n",
       "       [35.227562  , 16.083914  , -0.42365462, ...,  0.6507887 ,\n",
       "         1.9488229 , 67.15997   ],\n",
       "       [27.601126  , 12.589657  , -0.32717586, ...,  0.510366  ,\n",
       "         1.526387  , 52.645046  ],\n",
       "       ...,\n",
       "       [29.148487  , 13.295793  , -0.34638256, ...,  0.5351874 ,\n",
       "         1.6110816 , 55.57518   ],\n",
       "       [32.561676  , 14.861186  , -0.38977233, ...,  0.6000124 ,\n",
       "         1.8005797 , 62.079388  ],\n",
       "       [31.148556  , 14.21327   , -0.3717548 , ...,  0.57497466,\n",
       "         1.7236813 , 59.390217  ]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/plotly/express/_core.py:137: FutureWarning:\n",
      "\n",
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = px.scatter_matrix(res+tester_data,\n",
    "    dimensions=tester_data.columns,\n",
    "    title=\"Scatter matrix of data set\",\n",
    "    color=cbrtval,\n",
    "    labels=tester_data.columns) # remove underscore\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.update_traces(marker_size=1)\n",
    "\n",
    "fig.update_layout(font=dict(size=10))\n",
    "\n",
    "fig.update_layout({\"xaxis\"+str(i+1): dict(showticklabels = False, title=tester_data.columns[i][:3].upper()) for i in range(8)})\n",
    "fig.update_layout({\"yaxis\"+str(i+1): dict(showticklabels = False, title=tester_data.columns[i][:3].upper()) for i in range(8)})\n",
    "\n",
    "fig.update_layout(margin={\"r\":150,\"t\":20,\"l\":150,\"b\":20})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/plotly/express/_core.py:137: FutureWarning:\n",
      "\n",
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = px.scatter_matrix(res,\n",
    "    dimensions=[0,1,2,3,4,5,6,7],\n",
    "    title=\"Scatter matrix of data set\",\n",
    "    color=tier,\n",
    "    labels=tester_data.columns) # remove underscore\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.update_traces(marker_size=1)\n",
    "\n",
    "fig.update_layout(font=dict(size=10))\n",
    "\n",
    "fig.update_layout({\"xaxis\"+str(i+1): dict(showticklabels = False, title=tester_data.columns[i][:3].upper()) for i in range(8)})\n",
    "fig.update_layout({\"yaxis\"+str(i+1): dict(showticklabels = False, title=tester_data.columns[i][:3].upper()) for i in range(8)})\n",
    "\n",
    "fig.update_layout(margin={\"r\":150,\"t\":20,\"l\":150,\"b\":20})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 1s 1ms/step\n",
      "858/858 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_train = S4D_jengi.predict(np.concatenate([log_data, np.zeros((log_data.shape[0],1))], axis = 1))\n",
    "scale_res = (pred_train.T[-1])**3\n",
    "train_mape = np.array([ np.abs((train_gt[i] - scale_res[i])/train_gt[i])*100 for i in range(train_gt.shape[0])])\n",
    "\n",
    "pred_test =  S4D_jengi.predict(np.concatenate([log_data, np.zeros((log_data.shape[0],1))], axis = 1))\n",
    "scale_res = (pred_test.T[-1])**3\n",
    "test_mape = np.array([ np.abs((test_gt[i] - scale_res[i])/test_gt[i])*100 for i in range(test_gt.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = [0 if val < 25 else 1 for val in train_mape]\n",
    "cat_test = [0 if val < 25 else 1 for val in test_mape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_train = to_categorical(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xin = Input(shape=(8,),name='In')\n",
    "X = Dense(30)(Xin)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(30)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(30)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(30)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(30)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(30)(X)\n",
    "X = LeakyReLU()(X)\n",
    "X = Dense(2)(X)\n",
    "Yout = LeakyReLU()(X)\n",
    "\n",
    "S4D_astra = Model(inputs = Xin, outputs = [Yout], name = \"S4D_Astra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "22/22 [==============================] - 1s 8ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 2/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 3/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 4/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 5/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 6/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 7/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 8/1500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 9/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 10/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 11/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 12/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 13/1500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 14/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 15/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 16/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 17/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 18/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 19/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 20/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 21/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 22/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 23/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 24/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 25/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 26/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 27/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 28/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 29/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 30/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 31/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 32/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 33/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 34/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 35/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 36/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 37/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 38/1500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 39/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 40/1500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 41/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 42/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 43/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 44/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 45/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 46/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 47/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 48/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 49/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 50/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 51/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 52/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 53/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 54/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 55/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 56/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 57/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 58/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 59/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 60/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 61/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 62/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 63/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 64/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 65/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 66/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 67/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 68/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 69/1500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 70/1500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 71/1500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.5476 - val_loss: nan - val_accuracy: 0.5427\n",
      "Epoch 72/1500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [63], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m decay      \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m    \u001b[39m# decaimiento de alpha\u001b[39;00m\n\u001b[1;32m      6\u001b[0m S4D_astra\u001b[39m.\u001b[39mcompile(optimizer  \u001b[39m=\u001b[39m optimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39malpha, decay\u001b[39m=\u001b[39mdecay),\n\u001b[1;32m      7\u001b[0m                   loss      \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                   metrics   \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m history \u001b[39m=\u001b[39m S4D_astra\u001b[39m.\u001b[39;49mfit(x                 \u001b[39m=\u001b[39;49m pred_train,\n\u001b[1;32m     11\u001b[0m                         y                 \u001b[39m=\u001b[39;49m onehot_train,\n\u001b[1;32m     12\u001b[0m                         batch_size        \u001b[39m=\u001b[39;49m batch_size,\n\u001b[1;32m     13\u001b[0m                         epochs            \u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m     14\u001b[0m                         validation_split  \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m                         verbose           \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Documents/Code/hackathonBBVA/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs     = 1500        # número de epocas\n",
    "batch_size = 1000         # tamaño del lote\n",
    "alpha      = 10     # razon de aprendizaje\n",
    "decay      = 0.0001    # decaimiento de alpha\n",
    "\n",
    "S4D_astra.compile(optimizer  = optimizers.Adam(learning_rate=alpha, decay=decay),\n",
    "                  loss      = 'mse',\n",
    "                  metrics   = ['accuracy'])\n",
    "\n",
    "history = S4D_astra.fit(x                 = pred_train,\n",
    "                        y                 = onehot_train,\n",
    "                        batch_size        = batch_size,\n",
    "                        epochs            = epochs,\n",
    "                        validation_split  = 0.2,\n",
    "                        verbose           = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0198e78fcb23270f2f1a434797316f5c7d17439b897a09cc3cdde74d7b192a6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
